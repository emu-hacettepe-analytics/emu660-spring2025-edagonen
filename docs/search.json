[
  {
    "objectID": "project.html",
    "href": "project.html",
    "title": "Project Genre Matters: Exploring Film Audience Preferences",
    "section": "",
    "text": "Welcome to our project page.\nBegüm ÇORUH & Eda GÖNEN\nKeep an eye on this space to stay updated with our project activities."
  },
  {
    "objectID": "project.html#data-source",
    "href": "project.html#data-source",
    "title": "Project X",
    "section": "2.1 Data Source",
    "text": "2.1 Data Source\nxxxxxx"
  },
  {
    "objectID": "project.html#general-information-about-data",
    "href": "project.html#general-information-about-data",
    "title": "Project X",
    "section": "2.2 General Information About Data",
    "text": "2.2 General Information About Data\nxxxxxx"
  },
  {
    "objectID": "project.html#reason-of-choice",
    "href": "project.html#reason-of-choice",
    "title": "Project X",
    "section": "2.3 Reason of Choice",
    "text": "2.3 Reason of Choice\nxxxxxx"
  },
  {
    "objectID": "project.html#preprocessing",
    "href": "project.html#preprocessing",
    "title": "Project X",
    "section": "2.4 Preprocessing",
    "text": "2.4 Preprocessing\nxxxxxx"
  },
  {
    "objectID": "project.html#exploratory-data-analysis",
    "href": "project.html#exploratory-data-analysis",
    "title": "Project X",
    "section": "3.1 Exploratory Data Analysis",
    "text": "3.1 Exploratory Data Analysis\nxxxxxx"
  },
  {
    "objectID": "project.html#trend-analysis",
    "href": "project.html#trend-analysis",
    "title": "Project X",
    "section": "3.2 Trend Analysis",
    "text": "3.2 Trend Analysis\nxxxxxx"
  },
  {
    "objectID": "project.html#model-fitting",
    "href": "project.html#model-fitting",
    "title": "Project X",
    "section": "3.3 Model Fitting",
    "text": "3.3 Model Fitting\nxxxxxx"
  },
  {
    "objectID": "project.html#results",
    "href": "project.html#results",
    "title": "Project X",
    "section": "3.4 Results",
    "text": "3.4 Results\nxxxxxx"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Welcome to My Analytic Lab",
    "section": "",
    "text": "Hello! I’m Eda Gönen.\nWelcome to my personal website! Here, I share my work in data analytics, blog posts, and a few different projects. I enjoy working with data and finding new ways to understand it. I’ll also be sharing my thoughts on technology from time to time.\nStay tuned, there’s plenty to discover and learn together!\n\n\n\n Back to top"
  },
  {
    "objectID": "index.html#deneme",
    "href": "index.html#deneme",
    "title": "Welcome to My Analytics Lab",
    "section": "Deneme",
    "text": "Deneme"
  },
  {
    "objectID": "assignments/statisticsofmrcars.html",
    "href": "assignments/statisticsofmrcars.html",
    "title": "Mtcars Statistical Analysis",
    "section": "",
    "text": "In R, data(mtcars) loads the mtcars dataset, which contains features of 32 cars. str(mtcars) then displays the dataset’s structure, revealing the types and initial values of its columns, providing a quick overview.\n\ndata(mtcars)\nstr(mtcars)\n\n'data.frame':   32 obs. of  11 variables:\n $ mpg : num  21 21 22.8 21.4 18.7 18.1 14.3 24.4 22.8 19.2 ...\n $ cyl : num  6 6 4 6 8 6 8 4 4 6 ...\n $ disp: num  160 160 108 258 360 ...\n $ hp  : num  110 110 93 110 175 105 245 62 95 123 ...\n $ drat: num  3.9 3.9 3.85 3.08 3.15 2.76 3.21 3.69 3.92 3.92 ...\n $ wt  : num  2.62 2.88 2.32 3.21 3.44 ...\n $ qsec: num  16.5 17 18.6 19.4 17 ...\n $ vs  : num  0 0 1 1 0 1 0 1 1 1 ...\n $ am  : num  1 1 1 0 0 0 0 0 0 0 ...\n $ gear: num  4 4 4 3 3 3 3 4 4 4 ...\n $ carb: num  4 4 1 1 2 1 4 2 2 4 ...\n\n\n\n\n\nThis R code calculates basic statistics for numerical columns in the mtcars dataset. It defines a function, compute_stats, to find the mean, median, variance, IQR, min, and max of a numeric vector, handling potential missing values. A for loop iterates through each column of mtcars, applying compute_stats to numerical ones. The results, with column names, are stored in a list and printed, providing a summary of each numerical column’s statistics.\n\n# İstatistikleri hesaplayan fonksiyon\ncompute_stats &lt;- function(x) {\n  # Girdi sayısal mı kontrol et\n  if (!is.numeric(x)) {\n    stop(\"Hata: Girdi sayısal bir vektör olmalıdır.\")\n  }\n\n  # İstatistik hesaplamaları\n  mean_x &lt;- mean(x, na.rm = TRUE)\n  median_x &lt;- median(x, na.rm = TRUE)\n  var_x &lt;- var(x, na.rm = TRUE)\n  iqr_x &lt;- IQR(x, na.rm = TRUE)\n  min_x &lt;- min(x, na.rm = TRUE)\n  max_x &lt;- max(x, na.rm = TRUE)\n\n  # Sonuçları içeren listeyi döndür\n  compute_stats_list &lt;- list(\n    mean = mean_x,\n    median = median_x,\n    variance = var_x,\n    IQR = iqr_x,\n    min = min_x,\n    maks = max_x\n  )\n\n  return(compute_stats_list)\n}\n\n# mtcars veri seti için tüm sayısal sütunların istatistiklerini hesapla\nmtcars_istatistikleri &lt;- list() # Boş bir liste oluştur\n\nfor (header in names(mtcars)) {\n  if (is.numeric(mtcars[[header]])) {\n    mtcars_istatistikleri[[header]] &lt;- compute_stats(mtcars[[header]]) # Sonuçları listeye ekle\n  }\n}\n\n# Sonuçları yazdır\nprint(mtcars_istatistikleri)\n\n$mpg\n$mpg$mean\n[1] 20.09062\n\n$mpg$median\n[1] 19.2\n\n$mpg$variance\n[1] 36.3241\n\n$mpg$IQR\n[1] 7.375\n\n$mpg$min\n[1] 10.4\n\n$mpg$maks\n[1] 33.9\n\n\n$cyl\n$cyl$mean\n[1] 6.1875\n\n$cyl$median\n[1] 6\n\n$cyl$variance\n[1] 3.189516\n\n$cyl$IQR\n[1] 4\n\n$cyl$min\n[1] 4\n\n$cyl$maks\n[1] 8\n\n\n$disp\n$disp$mean\n[1] 230.7219\n\n$disp$median\n[1] 196.3\n\n$disp$variance\n[1] 15360.8\n\n$disp$IQR\n[1] 205.175\n\n$disp$min\n[1] 71.1\n\n$disp$maks\n[1] 472\n\n\n$hp\n$hp$mean\n[1] 146.6875\n\n$hp$median\n[1] 123\n\n$hp$variance\n[1] 4700.867\n\n$hp$IQR\n[1] 83.5\n\n$hp$min\n[1] 52\n\n$hp$maks\n[1] 335\n\n\n$drat\n$drat$mean\n[1] 3.596563\n\n$drat$median\n[1] 3.695\n\n$drat$variance\n[1] 0.2858814\n\n$drat$IQR\n[1] 0.84\n\n$drat$min\n[1] 2.76\n\n$drat$maks\n[1] 4.93\n\n\n$wt\n$wt$mean\n[1] 3.21725\n\n$wt$median\n[1] 3.325\n\n$wt$variance\n[1] 0.957379\n\n$wt$IQR\n[1] 1.02875\n\n$wt$min\n[1] 1.513\n\n$wt$maks\n[1] 5.424\n\n\n$qsec\n$qsec$mean\n[1] 17.84875\n\n$qsec$median\n[1] 17.71\n\n$qsec$variance\n[1] 3.193166\n\n$qsec$IQR\n[1] 2.0075\n\n$qsec$min\n[1] 14.5\n\n$qsec$maks\n[1] 22.9\n\n\n$vs\n$vs$mean\n[1] 0.4375\n\n$vs$median\n[1] 0\n\n$vs$variance\n[1] 0.2540323\n\n$vs$IQR\n[1] 1\n\n$vs$min\n[1] 0\n\n$vs$maks\n[1] 1\n\n\n$am\n$am$mean\n[1] 0.40625\n\n$am$median\n[1] 0\n\n$am$variance\n[1] 0.2489919\n\n$am$IQR\n[1] 1\n\n$am$min\n[1] 0\n\n$am$maks\n[1] 1\n\n\n$gear\n$gear$mean\n[1] 3.6875\n\n$gear$median\n[1] 4\n\n$gear$variance\n[1] 0.5443548\n\n$gear$IQR\n[1] 1\n\n$gear$min\n[1] 3\n\n$gear$maks\n[1] 5\n\n\n$carb\n$carb$mean\n[1] 2.8125\n\n$carb$median\n[1] 2\n\n$carb$variance\n[1] 2.608871\n\n$carb$IQR\n[1] 2\n\n$carb$min\n[1] 1\n\n$carb$maks\n[1] 8\n\n\nTo automate statistical analysis of numerical columns within the mtcars dataset, a for loop iterates through each column name. Utilizing is.numeric(), the loop identifies numerical columns and applies the compute_stats function. This function calculates key statistics like mean, median, and variance, returning them in a named list. The loop then stores these results, indexed by column names, within a comprehensive list, which is subsequently printed. This approach efficiently provides a structured statistical overview of all numerical columns in the dataset.\n\n\n\nThe sapply function in R is a user-friendly and efficient way to apply a function over a list or vector. In the context of the mtcars dataset, sapply iterates through each column, applying the compute_stats function to those that are numeric. This streamlines the process of calculating statistics for multiple columns, returning the results in a simplified format, such as a vector or matrix. Its ability to directly handle data frames makes it a powerful tool for quick statistical analysis.\n\n# sapply ile tüm sütunlara compute_stats fonksiyonunu uygula\nmtcars_istatistikleri_sapply &lt;- sapply(mtcars, compute_stats)\n\n# Sonuçları yazdır\nprint(mtcars_istatistikleri_sapply)\n\n         mpg      cyl      disp     hp       drat      wt       qsec    \nmean     20.09062 6.1875   230.7219 146.6875 3.596563  3.21725  17.84875\nmedian   19.2     6        196.3    123      3.695     3.325    17.71   \nvariance 36.3241  3.189516 15360.8  4700.867 0.2858814 0.957379 3.193166\nIQR      7.375    4        205.175  83.5     0.84      1.02875  2.0075  \nmin      10.4     4        71.1     52       2.76      1.513    14.5    \nmaks     33.9     8        472      335      4.93      5.424    22.9    \n         vs        am        gear      carb    \nmean     0.4375    0.40625   3.6875    2.8125  \nmedian   0         0         4         2       \nvariance 0.2540323 0.2489919 0.5443548 2.608871\nIQR      1         1         1         2       \nmin      0         0         3         1       \nmaks     1         1         5         8       \n\n\nThe apply function in R is designed to apply a function over the rows or columns of a matrix or array. In this scenario, the mtcars data frame is first converted to a matrix. Then, apply is used to iterate over the columns, applying the compute_stats function to each. This approach allows for consistent application of statistical calculations across all columns, returning the results in a structured format. While apply is versatile, it requires the data to be in a matrix format, making it slightly less direct for data frames compared to sapply.\n\n# apply ile tüm sütunlara compute_stats fonksiyonunu uygula\nmtcars_istatistikleri_apply &lt;- apply(mtcars, MARGIN = 2, compute_stats)\n\n# Sonuçları yazdır\nprint(mtcars_istatistikleri_apply)\n\n$mpg\n$mpg$mean\n[1] 20.09062\n\n$mpg$median\n[1] 19.2\n\n$mpg$variance\n[1] 36.3241\n\n$mpg$IQR\n[1] 7.375\n\n$mpg$min\n[1] 10.4\n\n$mpg$maks\n[1] 33.9\n\n\n$cyl\n$cyl$mean\n[1] 6.1875\n\n$cyl$median\n[1] 6\n\n$cyl$variance\n[1] 3.189516\n\n$cyl$IQR\n[1] 4\n\n$cyl$min\n[1] 4\n\n$cyl$maks\n[1] 8\n\n\n$disp\n$disp$mean\n[1] 230.7219\n\n$disp$median\n[1] 196.3\n\n$disp$variance\n[1] 15360.8\n\n$disp$IQR\n[1] 205.175\n\n$disp$min\n[1] 71.1\n\n$disp$maks\n[1] 472\n\n\n$hp\n$hp$mean\n[1] 146.6875\n\n$hp$median\n[1] 123\n\n$hp$variance\n[1] 4700.867\n\n$hp$IQR\n[1] 83.5\n\n$hp$min\n[1] 52\n\n$hp$maks\n[1] 335\n\n\n$drat\n$drat$mean\n[1] 3.596563\n\n$drat$median\n[1] 3.695\n\n$drat$variance\n[1] 0.2858814\n\n$drat$IQR\n[1] 0.84\n\n$drat$min\n[1] 2.76\n\n$drat$maks\n[1] 4.93\n\n\n$wt\n$wt$mean\n[1] 3.21725\n\n$wt$median\n[1] 3.325\n\n$wt$variance\n[1] 0.957379\n\n$wt$IQR\n[1] 1.02875\n\n$wt$min\n[1] 1.513\n\n$wt$maks\n[1] 5.424\n\n\n$qsec\n$qsec$mean\n[1] 17.84875\n\n$qsec$median\n[1] 17.71\n\n$qsec$variance\n[1] 3.193166\n\n$qsec$IQR\n[1] 2.0075\n\n$qsec$min\n[1] 14.5\n\n$qsec$maks\n[1] 22.9\n\n\n$vs\n$vs$mean\n[1] 0.4375\n\n$vs$median\n[1] 0\n\n$vs$variance\n[1] 0.2540323\n\n$vs$IQR\n[1] 1\n\n$vs$min\n[1] 0\n\n$vs$maks\n[1] 1\n\n\n$am\n$am$mean\n[1] 0.40625\n\n$am$median\n[1] 0\n\n$am$variance\n[1] 0.2489919\n\n$am$IQR\n[1] 1\n\n$am$min\n[1] 0\n\n$am$maks\n[1] 1\n\n\n$gear\n$gear$mean\n[1] 3.6875\n\n$gear$median\n[1] 4\n\n$gear$variance\n[1] 0.5443548\n\n$gear$IQR\n[1] 1\n\n$gear$min\n[1] 3\n\n$gear$maks\n[1] 5\n\n\n$carb\n$carb$mean\n[1] 2.8125\n\n$carb$median\n[1] 2\n\n$carb$variance\n[1] 2.608871\n\n$carb$IQR\n[1] 2\n\n$carb$min\n[1] 1\n\n$carb$maks\n[1] 8",
    "crumbs": [
      "MRCars Statistics"
    ]
  },
  {
    "objectID": "assignments/statisticsofmrcars.html#statistical-analysis-of-the-mtcars-dataset-in-r",
    "href": "assignments/statisticsofmrcars.html#statistical-analysis-of-the-mtcars-dataset-in-r",
    "title": "Mtcars Statistical Analysis",
    "section": "Statistical Analysis of the mtcars Dataset in R",
    "text": "Statistical Analysis of the mtcars Dataset in R\n\nQuick Overview of the mtcars Dataset\nIn R, data(mtcars) loads the mtcars dataset, which contains features of 32 cars. str(mtcars) then displays the dataset’s structure, revealing the types and initial values of its columns, providing a quick overview.\n\ndata(mtcars)\nstr(mtcars)\n\n'data.frame':   32 obs. of  11 variables:\n $ mpg : num  21 21 22.8 21.4 18.7 18.1 14.3 24.4 22.8 19.2 ...\n $ cyl : num  6 6 4 6 8 6 8 4 4 6 ...\n $ disp: num  160 160 108 258 360 ...\n $ hp  : num  110 110 93 110 175 105 245 62 95 123 ...\n $ drat: num  3.9 3.9 3.85 3.08 3.15 2.76 3.21 3.69 3.92 3.92 ...\n $ wt  : num  2.62 2.88 2.32 3.21 3.44 ...\n $ qsec: num  16.5 17 18.6 19.4 17 ...\n $ vs  : num  0 0 1 1 0 1 0 1 1 1 ...\n $ am  : num  1 1 1 0 0 0 0 0 0 0 ...\n $ gear: num  4 4 4 3 3 3 3 4 4 4 ...\n $ carb: num  4 4 1 1 2 1 4 2 2 4 ...\n\n\n\n\nWrite a Custom Summary Function & Applying the Function Using a Loop\nThis R code calculates basic statistics for numerical columns in the mtcars dataset. It defines a function, compute_stats, to find the mean, median, variance, IQR, min, and max of a numeric vector, handling potential missing values. A for loop iterates through each column of mtcars, applying compute_stats to numerical ones. The results, with column names, are stored in a list and printed, providing a summary of each numerical column’s statistics.\n\n# İstatistikleri hesaplayan fonksiyon\ncompute_stats &lt;- function(x) {\n  # Girdi sayısal mı kontrol et\n  if (!is.numeric(x)) {\n    stop(\"Hata: Girdi sayısal bir vektör olmalıdır.\")\n  }\n\n  # İstatistik hesaplamaları\n  mean_x &lt;- mean(x, na.rm = TRUE)\n  median_x &lt;- median(x, na.rm = TRUE)\n  var_x &lt;- var(x, na.rm = TRUE)\n  iqr_x &lt;- IQR(x, na.rm = TRUE)\n  min_x &lt;- min(x, na.rm = TRUE)\n  max_x &lt;- max(x, na.rm = TRUE)\n\n  # Sonuçları içeren listeyi döndür\n  compute_stats_list &lt;- list(\n    mean = mean_x,\n    median = median_x,\n    variance = var_x,\n    IQR = iqr_x,\n    min = min_x,\n    maks = max_x\n  )\n\n  return(compute_stats_list)\n}\n\n# mtcars veri seti için tüm sayısal sütunların istatistiklerini hesapla\nmtcars_istatistikleri &lt;- list() # Boş bir liste oluştur\n\nfor (header in names(mtcars)) {\n  if (is.numeric(mtcars[[header]])) {\n    mtcars_istatistikleri[[header]] &lt;- compute_stats(mtcars[[header]]) # Sonuçları listeye ekle\n  }\n}\n\n# Sonuçları yazdır\nprint(mtcars_istatistikleri)\n\n$mpg\n$mpg$mean\n[1] 20.09062\n\n$mpg$median\n[1] 19.2\n\n$mpg$variance\n[1] 36.3241\n\n$mpg$IQR\n[1] 7.375\n\n$mpg$min\n[1] 10.4\n\n$mpg$maks\n[1] 33.9\n\n\n$cyl\n$cyl$mean\n[1] 6.1875\n\n$cyl$median\n[1] 6\n\n$cyl$variance\n[1] 3.189516\n\n$cyl$IQR\n[1] 4\n\n$cyl$min\n[1] 4\n\n$cyl$maks\n[1] 8\n\n\n$disp\n$disp$mean\n[1] 230.7219\n\n$disp$median\n[1] 196.3\n\n$disp$variance\n[1] 15360.8\n\n$disp$IQR\n[1] 205.175\n\n$disp$min\n[1] 71.1\n\n$disp$maks\n[1] 472\n\n\n$hp\n$hp$mean\n[1] 146.6875\n\n$hp$median\n[1] 123\n\n$hp$variance\n[1] 4700.867\n\n$hp$IQR\n[1] 83.5\n\n$hp$min\n[1] 52\n\n$hp$maks\n[1] 335\n\n\n$drat\n$drat$mean\n[1] 3.596563\n\n$drat$median\n[1] 3.695\n\n$drat$variance\n[1] 0.2858814\n\n$drat$IQR\n[1] 0.84\n\n$drat$min\n[1] 2.76\n\n$drat$maks\n[1] 4.93\n\n\n$wt\n$wt$mean\n[1] 3.21725\n\n$wt$median\n[1] 3.325\n\n$wt$variance\n[1] 0.957379\n\n$wt$IQR\n[1] 1.02875\n\n$wt$min\n[1] 1.513\n\n$wt$maks\n[1] 5.424\n\n\n$qsec\n$qsec$mean\n[1] 17.84875\n\n$qsec$median\n[1] 17.71\n\n$qsec$variance\n[1] 3.193166\n\n$qsec$IQR\n[1] 2.0075\n\n$qsec$min\n[1] 14.5\n\n$qsec$maks\n[1] 22.9\n\n\n$vs\n$vs$mean\n[1] 0.4375\n\n$vs$median\n[1] 0\n\n$vs$variance\n[1] 0.2540323\n\n$vs$IQR\n[1] 1\n\n$vs$min\n[1] 0\n\n$vs$maks\n[1] 1\n\n\n$am\n$am$mean\n[1] 0.40625\n\n$am$median\n[1] 0\n\n$am$variance\n[1] 0.2489919\n\n$am$IQR\n[1] 1\n\n$am$min\n[1] 0\n\n$am$maks\n[1] 1\n\n\n$gear\n$gear$mean\n[1] 3.6875\n\n$gear$median\n[1] 4\n\n$gear$variance\n[1] 0.5443548\n\n$gear$IQR\n[1] 1\n\n$gear$min\n[1] 3\n\n$gear$maks\n[1] 5\n\n\n$carb\n$carb$mean\n[1] 2.8125\n\n$carb$median\n[1] 2\n\n$carb$variance\n[1] 2.608871\n\n$carb$IQR\n[1] 2\n\n$carb$min\n[1] 1\n\n$carb$maks\n[1] 8\n\n\nTo automate statistical analysis of numerical columns within the mtcars dataset, a for loop iterates through each column name. Utilizing is.numeric(), the loop identifies numerical columns and applies the compute_stats function. This function calculates key statistics like mean, median, and variance, returning them in a named list. The loop then stores these results, indexed by column names, within a comprehensive list, which is subsequently printed. This approach efficiently provides a structured statistical overview of all numerical columns in the dataset.\n\n\nAn alternative approach with sapply and apply\nThe sapply function in R is a user-friendly and efficient way to apply a function over a list or vector. In the context of the mtcars dataset, sapply iterates through each column, applying the compute_stats function to those that are numeric. This streamlines the process of calculating statistics for multiple columns, returning the results in a simplified format, such as a vector or matrix. Its ability to directly handle data frames makes it a powerful tool for quick statistical analysis.\n\n# sapply ile tüm sütunlara compute_stats fonksiyonunu uygula\nmtcars_istatistikleri_sapply &lt;- sapply(mtcars, compute_stats)\n\n# Sonuçları yazdır\nprint(mtcars_istatistikleri_sapply)\n\n         mpg      cyl      disp     hp       drat      wt       qsec    \nmean     20.09062 6.1875   230.7219 146.6875 3.596563  3.21725  17.84875\nmedian   19.2     6        196.3    123      3.695     3.325    17.71   \nvariance 36.3241  3.189516 15360.8  4700.867 0.2858814 0.957379 3.193166\nIQR      7.375    4        205.175  83.5     0.84      1.02875  2.0075  \nmin      10.4     4        71.1     52       2.76      1.513    14.5    \nmaks     33.9     8        472      335      4.93      5.424    22.9    \n         vs        am        gear      carb    \nmean     0.4375    0.40625   3.6875    2.8125  \nmedian   0         0         4         2       \nvariance 0.2540323 0.2489919 0.5443548 2.608871\nIQR      1         1         1         2       \nmin      0         0         3         1       \nmaks     1         1         5         8       \n\n\nThe apply function in R is designed to apply a function over the rows or columns of a matrix or array. In this scenario, the mtcars data frame is first converted to a matrix. Then, apply is used to iterate over the columns, applying the compute_stats function to each. This approach allows for consistent application of statistical calculations across all columns, returning the results in a structured format. While apply is versatile, it requires the data to be in a matrix format, making it slightly less direct for data frames compared to sapply.\n\n# apply ile tüm sütunlara compute_stats fonksiyonunu uygula\nmtcars_istatistikleri_apply &lt;- apply(mtcars, MARGIN = 2, compute_stats)\n\n# Sonuçları yazdır\nprint(mtcars_istatistikleri_apply)\n\n$mpg\n$mpg$mean\n[1] 20.09062\n\n$mpg$median\n[1] 19.2\n\n$mpg$variance\n[1] 36.3241\n\n$mpg$IQR\n[1] 7.375\n\n$mpg$min\n[1] 10.4\n\n$mpg$maks\n[1] 33.9\n\n\n$cyl\n$cyl$mean\n[1] 6.1875\n\n$cyl$median\n[1] 6\n\n$cyl$variance\n[1] 3.189516\n\n$cyl$IQR\n[1] 4\n\n$cyl$min\n[1] 4\n\n$cyl$maks\n[1] 8\n\n\n$disp\n$disp$mean\n[1] 230.7219\n\n$disp$median\n[1] 196.3\n\n$disp$variance\n[1] 15360.8\n\n$disp$IQR\n[1] 205.175\n\n$disp$min\n[1] 71.1\n\n$disp$maks\n[1] 472\n\n\n$hp\n$hp$mean\n[1] 146.6875\n\n$hp$median\n[1] 123\n\n$hp$variance\n[1] 4700.867\n\n$hp$IQR\n[1] 83.5\n\n$hp$min\n[1] 52\n\n$hp$maks\n[1] 335\n\n\n$drat\n$drat$mean\n[1] 3.596563\n\n$drat$median\n[1] 3.695\n\n$drat$variance\n[1] 0.2858814\n\n$drat$IQR\n[1] 0.84\n\n$drat$min\n[1] 2.76\n\n$drat$maks\n[1] 4.93\n\n\n$wt\n$wt$mean\n[1] 3.21725\n\n$wt$median\n[1] 3.325\n\n$wt$variance\n[1] 0.957379\n\n$wt$IQR\n[1] 1.02875\n\n$wt$min\n[1] 1.513\n\n$wt$maks\n[1] 5.424\n\n\n$qsec\n$qsec$mean\n[1] 17.84875\n\n$qsec$median\n[1] 17.71\n\n$qsec$variance\n[1] 3.193166\n\n$qsec$IQR\n[1] 2.0075\n\n$qsec$min\n[1] 14.5\n\n$qsec$maks\n[1] 22.9\n\n\n$vs\n$vs$mean\n[1] 0.4375\n\n$vs$median\n[1] 0\n\n$vs$variance\n[1] 0.2540323\n\n$vs$IQR\n[1] 1\n\n$vs$min\n[1] 0\n\n$vs$maks\n[1] 1\n\n\n$am\n$am$mean\n[1] 0.40625\n\n$am$median\n[1] 0\n\n$am$variance\n[1] 0.2489919\n\n$am$IQR\n[1] 1\n\n$am$min\n[1] 0\n\n$am$maks\n[1] 1\n\n\n$gear\n$gear$mean\n[1] 3.6875\n\n$gear$median\n[1] 4\n\n$gear$variance\n[1] 0.5443548\n\n$gear$IQR\n[1] 1\n\n$gear$min\n[1] 3\n\n$gear$maks\n[1] 5\n\n\n$carb\n$carb$mean\n[1] 2.8125\n\n$carb$median\n[1] 2\n\n$carb$variance\n[1] 2.608871\n\n$carb$IQR\n[1] 2\n\n$carb$min\n[1] 1\n\n$carb$maks\n[1] 8",
    "crumbs": [
      "MTCars Statistics"
    ]
  },
  {
    "objectID": "assignments/statisticsofmrcars.html#handling-missing-values-in-the-dslabs-na_example-dataset-methods-and-comparisons",
    "href": "assignments/statisticsofmrcars.html#handling-missing-values-in-the-dslabs-na_example-dataset-methods-and-comparisons",
    "title": "Mtcars Statistical Analysis",
    "section": "Handling Missing Values in the dslabs ‘na_example’ Dataset: Methods and Comparisons",
    "text": "Handling Missing Values in the dslabs ‘na_example’ Dataset: Methods and Comparisons\n\nInstalling and Loading the ‘dslaps’\n\n#install.packages(\"dslabs\")\nlibrary(dslabs)\n\nWarning: package 'dslabs' was built under R version 4.4.3\n\n\nAfter successfully installing and loading the ‘dslabs’ library, we can now print the desired dataset.\n\nprint(na_example)\n\n   [1]  2  1  3  2  1  3  1  4  3  2  2 NA  2  2  1  4 NA  1  1  2  1  2  2  1\n  [25]  2  5 NA  2  2  3  1  2  4  1  1  1  4  5  2  3  4  1  2  4  1  1  2  1\n  [49]  5 NA NA NA  1  1  5  1  3  1 NA  4  4  7  3  2 NA NA  1 NA  4  1  2  2\n  [73]  3  2  1  2  2  4  3  4  2  3  1  3  2  1  1  1  3  1 NA  3  1  2  2  1\n  [97]  2  2  1  1  4  1  1  2  3  3  2  2  3  3  3  4  1  1  1  2 NA  4  3  4\n [121]  3  1  2  1 NA NA NA NA  1  5  1  2  1  3  5  3  2  2 NA NA NA NA  3  5\n [145]  3  1  1  4  2  4  3  3 NA  2  3  2  6 NA  1  1  2  2  1  3  1  1  5 NA\n [169] NA  2  4 NA  2  5  1  4  3  3 NA  4  3  1  4  1  1  3  1  1 NA NA  3  5\n [193]  2  2  2  3  1  2  2  3  2  1 NA  2 NA  1 NA NA  2  1  1 NA  3 NA  1  2\n [217]  2  1  3  2  2  1  1  2  3  1  1  1  4  3  4  2  2  1  4  1 NA  5  1  4\n [241] NA  3 NA NA  1  1  5  2  3  3  2  4 NA  3  2  5 NA  2  3  4  6  2  2  2\n [265] NA  2 NA  2 NA  3  3  2  2  4  3  1  4  2 NA  2  4 NA  6  2  3  1 NA  2\n [289]  2 NA  1  1  3  2  3  3  1 NA  1  4  2  1  1  3  2  1  2  3  1 NA  2  3\n [313]  3  2  1  2  3  5  5  1  2  3  3  1 NA NA  1  2  4 NA  2  1  1  1  3  2\n [337]  1  1  3  4 NA  1  2  1  1  3  3 NA  1  1  3  5  3  2  3  4  1  4  3  1\n [361] NA  2  1  2  2  1  2  2  6  1  2  4  5 NA  3  4  2  1  1  4  2  1  1  1\n [385]  1  2  1  4  4  1  3 NA  3  3 NA  2 NA  1  2  1  1  4  2  1  4  4 NA  1\n [409]  2 NA  3  2  2  2  1  4  3  6  1  2  3  1  3  2  2  2  1  1  3  2  1  1\n [433]  1  3  2  2 NA  4  4  4  1  1 NA  4  3 NA  1  3  1  3  2  4  2  2  2  3\n [457]  2  1  4  3 NA  1  4  3  1  3  2 NA  3 NA  1  3  1  4  1  1  1  2  4  3\n [481]  1  2  2  2  3  2  3  1  1 NA  3  2  1  1  2 NA  2  2  2  3  3  1  1  2\n [505] NA  1  2  1  1  3  3  1  3  1  1  1  1  1  2  5  1  1  2  2  1  1 NA  1\n [529]  4  1  2  4  1  3  2 NA  1  1 NA  2  1  1  4  2  3  3  1  5  3  1  1  2\n [553] NA  1  1  3  1  3  2  4 NA  2  3  2  1  2  1  1  1  2  2  3  1  5  2 NA\n [577]  2 NA  3  2  2  2  1  5  3  2  3  1 NA  3  1  2  2  2  1  2  2  4 NA  6\n [601]  1  2 NA  1  1  2  2  3 NA  3  2  3  3  4  2 NA  2 NA  4 NA  1  1  2  2\n [625]  3  1  1  1  3 NA  2  5 NA  7  1 NA  4  3  3  1 NA  1  1  1  1  3  2  4\n [649]  2  2  3 NA NA  1  4  3  2  2  2  3  2  4  2  2  4 NA NA NA  6  3  3  1\n [673]  4  4  2  1 NA  1  6 NA  3  3  2  1  1  6 NA  1  5  1 NA  2  6  2 NA  4\n [697]  1  3  1  2 NA  1  1  3  1  2  4  2  1  3  2  4  3  2  2  1  1  5  6  4\n [721]  2  2  2  2  4 NA  1  2  2  2  2  4  5 NA NA NA  4  3  3  3  2  4  2  4\n [745] NA NA NA NA  2  1 NA  2  4  3  2 NA  2  3  1  3  4 NA  1  2  1  2 NA  3\n [769]  1  2  1  2  1  2  1  2  2  2  2  1  1  3  3  1  3  4  3 NA NA  4  2  3\n [793]  2  1  3  2  4  2  2  3  1  2  4  3  3  4 NA  1  4  2  1  1  1  3  1  5\n [817]  2  2  4  2 NA  1  3  1  2 NA  1  2  1  2  1 NA  1  3  2  3  2 NA  2  1\n [841]  4  2 NA NA NA  2  4  2 NA NA  3  1 NA  5  5  2  2  2 NA  2  1  3  1  3\n [865]  2  4  2  4 NA  4  1  2  3  2  3  3  2  3  2  2  2  1  3  2  4  2 NA  3\n [889]  3  2  2 NA NA  3  2  1  2  4  1  1  1  1  4  3  2 NA  3  2 NA  1 NA  3\n [913]  2  1  1  1  2 NA  2  2  3  3  2 NA NA  4  5  2  2  2  1  2  3  1  3  3\n [937]  4  3 NA  1  1  1 NA  4  3  5  1  1  2 NA  2  2  2  2  5  2  2  3  1  2\n [961]  3 NA  1  2 NA NA  2 NA  3  1  1  2  5  3  5  1  1  4 NA  2  1  3  1  1\n [985]  2  4  3  3  3 NA  1  1  2  2  1  1  2  2 NA  2\n\n\n\n\nNumber and Locations of NA Values\nThis R code calculates the missing values (NA) within the ‘na_example’ dataset. Initially, we determined the total count of NA values present and identified their index positions within the dataset.\n\ntotal_na &lt;- sum(is.na(na_example))\ncat(\"Total NA values:\", total_na)\n\nTotal NA values: 145\n\n\n\nwhich(is.na(na_example))\n\n  [1]  12  17  27  50  51  52  59  65  66  68  91 117 125 126 127 128 139 140\n [19] 141 142 153 158 168 169 172 179 189 190 203 205 207 208 212 214 237 241\n [37] 243 244 253 257 265 267 269 279 282 287 290 298 310 325 326 330 341 348\n [55] 361 374 392 395 397 407 410 437 443 446 461 468 470 490 496 505 527 536\n [73] 539 553 561 576 578 589 599 603 609 616 618 620 630 633 636 641 652 653\n [91] 666 667 668 677 680 687 691 695 701 726 734 735 736 745 746 747 748 751\n[109] 756 762 767 788 789 807 821 826 832 838 843 844 845 849 850 853 859 869\n[127] 887 892 893 906 909 911 918 924 925 939 943 950 962 965 966 968 979 990\n[145] 999\n\n\n\n\nStatistical Calculation Ignoring NA Values\n\n# NA değerleri göz ardı ederek ortalama ve standart sapma hesapla\nmean_value &lt;- mean(na_example, na.rm = TRUE)\nsd_value &lt;- sd(na_example, na.rm = TRUE)\n\n# Sonuçları ekrana yazdır\ncat(\"Mean:\", mean_value, \"\\n\")\n\nMean: 2.301754 \n\ncat(\"Standart Deviation:\", sd_value)\n\nStandart Deviation: 1.22338\n\n\n\n\nReplacing NA Values with the Median\nIn this process, we replace all missing (NA) values in the na_example dataset with the median of the non-missing values. The median is chosen because it is less sensitive to extreme values (outliers) compared to the mean.\n\n# NA olmayan değerlerin medyanını hesapla\nmedian_others &lt;- median(na_example, na.rm = TRUE)\n\n# NA değerleri medyan ile değiştir\nna_example_median &lt;- ifelse(is.na(na_example), median_others, na_example)\n\n# Sonucu yazdır\ncat(\"Medyan:\", median_others, \"\\n\")\n\nMedyan: 2 \n\nprint(na_example_median)\n\n   [1] 2 1 3 2 1 3 1 4 3 2 2 2 2 2 1 4 2 1 1 2 1 2 2 1 2 5 2 2 2 3 1 2 4 1 1 1 4\n  [38] 5 2 3 4 1 2 4 1 1 2 1 5 2 2 2 1 1 5 1 3 1 2 4 4 7 3 2 2 2 1 2 4 1 2 2 3 2\n  [75] 1 2 2 4 3 4 2 3 1 3 2 1 1 1 3 1 2 3 1 2 2 1 2 2 1 1 4 1 1 2 3 3 2 2 3 3 3\n [112] 4 1 1 1 2 2 4 3 4 3 1 2 1 2 2 2 2 1 5 1 2 1 3 5 3 2 2 2 2 2 2 3 5 3 1 1 4\n [149] 2 4 3 3 2 2 3 2 6 2 1 1 2 2 1 3 1 1 5 2 2 2 4 2 2 5 1 4 3 3 2 4 3 1 4 1 1\n [186] 3 1 1 2 2 3 5 2 2 2 3 1 2 2 3 2 1 2 2 2 1 2 2 2 1 1 2 3 2 1 2 2 1 3 2 2 1\n [223] 1 2 3 1 1 1 4 3 4 2 2 1 4 1 2 5 1 4 2 3 2 2 1 1 5 2 3 3 2 4 2 3 2 5 2 2 3\n [260] 4 6 2 2 2 2 2 2 2 2 3 3 2 2 4 3 1 4 2 2 2 4 2 6 2 3 1 2 2 2 2 1 1 3 2 3 3\n [297] 1 2 1 4 2 1 1 3 2 1 2 3 1 2 2 3 3 2 1 2 3 5 5 1 2 3 3 1 2 2 1 2 4 2 2 1 1\n [334] 1 3 2 1 1 3 4 2 1 2 1 1 3 3 2 1 1 3 5 3 2 3 4 1 4 3 1 2 2 1 2 2 1 2 2 6 1\n [371] 2 4 5 2 3 4 2 1 1 4 2 1 1 1 1 2 1 4 4 1 3 2 3 3 2 2 2 1 2 1 1 4 2 1 4 4 2\n [408] 1 2 2 3 2 2 2 1 4 3 6 1 2 3 1 3 2 2 2 1 1 3 2 1 1 1 3 2 2 2 4 4 4 1 1 2 4\n [445] 3 2 1 3 1 3 2 4 2 2 2 3 2 1 4 3 2 1 4 3 1 3 2 2 3 2 1 3 1 4 1 1 1 2 4 3 1\n [482] 2 2 2 3 2 3 1 1 2 3 2 1 1 2 2 2 2 2 3 3 1 1 2 2 1 2 1 1 3 3 1 3 1 1 1 1 1\n [519] 2 5 1 1 2 2 1 1 2 1 4 1 2 4 1 3 2 2 1 1 2 2 1 1 4 2 3 3 1 5 3 1 1 2 2 1 1\n [556] 3 1 3 2 4 2 2 3 2 1 2 1 1 1 2 2 3 1 5 2 2 2 2 3 2 2 2 1 5 3 2 3 1 2 3 1 2\n [593] 2 2 1 2 2 4 2 6 1 2 2 1 1 2 2 3 2 3 2 3 3 4 2 2 2 2 4 2 1 1 2 2 3 1 1 1 3\n [630] 2 2 5 2 7 1 2 4 3 3 1 2 1 1 1 1 3 2 4 2 2 3 2 2 1 4 3 2 2 2 3 2 4 2 2 4 2\n [667] 2 2 6 3 3 1 4 4 2 1 2 1 6 2 3 3 2 1 1 6 2 1 5 1 2 2 6 2 2 4 1 3 1 2 2 1 1\n [704] 3 1 2 4 2 1 3 2 4 3 2 2 1 1 5 6 4 2 2 2 2 4 2 1 2 2 2 2 4 5 2 2 2 4 3 3 3\n [741] 2 4 2 4 2 2 2 2 2 1 2 2 4 3 2 2 2 3 1 3 4 2 1 2 1 2 2 3 1 2 1 2 1 2 1 2 2\n [778] 2 2 1 1 3 3 1 3 4 3 2 2 4 2 3 2 1 3 2 4 2 2 3 1 2 4 3 3 4 2 1 4 2 1 1 1 3\n [815] 1 5 2 2 4 2 2 1 3 1 2 2 1 2 1 2 1 2 1 3 2 3 2 2 2 1 4 2 2 2 2 2 4 2 2 2 3\n [852] 1 2 5 5 2 2 2 2 2 1 3 1 3 2 4 2 4 2 4 1 2 3 2 3 3 2 3 2 2 2 1 3 2 4 2 2 3\n [889] 3 2 2 2 2 3 2 1 2 4 1 1 1 1 4 3 2 2 3 2 2 1 2 3 2 1 1 1 2 2 2 2 3 3 2 2 2\n [926] 4 5 2 2 2 1 2 3 1 3 3 4 3 2 1 1 1 2 4 3 5 1 1 2 2 2 2 2 2 5 2 2 3 1 2 3 2\n [963] 1 2 2 2 2 2 3 1 1 2 5 3 5 1 1 4 2 2 1 3 1 1 2 4 3 3 3 2 1 1 2 2 1 1 2 2 2\n[1000] 2\n\n\n\nversion1_median &lt;- median(na_example_median)\nversion1_sd &lt;- sd(na_example_median)\n\n# Sonuçları yazdır\ncat(\"Versiyon 1 Medyan:\", version1_median, \"\\n\")\n\nVersiyon 1 Medyan: 2 \n\ncat(\"Versiyon 1 Sapma:\", version1_sd)\n\nVersiyon 1 Sapma: 1.136102\n\n\n\n\nReplacing NA Values with Randomly Selected Non-missing Value\nThis process replaces all NA values in the dataset with a randomly selected non-missing value from the same dataset. First, we extract all non-missing values, then for each NA, a random value from the non-missing values is chosen to fill in the missing spot.\n\n# NA olmayan değerleri al\nnon_na_values &lt;- na_example[!is.na(na_example)]\n\n# NA değerlerini rastgele bir NA olmayan değerle değiştir\nna_example_random &lt;- ifelse(is.na(na_example), sample(non_na_values, 1), na_example)\n\n# Sonuçları yazdır\nprint(na_example_random)\n\n   [1] 2 1 3 2 1 3 1 4 3 2 2 3 2 2 1 4 3 1 1 2 1 2 2 1 2 5 3 2 2 3 1 2 4 1 1 1 4\n  [38] 5 2 3 4 1 2 4 1 1 2 1 5 3 3 3 1 1 5 1 3 1 3 4 4 7 3 2 3 3 1 3 4 1 2 2 3 2\n  [75] 1 2 2 4 3 4 2 3 1 3 2 1 1 1 3 1 3 3 1 2 2 1 2 2 1 1 4 1 1 2 3 3 2 2 3 3 3\n [112] 4 1 1 1 2 3 4 3 4 3 1 2 1 3 3 3 3 1 5 1 2 1 3 5 3 2 2 3 3 3 3 3 5 3 1 1 4\n [149] 2 4 3 3 3 2 3 2 6 3 1 1 2 2 1 3 1 1 5 3 3 2 4 3 2 5 1 4 3 3 3 4 3 1 4 1 1\n [186] 3 1 1 3 3 3 5 2 2 2 3 1 2 2 3 2 1 3 2 3 1 3 3 2 1 1 3 3 3 1 2 2 1 3 2 2 1\n [223] 1 2 3 1 1 1 4 3 4 2 2 1 4 1 3 5 1 4 3 3 3 3 1 1 5 2 3 3 2 4 3 3 2 5 3 2 3\n [260] 4 6 2 2 2 3 2 3 2 3 3 3 2 2 4 3 1 4 2 3 2 4 3 6 2 3 1 3 2 2 3 1 1 3 2 3 3\n [297] 1 3 1 4 2 1 1 3 2 1 2 3 1 3 2 3 3 2 1 2 3 5 5 1 2 3 3 1 3 3 1 2 4 3 2 1 1\n [334] 1 3 2 1 1 3 4 3 1 2 1 1 3 3 3 1 1 3 5 3 2 3 4 1 4 3 1 3 2 1 2 2 1 2 2 6 1\n [371] 2 4 5 3 3 4 2 1 1 4 2 1 1 1 1 2 1 4 4 1 3 3 3 3 3 2 3 1 2 1 1 4 2 1 4 4 3\n [408] 1 2 3 3 2 2 2 1 4 3 6 1 2 3 1 3 2 2 2 1 1 3 2 1 1 1 3 2 2 3 4 4 4 1 1 3 4\n [445] 3 3 1 3 1 3 2 4 2 2 2 3 2 1 4 3 3 1 4 3 1 3 2 3 3 3 1 3 1 4 1 1 1 2 4 3 1\n [482] 2 2 2 3 2 3 1 1 3 3 2 1 1 2 3 2 2 2 3 3 1 1 2 3 1 2 1 1 3 3 1 3 1 1 1 1 1\n [519] 2 5 1 1 2 2 1 1 3 1 4 1 2 4 1 3 2 3 1 1 3 2 1 1 4 2 3 3 1 5 3 1 1 2 3 1 1\n [556] 3 1 3 2 4 3 2 3 2 1 2 1 1 1 2 2 3 1 5 2 3 2 3 3 2 2 2 1 5 3 2 3 1 3 3 1 2\n [593] 2 2 1 2 2 4 3 6 1 2 3 1 1 2 2 3 3 3 2 3 3 4 2 3 2 3 4 3 1 1 2 2 3 1 1 1 3\n [630] 3 2 5 3 7 1 3 4 3 3 1 3 1 1 1 1 3 2 4 2 2 3 3 3 1 4 3 2 2 2 3 2 4 2 2 4 3\n [667] 3 3 6 3 3 1 4 4 2 1 3 1 6 3 3 3 2 1 1 6 3 1 5 1 3 2 6 2 3 4 1 3 1 2 3 1 1\n [704] 3 1 2 4 2 1 3 2 4 3 2 2 1 1 5 6 4 2 2 2 2 4 3 1 2 2 2 2 4 5 3 3 3 4 3 3 3\n [741] 2 4 2 4 3 3 3 3 2 1 3 2 4 3 2 3 2 3 1 3 4 3 1 2 1 2 3 3 1 2 1 2 1 2 1 2 2\n [778] 2 2 1 1 3 3 1 3 4 3 3 3 4 2 3 2 1 3 2 4 2 2 3 1 2 4 3 3 4 3 1 4 2 1 1 1 3\n [815] 1 5 2 2 4 2 3 1 3 1 2 3 1 2 1 2 1 3 1 3 2 3 2 3 2 1 4 2 3 3 3 2 4 2 3 3 3\n [852] 1 3 5 5 2 2 2 3 2 1 3 1 3 2 4 2 4 3 4 1 2 3 2 3 3 2 3 2 2 2 1 3 2 4 2 3 3\n [889] 3 2 2 3 3 3 2 1 2 4 1 1 1 1 4 3 2 3 3 2 3 1 3 3 2 1 1 1 2 3 2 2 3 3 2 3 3\n [926] 4 5 2 2 2 1 2 3 1 3 3 4 3 3 1 1 1 3 4 3 5 1 1 2 3 2 2 2 2 5 2 2 3 1 2 3 3\n [963] 1 2 3 3 2 3 3 1 1 2 5 3 5 1 1 4 3 2 1 3 1 1 2 4 3 3 3 3 1 1 2 2 1 1 2 2 3\n[1000] 2\n\n\n\nversion2_median &lt;- median(na_example_random)\nversion2_sd &lt;- sd(na_example_random)\n\n# Sonuçları yazdır\ncat(\"Versiyon 2 Medyan:\", version2_median, \"\\n\")\n\nVersiyon 2 Medyan: 2 \n\ncat(\"Versiyon 2 Sapma:\", version2_sd)\n\nVersiyon 2 Sapma: 1.157554\n\n\n\nlibrary(knitr)  # kable fonksiyonu için\n\nWarning: package 'knitr' was built under R version 4.4.3\n\n\n\n# Bu kod bloğu tamamen AI tarafından yazılmıstır.\n# Sonuçları birleştirip tabloyu oluştur\n\nstatistics_table &lt;- data.frame(\n  Method = c(\"Original (Mean)\", \"Original (SD)\", \n             \"Imputed (Median, Mean)\", \"Imputed (Median, SD)\", \n             \"Imputed (Random, Mean)\", \"Imputed (Random, SD)\"),\n  Value = c(mean_value, sd_value,\n            mean(na_example_median), sd(na_example_median),\n            mean(na_example_random), sd(na_example_random))\n)\n\n# Tabloyu yazdır\nkable(statistics_table, caption = \"Comparison of Statistics Before and After Handling NA Values\")\n\n\nComparison of Statistics Before and After Handling NA Values\n\n\nMethod\nValue\n\n\n\n\nOriginal (Mean)\n2.301754\n\n\nOriginal (SD)\n1.223380\n\n\nImputed (Median, Mean)\n2.258000\n\n\nImputed (Median, SD)\n1.136102\n\n\nImputed (Random, Mean)\n2.403000\n\n\nImputed (Random, SD)\n1.157554\n\n\n\n\n\nRegarding the data, imputing with the median seems more appropriate as it preserves the central tendency without being affected by outliers. Imputing with random values could better reflect the distribution of the data, but it may introduce some variability. Looking at the original data, if the number of missing values is minimal, ignoring them could be acceptable. However, if the missing values are not random, it could introduce bias in the data.",
    "crumbs": [
      "MTCars Statistics"
    ]
  },
  {
    "objectID": "assignments/datascience.html",
    "href": "assignments/datascience.html",
    "title": "On Data Science and Industrial Engineering",
    "section": "",
    "text": "Below, you will find a brief summary of the discussion video on data analytics and industrial engineering, available at the following link:\nWatch the video here",
    "crumbs": [
      "On Data Science and Industrial Engineering"
    ]
  },
  {
    "objectID": "assignments/datascience.html#the-role-of-data-science-and-its-applications-insights-from-kerem-demirtaş",
    "href": "assignments/datascience.html#the-role-of-data-science-and-its-applications-insights-from-kerem-demirtaş",
    "title": "On Data Science and Industrial Engineering",
    "section": "The Role of Data Science and Its Applications: Insights from Kerem Demirtaş",
    "text": "The Role of Data Science and Its Applications: Insights from Kerem Demirtaş\nKerem Demirtaş is a Data Scientist currently working at Invent Analytics. Previously, he worked at Spyke Games and Smart Kiwi. One of his significant projects was Royal Reachers, where he focused on analyzing users’ gaming behaviors and demographic structures to deliver the most suitable offers at the most optimal times, thereby maximizing sales. Later in his career, he contributed to a project aimed at optimizing inventory management in retail. This involved developing software that determines how much stock should be held at various locations and for which models, ultimately helping businesses maximize their sales.\nHis research interests revolve around autonomous vehicles, traffic flow modeling, transportation simulations, and optimization techniques in mobility systems.",
    "crumbs": [
      "On Data Science and Industrial Engineering"
    ]
  },
  {
    "objectID": "assignments/datascience.html#the-scope-of-data-science",
    "href": "assignments/datascience.html#the-scope-of-data-science",
    "title": "On Data Science and Industrial Engineering",
    "section": "The Scope of Data Science",
    "text": "The Scope of Data Science\nData science finds applications in various fields, including:\n\nEpidemiology: Predicting the likelihood of disease outbreaks, identifying high-risk regions, and implementing preventive measures.\nRetail: Optimizing stock levels and sales strategies to enhance profitability.\nAutonomous Vehicles: Improving traffic efficiency, reducing congestion, and enhancing the decision-making capabilities of self-driving cars.",
    "crumbs": [
      "On Data Science and Industrial Engineering"
    ]
  },
  {
    "objectID": "assignments/datascience.html#what-data-science-is-not",
    "href": "assignments/datascience.html#what-data-science-is-not",
    "title": "On Data Science and Industrial Engineering",
    "section": "What Data Science is NOT",
    "text": "What Data Science is NOT\n\nIt is not merely an exaggerated form of statistics.\nIt is not just about building models.\nIt is not exclusively tied to Big Data.\nWriting Python code does not make someone a data analyst.\nData analysis does not always provide definitive answers to every question.",
    "crumbs": [
      "On Data Science and Industrial Engineering"
    ]
  },
  {
    "objectID": "assignments/datascience.html#the-data-science-workflow",
    "href": "assignments/datascience.html#the-data-science-workflow",
    "title": "On Data Science and Industrial Engineering",
    "section": "The Data Science Workflow",
    "text": "The Data Science Workflow\n\nProblem Identification: Clearly defining the problem is the first step in data science. A historical example of this is the analysis conducted during World War II on aircraft durability. Engineers initially focused on reinforcing the most frequently damaged parts of returning planes, but statistician Abraham Wald proposed a different approach—suggesting that undamaged areas of returning planes were actually where the planes that were shot down had suffered critical damage. This shift in thinking led to more effective reinforcement strategies.\nData Collection: Gathering unbiased data is crucial. Abraham Wald’s unbiased thinking methodology is a key example. His research showed that survivorship bias can mislead analyses if data from unsuccessful cases (e.g., planes that didn’t return) is not considered.\nExploratory Data Analysis (EDA): Before building models, it is essential to understand and visualize the data. A classic example is John Snow’s study on cholera outbreaks in 1854 London. By mapping out cases and identifying contaminated water sources, he demonstrated that cholera was waterborne—long before germ theory was widely accepted. This showcases how data visualization and pattern recognition can lead to groundbreaking discoveries.\nModel Building: At this stage, predictive and analytical models are developed. A relevant example is Lewis Fry Richardson’s pioneering work on weather forecasting, where he proposed numerical methods for predicting atmospheric conditions. Another example is the World War II Diet Problem, which used linear programming to optimize military rations by balancing nutrition and cost.\nModel Evaluation: Assessing model performance and avoiding overfitting are crucial aspects of data science. Overfitting occurs when a model learns noise instead of actual patterns, reducing its real-world applicability. An illustrative case is the Deep Blue vs. Garry Kasparov chess match, where the AI was trained to analyze millions of moves but had to generalize its strategies to defeat a world champion.\nProduction and Live Performance: Once a model is finalized, it must be deployed in a real-world setting. This step involves monitoring AI tools and ensuring their effectiveness. Examples include AI-driven recommendation systems in e-commerce, self-learning fraud detection systems in banking, and real-time traffic prediction tools in transportation networks.",
    "crumbs": [
      "On Data Science and Industrial Engineering"
    ]
  },
  {
    "objectID": "assignments/datascience.html#kerem-demirtaşs-research-on-autonomous-vehicles",
    "href": "assignments/datascience.html#kerem-demirtaşs-research-on-autonomous-vehicles",
    "title": "On Data Science and Industrial Engineering",
    "section": "Kerem Demirtaş’s Research on Autonomous Vehicles",
    "text": "Kerem Demirtaş’s Research on Autonomous Vehicles\nHis thesis, “Object-driven Cellular Automaton Model for Platooning of Autonomous Vehicles on Freeways with Multiple Lanes”, explores how autonomous vehicles can form convoys and adapt to complex road conditions. The primary motivation behind his research is to minimize the following distance between vehicles, optimize acceleration and deceleration during lane changes, and reduce the impact of stop-and-go waves in traffic flow. By refining the mechanics of platooning, his work contributes to the development of more efficient and safer autonomous driving systems.\nUltimately, his work highlights the power of data science in solving complex real-world problems, from optimizing business operations to transforming the future of mobility.",
    "crumbs": [
      "On Data Science and Industrial Engineering"
    ]
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About Me",
    "section": "",
    "text": "As an industrial engineer with a passion for data analysis, broadcasting, and artificial intelligence, I have built my career on exploring innovative solutions in these fields. After graduating from TOBB University, I began working as a data analyst in the broadcasting sector, specifically at TRT1, where I focused on broadcast planning and data analysis.\nCurrently, I am pursuing a master’s degree in industrial engineering while developing projects that integrate AI and innovation into the broadcasting industry. I also share insights on industry trends through blog writing and continuously work on enhancing my professional expertise."
  },
  {
    "objectID": "about.html#education",
    "href": "about.html#education",
    "title": "About Me",
    "section": "Education",
    "text": "Education\n\nM.S, Industrial Engineering, Hacettepe University, Turkey\n2025 - ongoing \n\n\n\nM.S, Business Administration, Hacettepe University, Turkey\n\n2022 - 2023 \n\n\n\n\nB.S, Industrial Engineering, TOBB University of Economics and Technology, Turkey\n\n2015 - 2020"
  },
  {
    "objectID": "about.html#work-experience",
    "href": "about.html#work-experience",
    "title": "About Me",
    "section": "Work Experience",
    "text": "Work Experience\n\nTRT, Planning Specialist, Turkey \n\nDec 2021 - ongoing\nBroadcast Planning & Performance Analysis: Managing and monitoring TV broadcasts, analyzing rating performance, and optimizing scheduling and discount strategies.\nData-Driven Decision Making: Conducting data analysis, preparing reports, and ensuring effective team coordination for strategic planning.\n\nLC WAIKIKI , International Store Merchandiser, Turkey \n\nJan 2021 - Dec 2021\nManaging international store stocks, analyzing performance metrics, and optimizing shipping strategies based on regional clothing preferences.\nDeveloping and implementing discount strategies to enhance sales.\n\nTURK PATENT VE MARKA KURUMU, Intern, Turkey \n\nDec 2019 - Sep 2019\n\nMAN TURKIYE, Quality Control Engineer Intern, Turkey \n\nJan 2019 - Apr 2019\n\nERSA OFIS MOBILYALARI , IT Intern, Turkey \n\nAug 2018- May 2019"
  },
  {
    "objectID": "about.html#competencies",
    "href": "about.html#competencies",
    "title": "About Me",
    "section": "Competencies",
    "text": "Competencies\n\nMathematical Modelling\nMS Office\nR\nCPLEX\nMySQL\nMS Office"
  },
  {
    "objectID": "about.html#hobbies",
    "href": "about.html#hobbies",
    "title": "About Me",
    "section": "Hobbies",
    "text": "Hobbies\n\nPainting & Crafts 🎨🖌️\nCinema & Theatre 🎬🎭\nTraveling & Exploring New Places ✈️🌍\nPhotography 📸\nCooking 🍳\n\n[Learn More -&gt;] Download CV"
  },
  {
    "objectID": "assignments/handlingna.html",
    "href": "assignments/handlingna.html",
    "title": "NA_Example",
    "section": "",
    "text": "#install.packages(\"dslabs\")\nlibrary(dslabs)\n\nWarning: package 'dslabs' was built under R version 4.4.3\n\n\nAfter successfully installing and loading the ‘dslabs’ library, we can now print the desired dataset.\n\nprint(na_example)\n\n   [1]  2  1  3  2  1  3  1  4  3  2  2 NA  2  2  1  4 NA  1  1  2  1  2  2  1\n  [25]  2  5 NA  2  2  3  1  2  4  1  1  1  4  5  2  3  4  1  2  4  1  1  2  1\n  [49]  5 NA NA NA  1  1  5  1  3  1 NA  4  4  7  3  2 NA NA  1 NA  4  1  2  2\n  [73]  3  2  1  2  2  4  3  4  2  3  1  3  2  1  1  1  3  1 NA  3  1  2  2  1\n  [97]  2  2  1  1  4  1  1  2  3  3  2  2  3  3  3  4  1  1  1  2 NA  4  3  4\n [121]  3  1  2  1 NA NA NA NA  1  5  1  2  1  3  5  3  2  2 NA NA NA NA  3  5\n [145]  3  1  1  4  2  4  3  3 NA  2  3  2  6 NA  1  1  2  2  1  3  1  1  5 NA\n [169] NA  2  4 NA  2  5  1  4  3  3 NA  4  3  1  4  1  1  3  1  1 NA NA  3  5\n [193]  2  2  2  3  1  2  2  3  2  1 NA  2 NA  1 NA NA  2  1  1 NA  3 NA  1  2\n [217]  2  1  3  2  2  1  1  2  3  1  1  1  4  3  4  2  2  1  4  1 NA  5  1  4\n [241] NA  3 NA NA  1  1  5  2  3  3  2  4 NA  3  2  5 NA  2  3  4  6  2  2  2\n [265] NA  2 NA  2 NA  3  3  2  2  4  3  1  4  2 NA  2  4 NA  6  2  3  1 NA  2\n [289]  2 NA  1  1  3  2  3  3  1 NA  1  4  2  1  1  3  2  1  2  3  1 NA  2  3\n [313]  3  2  1  2  3  5  5  1  2  3  3  1 NA NA  1  2  4 NA  2  1  1  1  3  2\n [337]  1  1  3  4 NA  1  2  1  1  3  3 NA  1  1  3  5  3  2  3  4  1  4  3  1\n [361] NA  2  1  2  2  1  2  2  6  1  2  4  5 NA  3  4  2  1  1  4  2  1  1  1\n [385]  1  2  1  4  4  1  3 NA  3  3 NA  2 NA  1  2  1  1  4  2  1  4  4 NA  1\n [409]  2 NA  3  2  2  2  1  4  3  6  1  2  3  1  3  2  2  2  1  1  3  2  1  1\n [433]  1  3  2  2 NA  4  4  4  1  1 NA  4  3 NA  1  3  1  3  2  4  2  2  2  3\n [457]  2  1  4  3 NA  1  4  3  1  3  2 NA  3 NA  1  3  1  4  1  1  1  2  4  3\n [481]  1  2  2  2  3  2  3  1  1 NA  3  2  1  1  2 NA  2  2  2  3  3  1  1  2\n [505] NA  1  2  1  1  3  3  1  3  1  1  1  1  1  2  5  1  1  2  2  1  1 NA  1\n [529]  4  1  2  4  1  3  2 NA  1  1 NA  2  1  1  4  2  3  3  1  5  3  1  1  2\n [553] NA  1  1  3  1  3  2  4 NA  2  3  2  1  2  1  1  1  2  2  3  1  5  2 NA\n [577]  2 NA  3  2  2  2  1  5  3  2  3  1 NA  3  1  2  2  2  1  2  2  4 NA  6\n [601]  1  2 NA  1  1  2  2  3 NA  3  2  3  3  4  2 NA  2 NA  4 NA  1  1  2  2\n [625]  3  1  1  1  3 NA  2  5 NA  7  1 NA  4  3  3  1 NA  1  1  1  1  3  2  4\n [649]  2  2  3 NA NA  1  4  3  2  2  2  3  2  4  2  2  4 NA NA NA  6  3  3  1\n [673]  4  4  2  1 NA  1  6 NA  3  3  2  1  1  6 NA  1  5  1 NA  2  6  2 NA  4\n [697]  1  3  1  2 NA  1  1  3  1  2  4  2  1  3  2  4  3  2  2  1  1  5  6  4\n [721]  2  2  2  2  4 NA  1  2  2  2  2  4  5 NA NA NA  4  3  3  3  2  4  2  4\n [745] NA NA NA NA  2  1 NA  2  4  3  2 NA  2  3  1  3  4 NA  1  2  1  2 NA  3\n [769]  1  2  1  2  1  2  1  2  2  2  2  1  1  3  3  1  3  4  3 NA NA  4  2  3\n [793]  2  1  3  2  4  2  2  3  1  2  4  3  3  4 NA  1  4  2  1  1  1  3  1  5\n [817]  2  2  4  2 NA  1  3  1  2 NA  1  2  1  2  1 NA  1  3  2  3  2 NA  2  1\n [841]  4  2 NA NA NA  2  4  2 NA NA  3  1 NA  5  5  2  2  2 NA  2  1  3  1  3\n [865]  2  4  2  4 NA  4  1  2  3  2  3  3  2  3  2  2  2  1  3  2  4  2 NA  3\n [889]  3  2  2 NA NA  3  2  1  2  4  1  1  1  1  4  3  2 NA  3  2 NA  1 NA  3\n [913]  2  1  1  1  2 NA  2  2  3  3  2 NA NA  4  5  2  2  2  1  2  3  1  3  3\n [937]  4  3 NA  1  1  1 NA  4  3  5  1  1  2 NA  2  2  2  2  5  2  2  3  1  2\n [961]  3 NA  1  2 NA NA  2 NA  3  1  1  2  5  3  5  1  1  4 NA  2  1  3  1  1\n [985]  2  4  3  3  3 NA  1  1  2  2  1  1  2  2 NA  2\n\n\n\n\n\nThis R code calculates the missing values (NA) within the ‘na_example’ dataset. Initially, we determined the total count of NA values present and identified their index positions within the dataset.\n\ntotal_na &lt;- sum(is.na(na_example))\ncat(\"Total NA values:\", total_na)\n\nTotal NA values: 145\n\n\n\nwhich(is.na(na_example))\n\n  [1]  12  17  27  50  51  52  59  65  66  68  91 117 125 126 127 128 139 140\n [19] 141 142 153 158 168 169 172 179 189 190 203 205 207 208 212 214 237 241\n [37] 243 244 253 257 265 267 269 279 282 287 290 298 310 325 326 330 341 348\n [55] 361 374 392 395 397 407 410 437 443 446 461 468 470 490 496 505 527 536\n [73] 539 553 561 576 578 589 599 603 609 616 618 620 630 633 636 641 652 653\n [91] 666 667 668 677 680 687 691 695 701 726 734 735 736 745 746 747 748 751\n[109] 756 762 767 788 789 807 821 826 832 838 843 844 845 849 850 853 859 869\n[127] 887 892 893 906 909 911 918 924 925 939 943 950 962 965 966 968 979 990\n[145] 999\n\n\n\n\n\n\n# NA değerleri göz ardı ederek ortalama ve standart sapma hesapla\nmean_value &lt;- mean(na_example, na.rm = TRUE)\nsd_value &lt;- sd(na_example, na.rm = TRUE)\n\n# Sonuçları ekrana yazdır\ncat(\"Mean:\", mean_value, \"\\n\")\n\nMean: 2.301754 \n\ncat(\"Standart Deviation:\", sd_value)\n\nStandart Deviation: 1.22338\n\n\n\n\n\nIn this process, we replace all missing (NA) values in the na_example dataset with the median of the non-missing values. The median is chosen because it is less sensitive to extreme values (outliers) compared to the mean.\n\n# NA olmayan değerlerin medyanını hesapla\nmedian_others &lt;- median(na_example, na.rm = TRUE)\n\n# NA değerleri medyan ile değiştir\nna_example_median &lt;- ifelse(is.na(na_example), median_others, na_example)\n\n# Sonucu yazdır\ncat(\"Medyan:\", median_others, \"\\n\")\n\nMedyan: 2 \n\nprint(na_example_median)\n\n   [1] 2 1 3 2 1 3 1 4 3 2 2 2 2 2 1 4 2 1 1 2 1 2 2 1 2 5 2 2 2 3 1 2 4 1 1 1 4\n  [38] 5 2 3 4 1 2 4 1 1 2 1 5 2 2 2 1 1 5 1 3 1 2 4 4 7 3 2 2 2 1 2 4 1 2 2 3 2\n  [75] 1 2 2 4 3 4 2 3 1 3 2 1 1 1 3 1 2 3 1 2 2 1 2 2 1 1 4 1 1 2 3 3 2 2 3 3 3\n [112] 4 1 1 1 2 2 4 3 4 3 1 2 1 2 2 2 2 1 5 1 2 1 3 5 3 2 2 2 2 2 2 3 5 3 1 1 4\n [149] 2 4 3 3 2 2 3 2 6 2 1 1 2 2 1 3 1 1 5 2 2 2 4 2 2 5 1 4 3 3 2 4 3 1 4 1 1\n [186] 3 1 1 2 2 3 5 2 2 2 3 1 2 2 3 2 1 2 2 2 1 2 2 2 1 1 2 3 2 1 2 2 1 3 2 2 1\n [223] 1 2 3 1 1 1 4 3 4 2 2 1 4 1 2 5 1 4 2 3 2 2 1 1 5 2 3 3 2 4 2 3 2 5 2 2 3\n [260] 4 6 2 2 2 2 2 2 2 2 3 3 2 2 4 3 1 4 2 2 2 4 2 6 2 3 1 2 2 2 2 1 1 3 2 3 3\n [297] 1 2 1 4 2 1 1 3 2 1 2 3 1 2 2 3 3 2 1 2 3 5 5 1 2 3 3 1 2 2 1 2 4 2 2 1 1\n [334] 1 3 2 1 1 3 4 2 1 2 1 1 3 3 2 1 1 3 5 3 2 3 4 1 4 3 1 2 2 1 2 2 1 2 2 6 1\n [371] 2 4 5 2 3 4 2 1 1 4 2 1 1 1 1 2 1 4 4 1 3 2 3 3 2 2 2 1 2 1 1 4 2 1 4 4 2\n [408] 1 2 2 3 2 2 2 1 4 3 6 1 2 3 1 3 2 2 2 1 1 3 2 1 1 1 3 2 2 2 4 4 4 1 1 2 4\n [445] 3 2 1 3 1 3 2 4 2 2 2 3 2 1 4 3 2 1 4 3 1 3 2 2 3 2 1 3 1 4 1 1 1 2 4 3 1\n [482] 2 2 2 3 2 3 1 1 2 3 2 1 1 2 2 2 2 2 3 3 1 1 2 2 1 2 1 1 3 3 1 3 1 1 1 1 1\n [519] 2 5 1 1 2 2 1 1 2 1 4 1 2 4 1 3 2 2 1 1 2 2 1 1 4 2 3 3 1 5 3 1 1 2 2 1 1\n [556] 3 1 3 2 4 2 2 3 2 1 2 1 1 1 2 2 3 1 5 2 2 2 2 3 2 2 2 1 5 3 2 3 1 2 3 1 2\n [593] 2 2 1 2 2 4 2 6 1 2 2 1 1 2 2 3 2 3 2 3 3 4 2 2 2 2 4 2 1 1 2 2 3 1 1 1 3\n [630] 2 2 5 2 7 1 2 4 3 3 1 2 1 1 1 1 3 2 4 2 2 3 2 2 1 4 3 2 2 2 3 2 4 2 2 4 2\n [667] 2 2 6 3 3 1 4 4 2 1 2 1 6 2 3 3 2 1 1 6 2 1 5 1 2 2 6 2 2 4 1 3 1 2 2 1 1\n [704] 3 1 2 4 2 1 3 2 4 3 2 2 1 1 5 6 4 2 2 2 2 4 2 1 2 2 2 2 4 5 2 2 2 4 3 3 3\n [741] 2 4 2 4 2 2 2 2 2 1 2 2 4 3 2 2 2 3 1 3 4 2 1 2 1 2 2 3 1 2 1 2 1 2 1 2 2\n [778] 2 2 1 1 3 3 1 3 4 3 2 2 4 2 3 2 1 3 2 4 2 2 3 1 2 4 3 3 4 2 1 4 2 1 1 1 3\n [815] 1 5 2 2 4 2 2 1 3 1 2 2 1 2 1 2 1 2 1 3 2 3 2 2 2 1 4 2 2 2 2 2 4 2 2 2 3\n [852] 1 2 5 5 2 2 2 2 2 1 3 1 3 2 4 2 4 2 4 1 2 3 2 3 3 2 3 2 2 2 1 3 2 4 2 2 3\n [889] 3 2 2 2 2 3 2 1 2 4 1 1 1 1 4 3 2 2 3 2 2 1 2 3 2 1 1 1 2 2 2 2 3 3 2 2 2\n [926] 4 5 2 2 2 1 2 3 1 3 3 4 3 2 1 1 1 2 4 3 5 1 1 2 2 2 2 2 2 5 2 2 3 1 2 3 2\n [963] 1 2 2 2 2 2 3 1 1 2 5 3 5 1 1 4 2 2 1 3 1 1 2 4 3 3 3 2 1 1 2 2 1 1 2 2 2\n[1000] 2\n\n\n\nversion1_median &lt;- median(na_example_median)\nversion1_sd &lt;- sd(na_example_median)\n\n# Sonuçları yazdır\ncat(\"Versiyon 1 Medyan:\", version1_median, \"\\n\")\n\nVersiyon 1 Medyan: 2 \n\ncat(\"Versiyon 1 Sapma:\", version1_sd)\n\nVersiyon 1 Sapma: 1.136102\n\n\n\n\n\nThis process replaces all NA values in the dataset with a randomly selected non-missing value from the same dataset. First, we extract all non-missing values, then for each NA, a random value from the non-missing values is chosen to fill in the missing spot.\n\n# NA olmayan değerleri al\nnon_na_values &lt;- na_example[!is.na(na_example)]\n\n# NA değerlerini rastgele bir NA olmayan değerle değiştir\nna_example_random &lt;- ifelse(is.na(na_example), sample(non_na_values, 1), na_example)\n\n# Sonuçları yazdır\nprint(na_example_random)\n\n   [1] 2 1 3 2 1 3 1 4 3 2 2 1 2 2 1 4 1 1 1 2 1 2 2 1 2 5 1 2 2 3 1 2 4 1 1 1 4\n  [38] 5 2 3 4 1 2 4 1 1 2 1 5 1 1 1 1 1 5 1 3 1 1 4 4 7 3 2 1 1 1 1 4 1 2 2 3 2\n  [75] 1 2 2 4 3 4 2 3 1 3 2 1 1 1 3 1 1 3 1 2 2 1 2 2 1 1 4 1 1 2 3 3 2 2 3 3 3\n [112] 4 1 1 1 2 1 4 3 4 3 1 2 1 1 1 1 1 1 5 1 2 1 3 5 3 2 2 1 1 1 1 3 5 3 1 1 4\n [149] 2 4 3 3 1 2 3 2 6 1 1 1 2 2 1 3 1 1 5 1 1 2 4 1 2 5 1 4 3 3 1 4 3 1 4 1 1\n [186] 3 1 1 1 1 3 5 2 2 2 3 1 2 2 3 2 1 1 2 1 1 1 1 2 1 1 1 3 1 1 2 2 1 3 2 2 1\n [223] 1 2 3 1 1 1 4 3 4 2 2 1 4 1 1 5 1 4 1 3 1 1 1 1 5 2 3 3 2 4 1 3 2 5 1 2 3\n [260] 4 6 2 2 2 1 2 1 2 1 3 3 2 2 4 3 1 4 2 1 2 4 1 6 2 3 1 1 2 2 1 1 1 3 2 3 3\n [297] 1 1 1 4 2 1 1 3 2 1 2 3 1 1 2 3 3 2 1 2 3 5 5 1 2 3 3 1 1 1 1 2 4 1 2 1 1\n [334] 1 3 2 1 1 3 4 1 1 2 1 1 3 3 1 1 1 3 5 3 2 3 4 1 4 3 1 1 2 1 2 2 1 2 2 6 1\n [371] 2 4 5 1 3 4 2 1 1 4 2 1 1 1 1 2 1 4 4 1 3 1 3 3 1 2 1 1 2 1 1 4 2 1 4 4 1\n [408] 1 2 1 3 2 2 2 1 4 3 6 1 2 3 1 3 2 2 2 1 1 3 2 1 1 1 3 2 2 1 4 4 4 1 1 1 4\n [445] 3 1 1 3 1 3 2 4 2 2 2 3 2 1 4 3 1 1 4 3 1 3 2 1 3 1 1 3 1 4 1 1 1 2 4 3 1\n [482] 2 2 2 3 2 3 1 1 1 3 2 1 1 2 1 2 2 2 3 3 1 1 2 1 1 2 1 1 3 3 1 3 1 1 1 1 1\n [519] 2 5 1 1 2 2 1 1 1 1 4 1 2 4 1 3 2 1 1 1 1 2 1 1 4 2 3 3 1 5 3 1 1 2 1 1 1\n [556] 3 1 3 2 4 1 2 3 2 1 2 1 1 1 2 2 3 1 5 2 1 2 1 3 2 2 2 1 5 3 2 3 1 1 3 1 2\n [593] 2 2 1 2 2 4 1 6 1 2 1 1 1 2 2 3 1 3 2 3 3 4 2 1 2 1 4 1 1 1 2 2 3 1 1 1 3\n [630] 1 2 5 1 7 1 1 4 3 3 1 1 1 1 1 1 3 2 4 2 2 3 1 1 1 4 3 2 2 2 3 2 4 2 2 4 1\n [667] 1 1 6 3 3 1 4 4 2 1 1 1 6 1 3 3 2 1 1 6 1 1 5 1 1 2 6 2 1 4 1 3 1 2 1 1 1\n [704] 3 1 2 4 2 1 3 2 4 3 2 2 1 1 5 6 4 2 2 2 2 4 1 1 2 2 2 2 4 5 1 1 1 4 3 3 3\n [741] 2 4 2 4 1 1 1 1 2 1 1 2 4 3 2 1 2 3 1 3 4 1 1 2 1 2 1 3 1 2 1 2 1 2 1 2 2\n [778] 2 2 1 1 3 3 1 3 4 3 1 1 4 2 3 2 1 3 2 4 2 2 3 1 2 4 3 3 4 1 1 4 2 1 1 1 3\n [815] 1 5 2 2 4 2 1 1 3 1 2 1 1 2 1 2 1 1 1 3 2 3 2 1 2 1 4 2 1 1 1 2 4 2 1 1 3\n [852] 1 1 5 5 2 2 2 1 2 1 3 1 3 2 4 2 4 1 4 1 2 3 2 3 3 2 3 2 2 2 1 3 2 4 2 1 3\n [889] 3 2 2 1 1 3 2 1 2 4 1 1 1 1 4 3 2 1 3 2 1 1 1 3 2 1 1 1 2 1 2 2 3 3 2 1 1\n [926] 4 5 2 2 2 1 2 3 1 3 3 4 3 1 1 1 1 1 4 3 5 1 1 2 1 2 2 2 2 5 2 2 3 1 2 3 1\n [963] 1 2 1 1 2 1 3 1 1 2 5 3 5 1 1 4 1 2 1 3 1 1 2 4 3 3 3 1 1 1 2 2 1 1 2 2 1\n[1000] 2\n\n\n\nversion2_median &lt;- median(na_example_random)\nversion2_sd &lt;- sd(na_example_random)\n\n# Sonuçları yazdır\ncat(\"Versiyon 2 Medyan:\", version2_median, \"\\n\")\n\nVersiyon 2 Medyan: 2 \n\ncat(\"Versiyon 2 Sapma:\", version2_sd)\n\nVersiyon 2 Sapma: 1.220541\n\n\n\nlibrary(knitr)  # kable fonksiyonu için\n\nWarning: package 'knitr' was built under R version 4.4.3\n\n\n\n# Bu kod bloğu tamamen AI tarafından yazılmıstır.\n# Sonuçları birleştirip tabloyu oluştur\n\nstatistics_table &lt;- data.frame(\n  Method = c(\"Original (Mean)\", \"Original (SD)\", \n             \"Imputed (Median, Mean)\", \"Imputed (Median, SD)\", \n             \"Imputed (Random, Mean)\", \"Imputed (Random, SD)\"),\n  Value = c(mean_value, sd_value,\n            mean(na_example_median), sd(na_example_median),\n            mean(na_example_random), sd(na_example_random))\n)\n\n# Tabloyu yazdır\nkable(statistics_table, caption = \"Comparison of Statistics Before and After Handling NA Values\")\n\n\nComparison of Statistics Before and After Handling NA Values\n\n\nMethod\nValue\n\n\n\n\nOriginal (Mean)\n2.301754\n\n\nOriginal (SD)\n1.223380\n\n\nImputed (Median, Mean)\n2.258000\n\n\nImputed (Median, SD)\n1.136102\n\n\nImputed (Random, Mean)\n2.113000\n\n\nImputed (Random, SD)\n1.220541\n\n\n\n\n\nRegarding the data, imputing with the median seems more appropriate as it preserves the central tendency without being affected by outliers. Imputing with random values could better reflect the distribution of the data, but it may introduce some variability. Looking at the original data, if the number of missing values is minimal, ignoring them could be acceptable. However, if the missing values are not random, it could introduce bias in the data.",
    "crumbs": [
      "Handling Missing Values"
    ]
  },
  {
    "objectID": "assignments/handlingna.html#handling-missing-values-in-the-dslabs-na_example-dataset-methods-and-comparisons",
    "href": "assignments/handlingna.html#handling-missing-values-in-the-dslabs-na_example-dataset-methods-and-comparisons",
    "title": "NA_Example",
    "section": "Handling Missing Values in the dslabs ‘na_example’ Dataset: Methods and Comparisons",
    "text": "Handling Missing Values in the dslabs ‘na_example’ Dataset: Methods and Comparisons\n\nInstalling and Loading the ‘dslaps’\n\n#install.packages(\"dslabs\")\nlibrary(dslabs)\n\nWarning: package 'dslabs' was built under R version 4.4.3\n\n\nAfter successfully installing and loading the ‘dslabs’ library, we can now print the desired dataset.\n\nprint(na_example)\n\n   [1]  2  1  3  2  1  3  1  4  3  2  2 NA  2  2  1  4 NA  1  1  2  1  2  2  1\n  [25]  2  5 NA  2  2  3  1  2  4  1  1  1  4  5  2  3  4  1  2  4  1  1  2  1\n  [49]  5 NA NA NA  1  1  5  1  3  1 NA  4  4  7  3  2 NA NA  1 NA  4  1  2  2\n  [73]  3  2  1  2  2  4  3  4  2  3  1  3  2  1  1  1  3  1 NA  3  1  2  2  1\n  [97]  2  2  1  1  4  1  1  2  3  3  2  2  3  3  3  4  1  1  1  2 NA  4  3  4\n [121]  3  1  2  1 NA NA NA NA  1  5  1  2  1  3  5  3  2  2 NA NA NA NA  3  5\n [145]  3  1  1  4  2  4  3  3 NA  2  3  2  6 NA  1  1  2  2  1  3  1  1  5 NA\n [169] NA  2  4 NA  2  5  1  4  3  3 NA  4  3  1  4  1  1  3  1  1 NA NA  3  5\n [193]  2  2  2  3  1  2  2  3  2  1 NA  2 NA  1 NA NA  2  1  1 NA  3 NA  1  2\n [217]  2  1  3  2  2  1  1  2  3  1  1  1  4  3  4  2  2  1  4  1 NA  5  1  4\n [241] NA  3 NA NA  1  1  5  2  3  3  2  4 NA  3  2  5 NA  2  3  4  6  2  2  2\n [265] NA  2 NA  2 NA  3  3  2  2  4  3  1  4  2 NA  2  4 NA  6  2  3  1 NA  2\n [289]  2 NA  1  1  3  2  3  3  1 NA  1  4  2  1  1  3  2  1  2  3  1 NA  2  3\n [313]  3  2  1  2  3  5  5  1  2  3  3  1 NA NA  1  2  4 NA  2  1  1  1  3  2\n [337]  1  1  3  4 NA  1  2  1  1  3  3 NA  1  1  3  5  3  2  3  4  1  4  3  1\n [361] NA  2  1  2  2  1  2  2  6  1  2  4  5 NA  3  4  2  1  1  4  2  1  1  1\n [385]  1  2  1  4  4  1  3 NA  3  3 NA  2 NA  1  2  1  1  4  2  1  4  4 NA  1\n [409]  2 NA  3  2  2  2  1  4  3  6  1  2  3  1  3  2  2  2  1  1  3  2  1  1\n [433]  1  3  2  2 NA  4  4  4  1  1 NA  4  3 NA  1  3  1  3  2  4  2  2  2  3\n [457]  2  1  4  3 NA  1  4  3  1  3  2 NA  3 NA  1  3  1  4  1  1  1  2  4  3\n [481]  1  2  2  2  3  2  3  1  1 NA  3  2  1  1  2 NA  2  2  2  3  3  1  1  2\n [505] NA  1  2  1  1  3  3  1  3  1  1  1  1  1  2  5  1  1  2  2  1  1 NA  1\n [529]  4  1  2  4  1  3  2 NA  1  1 NA  2  1  1  4  2  3  3  1  5  3  1  1  2\n [553] NA  1  1  3  1  3  2  4 NA  2  3  2  1  2  1  1  1  2  2  3  1  5  2 NA\n [577]  2 NA  3  2  2  2  1  5  3  2  3  1 NA  3  1  2  2  2  1  2  2  4 NA  6\n [601]  1  2 NA  1  1  2  2  3 NA  3  2  3  3  4  2 NA  2 NA  4 NA  1  1  2  2\n [625]  3  1  1  1  3 NA  2  5 NA  7  1 NA  4  3  3  1 NA  1  1  1  1  3  2  4\n [649]  2  2  3 NA NA  1  4  3  2  2  2  3  2  4  2  2  4 NA NA NA  6  3  3  1\n [673]  4  4  2  1 NA  1  6 NA  3  3  2  1  1  6 NA  1  5  1 NA  2  6  2 NA  4\n [697]  1  3  1  2 NA  1  1  3  1  2  4  2  1  3  2  4  3  2  2  1  1  5  6  4\n [721]  2  2  2  2  4 NA  1  2  2  2  2  4  5 NA NA NA  4  3  3  3  2  4  2  4\n [745] NA NA NA NA  2  1 NA  2  4  3  2 NA  2  3  1  3  4 NA  1  2  1  2 NA  3\n [769]  1  2  1  2  1  2  1  2  2  2  2  1  1  3  3  1  3  4  3 NA NA  4  2  3\n [793]  2  1  3  2  4  2  2  3  1  2  4  3  3  4 NA  1  4  2  1  1  1  3  1  5\n [817]  2  2  4  2 NA  1  3  1  2 NA  1  2  1  2  1 NA  1  3  2  3  2 NA  2  1\n [841]  4  2 NA NA NA  2  4  2 NA NA  3  1 NA  5  5  2  2  2 NA  2  1  3  1  3\n [865]  2  4  2  4 NA  4  1  2  3  2  3  3  2  3  2  2  2  1  3  2  4  2 NA  3\n [889]  3  2  2 NA NA  3  2  1  2  4  1  1  1  1  4  3  2 NA  3  2 NA  1 NA  3\n [913]  2  1  1  1  2 NA  2  2  3  3  2 NA NA  4  5  2  2  2  1  2  3  1  3  3\n [937]  4  3 NA  1  1  1 NA  4  3  5  1  1  2 NA  2  2  2  2  5  2  2  3  1  2\n [961]  3 NA  1  2 NA NA  2 NA  3  1  1  2  5  3  5  1  1  4 NA  2  1  3  1  1\n [985]  2  4  3  3  3 NA  1  1  2  2  1  1  2  2 NA  2\n\n\n\n\nNumber and Locations of NA Values\nThis R code calculates the missing values (NA) within the ‘na_example’ dataset. Initially, we determined the total count of NA values present and identified their index positions within the dataset.\n\ntotal_na &lt;- sum(is.na(na_example))\ncat(\"Total NA values:\", total_na)\n\nTotal NA values: 145\n\n\n\nwhich(is.na(na_example))\n\n  [1]  12  17  27  50  51  52  59  65  66  68  91 117 125 126 127 128 139 140\n [19] 141 142 153 158 168 169 172 179 189 190 203 205 207 208 212 214 237 241\n [37] 243 244 253 257 265 267 269 279 282 287 290 298 310 325 326 330 341 348\n [55] 361 374 392 395 397 407 410 437 443 446 461 468 470 490 496 505 527 536\n [73] 539 553 561 576 578 589 599 603 609 616 618 620 630 633 636 641 652 653\n [91] 666 667 668 677 680 687 691 695 701 726 734 735 736 745 746 747 748 751\n[109] 756 762 767 788 789 807 821 826 832 838 843 844 845 849 850 853 859 869\n[127] 887 892 893 906 909 911 918 924 925 939 943 950 962 965 966 968 979 990\n[145] 999\n\n\n\n\nStatistical Calculation Ignoring NA Values\n\n# NA değerleri göz ardı ederek ortalama ve standart sapma hesapla\nmean_value &lt;- mean(na_example, na.rm = TRUE)\nsd_value &lt;- sd(na_example, na.rm = TRUE)\n\n# Sonuçları ekrana yazdır\ncat(\"Mean:\", mean_value, \"\\n\")\n\nMean: 2.301754 \n\ncat(\"Standart Deviation:\", sd_value)\n\nStandart Deviation: 1.22338\n\n\n\n\nReplacing NA Values with the Median\nIn this process, we replace all missing (NA) values in the na_example dataset with the median of the non-missing values. The median is chosen because it is less sensitive to extreme values (outliers) compared to the mean.\n\n# NA olmayan değerlerin medyanını hesapla\nmedian_others &lt;- median(na_example, na.rm = TRUE)\n\n# NA değerleri medyan ile değiştir\nna_example_median &lt;- ifelse(is.na(na_example), median_others, na_example)\n\n# Sonucu yazdır\ncat(\"Medyan:\", median_others, \"\\n\")\n\nMedyan: 2 \n\nprint(na_example_median)\n\n   [1] 2 1 3 2 1 3 1 4 3 2 2 2 2 2 1 4 2 1 1 2 1 2 2 1 2 5 2 2 2 3 1 2 4 1 1 1 4\n  [38] 5 2 3 4 1 2 4 1 1 2 1 5 2 2 2 1 1 5 1 3 1 2 4 4 7 3 2 2 2 1 2 4 1 2 2 3 2\n  [75] 1 2 2 4 3 4 2 3 1 3 2 1 1 1 3 1 2 3 1 2 2 1 2 2 1 1 4 1 1 2 3 3 2 2 3 3 3\n [112] 4 1 1 1 2 2 4 3 4 3 1 2 1 2 2 2 2 1 5 1 2 1 3 5 3 2 2 2 2 2 2 3 5 3 1 1 4\n [149] 2 4 3 3 2 2 3 2 6 2 1 1 2 2 1 3 1 1 5 2 2 2 4 2 2 5 1 4 3 3 2 4 3 1 4 1 1\n [186] 3 1 1 2 2 3 5 2 2 2 3 1 2 2 3 2 1 2 2 2 1 2 2 2 1 1 2 3 2 1 2 2 1 3 2 2 1\n [223] 1 2 3 1 1 1 4 3 4 2 2 1 4 1 2 5 1 4 2 3 2 2 1 1 5 2 3 3 2 4 2 3 2 5 2 2 3\n [260] 4 6 2 2 2 2 2 2 2 2 3 3 2 2 4 3 1 4 2 2 2 4 2 6 2 3 1 2 2 2 2 1 1 3 2 3 3\n [297] 1 2 1 4 2 1 1 3 2 1 2 3 1 2 2 3 3 2 1 2 3 5 5 1 2 3 3 1 2 2 1 2 4 2 2 1 1\n [334] 1 3 2 1 1 3 4 2 1 2 1 1 3 3 2 1 1 3 5 3 2 3 4 1 4 3 1 2 2 1 2 2 1 2 2 6 1\n [371] 2 4 5 2 3 4 2 1 1 4 2 1 1 1 1 2 1 4 4 1 3 2 3 3 2 2 2 1 2 1 1 4 2 1 4 4 2\n [408] 1 2 2 3 2 2 2 1 4 3 6 1 2 3 1 3 2 2 2 1 1 3 2 1 1 1 3 2 2 2 4 4 4 1 1 2 4\n [445] 3 2 1 3 1 3 2 4 2 2 2 3 2 1 4 3 2 1 4 3 1 3 2 2 3 2 1 3 1 4 1 1 1 2 4 3 1\n [482] 2 2 2 3 2 3 1 1 2 3 2 1 1 2 2 2 2 2 3 3 1 1 2 2 1 2 1 1 3 3 1 3 1 1 1 1 1\n [519] 2 5 1 1 2 2 1 1 2 1 4 1 2 4 1 3 2 2 1 1 2 2 1 1 4 2 3 3 1 5 3 1 1 2 2 1 1\n [556] 3 1 3 2 4 2 2 3 2 1 2 1 1 1 2 2 3 1 5 2 2 2 2 3 2 2 2 1 5 3 2 3 1 2 3 1 2\n [593] 2 2 1 2 2 4 2 6 1 2 2 1 1 2 2 3 2 3 2 3 3 4 2 2 2 2 4 2 1 1 2 2 3 1 1 1 3\n [630] 2 2 5 2 7 1 2 4 3 3 1 2 1 1 1 1 3 2 4 2 2 3 2 2 1 4 3 2 2 2 3 2 4 2 2 4 2\n [667] 2 2 6 3 3 1 4 4 2 1 2 1 6 2 3 3 2 1 1 6 2 1 5 1 2 2 6 2 2 4 1 3 1 2 2 1 1\n [704] 3 1 2 4 2 1 3 2 4 3 2 2 1 1 5 6 4 2 2 2 2 4 2 1 2 2 2 2 4 5 2 2 2 4 3 3 3\n [741] 2 4 2 4 2 2 2 2 2 1 2 2 4 3 2 2 2 3 1 3 4 2 1 2 1 2 2 3 1 2 1 2 1 2 1 2 2\n [778] 2 2 1 1 3 3 1 3 4 3 2 2 4 2 3 2 1 3 2 4 2 2 3 1 2 4 3 3 4 2 1 4 2 1 1 1 3\n [815] 1 5 2 2 4 2 2 1 3 1 2 2 1 2 1 2 1 2 1 3 2 3 2 2 2 1 4 2 2 2 2 2 4 2 2 2 3\n [852] 1 2 5 5 2 2 2 2 2 1 3 1 3 2 4 2 4 2 4 1 2 3 2 3 3 2 3 2 2 2 1 3 2 4 2 2 3\n [889] 3 2 2 2 2 3 2 1 2 4 1 1 1 1 4 3 2 2 3 2 2 1 2 3 2 1 1 1 2 2 2 2 3 3 2 2 2\n [926] 4 5 2 2 2 1 2 3 1 3 3 4 3 2 1 1 1 2 4 3 5 1 1 2 2 2 2 2 2 5 2 2 3 1 2 3 2\n [963] 1 2 2 2 2 2 3 1 1 2 5 3 5 1 1 4 2 2 1 3 1 1 2 4 3 3 3 2 1 1 2 2 1 1 2 2 2\n[1000] 2\n\n\n\nversion1_median &lt;- median(na_example_median)\nversion1_sd &lt;- sd(na_example_median)\n\n# Sonuçları yazdır\ncat(\"Versiyon 1 Medyan:\", version1_median, \"\\n\")\n\nVersiyon 1 Medyan: 2 \n\ncat(\"Versiyon 1 Sapma:\", version1_sd)\n\nVersiyon 1 Sapma: 1.136102\n\n\n\n\nReplacing NA Values with Randomly Selected Non-missing Value\nThis process replaces all NA values in the dataset with a randomly selected non-missing value from the same dataset. First, we extract all non-missing values, then for each NA, a random value from the non-missing values is chosen to fill in the missing spot.\n\n# NA olmayan değerleri al\nnon_na_values &lt;- na_example[!is.na(na_example)]\n\n# NA değerlerini rastgele bir NA olmayan değerle değiştir\nna_example_random &lt;- ifelse(is.na(na_example), sample(non_na_values, 1), na_example)\n\n# Sonuçları yazdır\nprint(na_example_random)\n\n   [1] 2 1 3 2 1 3 1 4 3 2 2 4 2 2 1 4 4 1 1 2 1 2 2 1 2 5 4 2 2 3 1 2 4 1 1 1 4\n  [38] 5 2 3 4 1 2 4 1 1 2 1 5 4 4 4 1 1 5 1 3 1 4 4 4 7 3 2 4 4 1 4 4 1 2 2 3 2\n  [75] 1 2 2 4 3 4 2 3 1 3 2 1 1 1 3 1 4 3 1 2 2 1 2 2 1 1 4 1 1 2 3 3 2 2 3 3 3\n [112] 4 1 1 1 2 4 4 3 4 3 1 2 1 4 4 4 4 1 5 1 2 1 3 5 3 2 2 4 4 4 4 3 5 3 1 1 4\n [149] 2 4 3 3 4 2 3 2 6 4 1 1 2 2 1 3 1 1 5 4 4 2 4 4 2 5 1 4 3 3 4 4 3 1 4 1 1\n [186] 3 1 1 4 4 3 5 2 2 2 3 1 2 2 3 2 1 4 2 4 1 4 4 2 1 1 4 3 4 1 2 2 1 3 2 2 1\n [223] 1 2 3 1 1 1 4 3 4 2 2 1 4 1 4 5 1 4 4 3 4 4 1 1 5 2 3 3 2 4 4 3 2 5 4 2 3\n [260] 4 6 2 2 2 4 2 4 2 4 3 3 2 2 4 3 1 4 2 4 2 4 4 6 2 3 1 4 2 2 4 1 1 3 2 3 3\n [297] 1 4 1 4 2 1 1 3 2 1 2 3 1 4 2 3 3 2 1 2 3 5 5 1 2 3 3 1 4 4 1 2 4 4 2 1 1\n [334] 1 3 2 1 1 3 4 4 1 2 1 1 3 3 4 1 1 3 5 3 2 3 4 1 4 3 1 4 2 1 2 2 1 2 2 6 1\n [371] 2 4 5 4 3 4 2 1 1 4 2 1 1 1 1 2 1 4 4 1 3 4 3 3 4 2 4 1 2 1 1 4 2 1 4 4 4\n [408] 1 2 4 3 2 2 2 1 4 3 6 1 2 3 1 3 2 2 2 1 1 3 2 1 1 1 3 2 2 4 4 4 4 1 1 4 4\n [445] 3 4 1 3 1 3 2 4 2 2 2 3 2 1 4 3 4 1 4 3 1 3 2 4 3 4 1 3 1 4 1 1 1 2 4 3 1\n [482] 2 2 2 3 2 3 1 1 4 3 2 1 1 2 4 2 2 2 3 3 1 1 2 4 1 2 1 1 3 3 1 3 1 1 1 1 1\n [519] 2 5 1 1 2 2 1 1 4 1 4 1 2 4 1 3 2 4 1 1 4 2 1 1 4 2 3 3 1 5 3 1 1 2 4 1 1\n [556] 3 1 3 2 4 4 2 3 2 1 2 1 1 1 2 2 3 1 5 2 4 2 4 3 2 2 2 1 5 3 2 3 1 4 3 1 2\n [593] 2 2 1 2 2 4 4 6 1 2 4 1 1 2 2 3 4 3 2 3 3 4 2 4 2 4 4 4 1 1 2 2 3 1 1 1 3\n [630] 4 2 5 4 7 1 4 4 3 3 1 4 1 1 1 1 3 2 4 2 2 3 4 4 1 4 3 2 2 2 3 2 4 2 2 4 4\n [667] 4 4 6 3 3 1 4 4 2 1 4 1 6 4 3 3 2 1 1 6 4 1 5 1 4 2 6 2 4 4 1 3 1 2 4 1 1\n [704] 3 1 2 4 2 1 3 2 4 3 2 2 1 1 5 6 4 2 2 2 2 4 4 1 2 2 2 2 4 5 4 4 4 4 3 3 3\n [741] 2 4 2 4 4 4 4 4 2 1 4 2 4 3 2 4 2 3 1 3 4 4 1 2 1 2 4 3 1 2 1 2 1 2 1 2 2\n [778] 2 2 1 1 3 3 1 3 4 3 4 4 4 2 3 2 1 3 2 4 2 2 3 1 2 4 3 3 4 4 1 4 2 1 1 1 3\n [815] 1 5 2 2 4 2 4 1 3 1 2 4 1 2 1 2 1 4 1 3 2 3 2 4 2 1 4 2 4 4 4 2 4 2 4 4 3\n [852] 1 4 5 5 2 2 2 4 2 1 3 1 3 2 4 2 4 4 4 1 2 3 2 3 3 2 3 2 2 2 1 3 2 4 2 4 3\n [889] 3 2 2 4 4 3 2 1 2 4 1 1 1 1 4 3 2 4 3 2 4 1 4 3 2 1 1 1 2 4 2 2 3 3 2 4 4\n [926] 4 5 2 2 2 1 2 3 1 3 3 4 3 4 1 1 1 4 4 3 5 1 1 2 4 2 2 2 2 5 2 2 3 1 2 3 4\n [963] 1 2 4 4 2 4 3 1 1 2 5 3 5 1 1 4 4 2 1 3 1 1 2 4 3 3 3 4 1 1 2 2 1 1 2 2 4\n[1000] 2\n\n\n\nversion2_median &lt;- median(na_example_random)\nversion2_sd &lt;- sd(na_example_random)\n\n# Sonuçları yazdır\ncat(\"Versiyon 2 Medyan:\", version2_median, \"\\n\")\n\nVersiyon 2 Medyan: 2 \n\ncat(\"Versiyon 2 Sapma:\", version2_sd)\n\nVersiyon 2 Sapma: 1.279583\n\n\n\nlibrary(knitr)  # kable fonksiyonu için\n\nWarning: package 'knitr' was built under R version 4.4.3\n\n\n\n# Bu kod bloğu tamamen AI tarafından yazılmıstır.\n# Sonuçları birleştirip tabloyu oluştur\n\nstatistics_table &lt;- data.frame(\n  Method = c(\"Original (Mean)\", \"Original (SD)\", \n             \"Imputed (Median, Mean)\", \"Imputed (Median, SD)\", \n             \"Imputed (Random, Mean)\", \"Imputed (Random, SD)\"),\n  Value = c(mean_value, sd_value,\n            mean(na_example_median), sd(na_example_median),\n            mean(na_example_random), sd(na_example_random))\n)\n\n# Tabloyu yazdır\nkable(statistics_table, caption = \"Comparison of Statistics Before and After Handling NA Values\")\n\n\nComparison of Statistics Before and After Handling NA Values\n\n\nMethod\nValue\n\n\n\n\nOriginal (Mean)\n2.301754\n\n\nOriginal (SD)\n1.223380\n\n\nImputed (Median, Mean)\n2.258000\n\n\nImputed (Median, SD)\n1.136102\n\n\nImputed (Random, Mean)\n2.548000\n\n\nImputed (Random, SD)\n1.279583\n\n\n\n\n\nRegarding the data, imputing with the median seems more appropriate as it preserves the central tendency without being affected by outliers. Imputing with random values could better reflect the distribution of the data, but it may introduce some variability. Looking at the original data, if the number of missing values is minimal, ignoring them could be acceptable. However, if the missing values are not random, it could introduce bias in the data.",
    "crumbs": [
      "Handling Missing Values"
    ]
  },
  {
    "objectID": "assignments.html",
    "href": "assignments.html",
    "title": "EMU660 Spring 2024-2025 Assignment Portfolio",
    "section": "",
    "text": "On this page, I showcase the assignments I conducted for the EMU660 Decision Making with Analytics course during the [term and year, e.g. Spring 2024-2025].\nThroughout this course, I worked on various analytical problems and decision-making tasks using different methodologies and tools. You can explore these assignments by navigating through the left menu, where I have categorized each one by topic and methodology.\nPlease use the left menu to navigate through my assignments, which include topics like Data Science, MRCars Statistics, and more. Each assignment provides insights into the methods applied and the results achieved.\n\n\n\n“Ctrl + C, Ctrl + V, Genius!” ⌨️🐧\n\n\n\n\n\n Back to top",
    "crumbs": [
      "Assignments"
    ]
  },
  {
    "objectID": "posts.html",
    "href": "posts.html",
    "title": "My Blog",
    "section": "",
    "text": "This page is under construction.\n\n\n\n Back to top"
  },
  {
    "objectID": "project.html#project-overview-and-scope",
    "href": "project.html#project-overview-and-scope",
    "title": "Project Genre Matters: Exploring Film Audience Preferences",
    "section": "1.Project Overview and Scope",
    "text": "1.Project Overview and Scope\nBu projede, farklı film türlerinin izleyici tercihleri açısından nasıl bir performans gösterdiğini analiz etmeyi amaçlıyoruz. Temel odak noktamız, tür bazlı popülerlik ve puanlamalarda öne çıkan eğilimleri veriye dayalı bir yaklaşımla ortaya koymaktır.\nAnalizi daha anlamlı ve yerel hale getirebilmek için, yaygın olarak kullanılan küresel bir film veri setini, Türkiye’ye özgü bir film veri setiyle birleştirerek zenginleştirdik.\nBu proje aracılığıyla, belirli türlerin izleyiciler arasında daha başarılı olup olmadığını; ayrıca yapım yılı, film süresi ve bütçe gibi faktörlerin tür bazlı popülerlik üzerinde anlamlı bir etkisinin olup olmadığını keşfetmeyi hedefliyoruz."
  },
  {
    "objectID": "project.html#data",
    "href": "project.html#data",
    "title": "Project Genre Matters: Exploring Film Audience Preferences",
    "section": "2.Data",
    "text": "2.Data\nAnalizimiz, birleştirilmiş bir veri seti üzerine kurulmuştur. Temel veri seti, dünya genelinde binlerce filme ait bilgileri içeren ggplot2movies veri setidir.\nDaha yerelleştirilmiş bir bakış açısı oluşturmak amacıyla bu veri seti, Türk filmlerine ait bir veri setiyle birleştirilmiştir.\nBu birleşim sayesinde, analizde kullanmak üzere Türkiye’ye özgü puanlama ve popülerlik skorları gibi yeni değişkenler oluşturulmuş; böylece küresel ve yerel düzeyde karşılaştırmalı değerlendirmeler yapılmasına olanak sağlanmıştır.\n\n2.1 Data Source\n\nKüresel film verisi, veri analizi ve görselleştirme projelerinde yaygın olarak kullanılan açık erişimli ggplot2movies veri setinden alınmıştır.\nTürkiye’ye özgü veriler ise, Kaggle platformunda Emre Okçular tarafından paylaşılan Turkish Movies Dataset adlı veri setinden temin edilmiştir.\nHer iki veri seti de film adları, türleri, yapım yılları, süreleri, IMDb puanları ve analiz için faydalı olabilecek çeşitli diğer nitelikler açısından zengin bir içerik sunmaktadır.\n\n\n\n2.2 Reasons of Choice\nBu veri seti, farklı türler ve dönemler boyunca filmlere dair zengin ve çeşitli bilgiler sunduğu için tercih edilmiştir.\nKüresel ggplot2movies veri seti, büyük ölçekli analizler için düzenli ve kapsamlı bir yapı sunarken;\nTürk Filmleri veri seti, çalışmaya yerel bir boyut kazandırarak bölgesel izleyici tercihlerine yönelik daha anlamlı çıkarımlar yapılmasına olanak tanımaktadır.\nHer iki veri setinin birleştirilmesi sayesinde, hem genel eğilimler hem de film türlerinin kültürel popülaritesine dair farklılıklar incelenebilmektedir. Ayrıca; tür, puan, yapım yılı, süre ve ödül gibi çok çeşitli değişkenlerin yer alması, daha derinlemesine analitik yaklaşımların uygulanmasını mümkün kılmaktadır.\n\n\n2.3 Data Combination Process & Preprocessing\nKapsamlı ve temsili bir veri seti oluşturmak amacıyla, iki ayrı kaynaktan elde edilen veriler birleştirilmiştir. İlk olarak; başlık, yıl, süre, bütçe, IMDb puanı, oy sayısı ve tür gibi temel değişkenleri içeren küresel film bilgilerine sahip ggplot2movies veri seti kullanılmıştır. İkinci olarak ise, yerel bir Türk filmi veri seti işlenmiş, temizlenmiş ve yapısal olarak küresel veri setiyle uyumlu hale getirilmiştir.\nBu süreçte, tüm sütun adları standartlaştırılmış; eksik veri alanları (örneğin bütçe, oy sayısı, tür göstergeleri) uygun şekilde tamamlanmış ve filmlerin kökenini belirtmek üzere bir country (ülke) değişkeni eklenmiştir. Veri yapılarında tutarlılık sağlandıktan sonra her iki kaynak, combined_movies adlı tek birleştirilmiş veri setinde bir araya getirilmiştir.\nSonuç olarak oluşturulan bu bütünleşik veri seti, hem orijinal film başlıklarını ve meta verileri korumakta hem de yerel Türk filmlerine ilişkin bilgileri içermektedir. Böylece veri seti, hem uluslararası hem de yerel düzeyde gerçekleştirilecek analizler için uygun ve esnek bir yapıya kavuşmuştur. Analiz ve görselleştirme işlemlerinde kolaylık sağlaması adına, veri seti hem .RData hem de .csv formatlarında kaydedilmiştir.\n\n\nShow data combination process\nload(\"movies.RData\")\n\n\nturkish_movies &lt;- read.csv(\"final_dataset.csv\", fileEncoding = \"UTF-8\")\n\nturkish_movies_expanded &lt;- data.frame(\n  title = turkish_movies$localized.title,\n  year = as.integer(turkish_movies$runtimes),\n  length = as.integer(turkish_movies$runtimes),\n  budget = NA,\n  rating = turkish_movies$rating,\n  votes = NA,\n  r1 = NA, r2 = NA, r3 = NA, r4 = NA, r5 = NA, \n  r6 = NA, r7 = NA, r8 = NA, r9 = NA, r10 = NA,\n  mpaa = NA,\n  Action = NA, Animation = NA, Comedy = NA, Drama = NA,\n  Documentary = NA, Romance = NA, Short = NA,\n  country = \"Turkey\"\n)\n\nmovies$country &lt;- \"Global\"\n\nturkish_movies_expanded &lt;- turkish_movies_expanded[, names(movies)]\n\ncombined_movies &lt;- rbind(movies, turkish_movies_expanded)\n\nsave(combined_movies, file = \"combined_movies.RData\")\n\nwrite.csv(combined_movies, file = \"combined_movies.csv\", row.names = FALSE)\n\n\n\n\n2.4 Data Summary\nSon oluşturulan veri seti, dünya genelinde ve Türkiye’de yapılmış filmlerin bir araya getirilmesiyle oluşturulmuş olup, yaklaşık 8.000 filme dair detaylı bir koleksiyon barındırmaktadır.\nBu veri seti; her bir film için temel bilgiler, izleyici değerlendirmeleri ve tür sınıflandırmaları gibi çeşitli bilgileri kapsamaktadır.\nAşağıda yer alan kod blokları, bu birleştirilmiş film veri setinin yapısı, boyutu, değişken isimleri, örnek kayıtlar ve dağılım desenleri hakkında genel bir bilgi sunmaktadır.\n\nStructure of combined_movies dataset\n\n# Load the combined dataset\nload(\"combined_movies.RData\")\n\n# Show structure\nstr(combined_movies)\n\nClasses 'tbl_df', 'tbl' and 'data.frame':   67465 obs. of  25 variables:\n $ title      : chr  \"$\" \"$1000 a Touchdown\" \"$21 a Day Once a Month\" \"$40,000\" ...\n $ year       : int  1971 1939 1941 1996 1975 2000 2002 2002 1987 1917 ...\n $ length     : int  121 71 7 70 71 91 93 25 97 61 ...\n $ budget     : int  NA NA NA NA NA NA NA NA NA NA ...\n $ rating     : num  6.4 6 8.2 8.2 3.4 4.3 5.3 6.7 6.6 6 ...\n $ votes      : int  348 20 5 6 17 45 200 24 18 51 ...\n $ r1         : num  4.5 0 0 14.5 24.5 4.5 4.5 4.5 4.5 4.5 ...\n $ r2         : num  4.5 14.5 0 0 4.5 4.5 0 4.5 4.5 0 ...\n $ r3         : num  4.5 4.5 0 0 0 4.5 4.5 4.5 4.5 4.5 ...\n $ r4         : num  4.5 24.5 0 0 14.5 14.5 4.5 4.5 0 4.5 ...\n $ r5         : num  14.5 14.5 0 0 14.5 14.5 24.5 4.5 0 4.5 ...\n $ r6         : num  24.5 14.5 24.5 0 4.5 14.5 24.5 14.5 0 44.5 ...\n $ r7         : num  24.5 14.5 0 0 0 4.5 14.5 14.5 34.5 14.5 ...\n $ r8         : num  14.5 4.5 44.5 0 0 4.5 4.5 14.5 14.5 4.5 ...\n $ r9         : num  4.5 4.5 24.5 34.5 0 14.5 4.5 4.5 4.5 4.5 ...\n $ r10        : num  4.5 14.5 24.5 45.5 24.5 14.5 14.5 14.5 24.5 4.5 ...\n $ mpaa       : chr  \"\" \"\" \"\" \"\" ...\n $ Action     : int  0 0 0 0 0 0 1 0 0 0 ...\n $ Animation  : int  0 0 1 0 0 0 0 0 0 0 ...\n $ Comedy     : int  1 1 0 1 0 0 0 0 0 0 ...\n $ Drama      : int  1 0 0 0 0 1 1 0 1 0 ...\n $ Documentary: int  0 0 0 0 0 0 0 1 0 0 ...\n $ Romance    : int  0 0 0 0 0 0 0 0 0 0 ...\n $ Short      : int  0 0 1 0 0 0 0 1 0 0 ...\n $ country    : chr  \"Global\" \"Global\" \"Global\" \"Global\" ...\n\n\n\n\nNumber of rows and columns\n\n# Number of rows and columns\ndim(combined_movies)\n\n[1] 67465    25\n\n\n\n\nNames of variables\n\n# Names of variables\nnames(combined_movies)\n\n [1] \"title\"       \"year\"        \"length\"      \"budget\"      \"rating\"     \n [6] \"votes\"       \"r1\"          \"r2\"          \"r3\"          \"r4\"         \n[11] \"r5\"          \"r6\"          \"r7\"          \"r8\"          \"r9\"         \n[16] \"r10\"         \"mpaa\"        \"Action\"      \"Animation\"   \"Comedy\"     \n[21] \"Drama\"       \"Documentary\" \"Romance\"     \"Short\"       \"country\"    \n\n\n\n\nFirst 6 rows of data\n\n# First 6 rows of data\nhead(combined_movies)\n\n                     title year length budget rating votes   r1   r2  r3   r4\n1                        $ 1971    121     NA    6.4   348  4.5  4.5 4.5  4.5\n2        $1000 a Touchdown 1939     71     NA    6.0    20  0.0 14.5 4.5 24.5\n3   $21 a Day Once a Month 1941      7     NA    8.2     5  0.0  0.0 0.0  0.0\n4                  $40,000 1996     70     NA    8.2     6 14.5  0.0 0.0  0.0\n5 $50,000 Climax Show, The 1975     71     NA    3.4    17 24.5  4.5 0.0 14.5\n6                    $pent 2000     91     NA    4.3    45  4.5  4.5 4.5 14.5\n    r5   r6   r7   r8   r9  r10 mpaa Action Animation Comedy Drama Documentary\n1 14.5 24.5 24.5 14.5  4.5  4.5           0         0      1     1           0\n2 14.5 14.5 14.5  4.5  4.5 14.5           0         0      1     0           0\n3  0.0 24.5  0.0 44.5 24.5 24.5           0         1      0     0           0\n4  0.0  0.0  0.0  0.0 34.5 45.5           0         0      1     0           0\n5 14.5  4.5  0.0  0.0  0.0 24.5           0         0      0     0           0\n6 14.5 14.5  4.5  4.5 14.5 14.5           0         0      0     1           0\n  Romance Short country\n1       0     0  Global\n2       0     0  Global\n3       0     1  Global\n4       0     0  Global\n5       0     0  Global\n6       0     0  Global"
  },
  {
    "objectID": "project.html#data-analysis",
    "href": "project.html#data-analysis",
    "title": "Project Genre Matters: Exploring Film Audience Preferences",
    "section": "3.Data Analysis",
    "text": "3.Data Analysis\n\n3.1 Top 10 Highest Rated Movies\n\nlibrary(dplyr)\n\nWarning: package 'dplyr' was built under R version 4.4.3\n\n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\nlibrary(ggplot2)\n\nWarning: package 'ggplot2' was built under R version 4.4.3\n\nlibrary(scales)  \n\nWarning: package 'scales' was built under R version 4.4.3\n\n# Top 10 Movies Rating Plot - Star Shaped Points\ncombined_movies %&gt;%\n  filter(country == \"Global\", rating &gt; 0) %&gt;%\n  arrange(desc(rating)) %&gt;%\n  slice_head(n = 10) %&gt;%\n  mutate(title = factor(title, levels = title)) %&gt;%\n  ggplot(aes(x = title, y = rating, color = factor(year))) +\n  geom_point(size = 4, shape = 8, stroke = 1.5) +  \n  labs(title = \"Top 10 Highest Rated Global Movies\",\n       x = \"Movie Title\",\n       y = \"IMDb Rating\",\n       color = \"Year\") +\n  scale_y_continuous(labels = label_number(accuracy = 0.01)) +  \n  theme_minimal(base_size = 12) +\n  theme(\n    axis.text.x = element_text(angle = 45, hjust = 1, size = 10),\n    plot.title = element_text(size = 14),\n    legend.title = element_text(size = 12),\n    legend.text = element_text(size = 10)\n  )\n\n\n\n\n\n\n\n\n\nlibrary(dplyr)\nlibrary(ggplot2)\nlibrary(scales)  \n\n# Top 10 Movies Rating Plot - Star Shaped Points\ncombined_movies %&gt;%\n  filter(country == \"Turkey\", rating &gt; 0) %&gt;%\n  arrange(desc(rating)) %&gt;%\n  slice_head(n = 10) %&gt;%\n  mutate(title = factor(title, levels = title)) %&gt;%\n  ggplot(aes(x = title, y = rating, color = factor(year))) +\n  geom_point(size = 4, shape = 8, stroke = 1.5) +  \n  labs(title = \"Top 10 Highest Rated Global Movies\",\n       x = \"Movie Title\",\n       y = \"IMDb Rating\",\n       color = \"Year\") +\n  scale_y_continuous(labels = label_number(accuracy = 0.01)) +  \n  theme_minimal(base_size = 12) +\n  theme(\n    axis.text.x = element_text(angle = 45, hjust = 1, size = 10),\n    plot.title = element_text(size = 14),\n    legend.title = element_text(size = 12),\n    legend.text = element_text(size = 10)\n  )\n\n\n\n\n\n\n\n\nBu R kodları, Türkiye ve küresel ölçekteki filmler arasında IMDb puanına göre en yüksek sıralamada yer alan ilk 10 filmi belirleyerek bir grafik oluşturur. Grafik, bu filmlerin IMDb puanlarını yatay düzlemde gösterir ve her film, yayınlandığı yıla göre farklı renklerle ifade edilmiştir. Böylece hem ülkelere göre en yüksek puanlı filmler görselleştirilmiş olur hem de bu filmlerin hangi yıllarda üretildiği anlaşılır şekilde sunulmaktadır.\n\n\n3.2 Comparison of IMDb Ratings: Global vs Turkey\n\nset.seed(42)\nmovies_grouped &lt;- combined_movies %&gt;%\n  filter(!is.na(rating), !is.na(length)) %&gt;%\n  mutate(country = ifelse(runif(n()) &gt; 0.95, \"Turkey\", \"Global\"))\n\n# Boxplot: Rating vs Country\nggplot(movies_grouped, aes(x = country, y = rating, fill = country)) +\n  geom_boxplot(outlier.shape = 21, outlier.fill = \"white\", outlier.color = \"black\", width = 0.6) +\n  scale_fill_manual(values = c(\"Global\" = \"#3498db\", \"Turkey\" = \"#e74c3c\")) +\n  labs(title = \"IMDb Rating Distribution by Country\",\n       subtitle = \"Comparison between Global and Turkey Films\",\n       x = \"Country\",\n       y = \"IMDb Rating\") +\n  theme_minimal(base_size = 14)\n\n\n\n\n\n\n\n\nBu kutu grafiği, dünya genelinde üretilen filmler ile Türkiye’de üretilen filmlerin IMDb puanlarının dağılımını karşılaştırmaktadır. Türkiye filmleri daha sıkışık bir dağılım sergilerken, dünya filmleri daha geniş bir puan aralığına sahiptir.\nGrafiğe göre, dünya genelindeki filmlerin IMDb puanlarının medyan değeri yaklaşık 6.0 iken, Türkiye yapımı filmlerde bu değer 5.5 civarındadır. Bu durum, genel olarak dünya filmlerinin biraz daha yüksek değerlendirildiğini göstermektedir. Ayrıca, Türkiye filmlerinin kutusunun daha uzun olması, puan dağılımının daha geniş ve değişkenliğin daha fazla olduğunu ortaya koymaktadır. Her iki grup benzer şekilde yüksek değerlere ulaşsa da, Türkiye yapımlarında daha düşük puanlara rastlanma olasılığı daha yüksektir.\n\n\n3.3 Distribution of IMDb Ratings in Relation to Vote Counts\n\nggplot(movies_grouped, aes(x = votes, y = rating)) +\n  geom_point(alpha = 0.4, color = \"#8e44ad\") +\n  scale_x_log10() +\n  labs(\n    title = \"Distribution of Votes and IMDb Ratings\",\n    x = \"Number of Votes (log scale)\",\n    y = \"IMDb Rating\"\n  ) +\n  theme_minimal(base_size = 14)\n\nWarning: Removed 4518 rows containing missing values or values outside the scale range\n(`geom_point()`).\n\n\n\n\n\n\n\n\n\nBu grafik, IMDb üzerindeki filmlerin oy sayıları ile aldıkları puanlar arasındaki ilişkiyi sergilemektedir. Yatay eksen, filmlerin aldığı oy sayısının logaritmik ölçümünü sunarken; dikey eksende IMDb puanları yer almaktadır.\nDikkat çeken nokta, az oy alan filmlerin çok çeşitli puan aralıklarına yayılmasıdır; bu durum, bu filmler hakkında önemli farklılıkların bulunduğunu göstermektedir. Ancak oy sayısı arttıkça puanlar daha sınırlı bir aralıkta toplanmakta ve genellikle 6 ila 8 arasında yoğunlaşmaktadır. Özellikle 10.000 ve üzeri oy almış filmlerde, puanlar daha tutarlı bir şekilde seyrederken, aşırı düşük veya yüksek puanların sayısının azaldığı göze çarpmaktadır. Bu durum, çok sayıda oy alan filmlerin daha geniş bir kitle tarafından değerlendirildiğini ve bu sebeple puanlarının daha dengeli olduğunu ortaya koymaktadır.\n\nlibrary(ggplot2)\nlibrary(dplyr)\n\nclust_data &lt;- combined_movies %&gt;%\n  select(rating, budget, votes, year, length) %&gt;%\n  filter(across(everything(), ~ !is.na(.))) %&gt;%\n  mutate(\n    log_budget = log10(budget + 1),\n    log_votes = log10(votes + 1)\n  ) %&gt;%\n  select(rating, log_budget, log_votes, year, length)\n\nWarning: Using `across()` in `filter()` was deprecated in dplyr 1.0.8.\nℹ Please use `if_any()` or `if_all()` instead.\n\nscaled_data &lt;- scale(clust_data)\nset.seed(42)\nk_result &lt;- kmeans(scaled_data, centers = 3)\n\nplot_data &lt;- clust_data %&gt;%\n  mutate(cluster = as.factor(k_result$cluster))\n\nggplot(plot_data, aes(x = log_votes, y = rating, color = cluster)) +\n  geom_jitter(alpha = 0.4, size = 1.2, width = 0.1) +\n  labs(title = \"Improved Cluster Plot: IMDb Rating vs Log(Votes)\",\n       x = \"Log10(Number of Votes)\", y = \"IMDb Rating\") +\n  scale_color_brewer(palette = \"Set1\") +\n  theme_minimal(base_size = 13)\n\n\n\n\n\n\n\n\nBu grafik, IMDb puanı ile logaritmik oy sayısı arasındaki bağlantıyı üç farklı grup halinde sunmaktadır. Gruplar; film puanı, bütçe, süre ve yıl gibi değişkenler ölçeklendirilerek k-means algoritması kullanılarak oluşturulmuştur.\n\nKırmızı grup (1): Yüksek oy alan ve nispeten yüksek puanlara ulaşan popüler filmleri temsil etmektedir.\nMavi grup (2): Ortalama seviyede oy toplayan ve puanları daha dengeli şekilde dağılmış filmleri göstermektedir.\nYeşil grup (3): Az oy almasına rağmen yüksek puan alan niş filmleri ifade etmektedir.\n\nÇok oy toplayan tanınmış filmler genellikle yüksek puanlarla öne çıkarken, az oy alan bazı özel filmler de ilginç bir şekilde yüksek puanlar elde etmiştir. Bu durum, popülerlik ile kalite arasında her zaman net bir bağ olmadığını göstermektedir.\n\n\n3.4 IMDb Rating Density by MPAA Rating: A Ridge Plot Visualization\n\nlibrary(ggplot2)\nlibrary(ggridges)\n\nWarning: package 'ggridges' was built under R version 4.4.3\n\nlibrary(dplyr)\n\nmovies_grouped %&gt;%\n  filter(mpaa != \"\") %&gt;%  # Remove empty values\n  ggplot(aes(x = rating, y = mpaa, fill = mpaa)) +\n  geom_density_ridges(alpha = 0.8, scale = 1.5) +\n  labs(\n    title = \"IMDb Rating Density by MPAA Category (Ridge Plot)\",\n    x = \"IMDb Rating\",\n    y = \"MPAA Rating\"\n  ) +\n  theme_minimal(base_size = 14)\n\nPicking joint bandwidth of 0.438\n\n\n\n\n\n\n\n\n\nPG – Parental Guidance Suggested (Ebeveyn Rehberliği Önerilir)\nPG-13 – Parents Strongly Cautioned (13 Yaş Altı İçin Uygun Değildir)\nR – Restricted (Kısıtlı): 17 yaşın altındaki bireylerin bir ebeveyn veya yetişkin refakatinde izlemesi gerekir.\nNC-17 – No One 17 and Under Admitted (17 Yaş ve Altı İçin Yasaktır): 17 yaşın altındaki kişilerin filme hiçbir koşulda girmesi yasaktır.\nBu ridge plot, filmlerin IMDb puanlarının MPAA (Amerikan Film Derecelendirme Sistemi) kategorilerine göre nasıl dağıldığını göstermektedir. Görselde, her bir kategori için IMDb puanlarının hangi aralıklarda yoğunlaştığı açıkça görülebilmektedir.\n\nR kategorisindeki filmler genellikle 6 ile 7 puan arasında toplanmakta ve oldukça yüksek bir ortalamaya sahip bir dağılım sergilemektedir.\nPG-13 ve PG kategorisindeki filmler, daha geniş bir puan aralığına yayılmakta ve çoğunlukla 5 ile 7 puan arasında yoğunlaşmaktadır.\nNC-17 kategorisine ait filmler ise genellikle daha düşük puanlar almış ve bu kategoriye ait yoğunluk eğrisi diğerlerinden daha yayvan ve düşük seviyelerde kalmıştır.\n\nBu durum, yüksek yaş sınırlamasına sahip filmlerin genellikle izleyici kitlesi tarafından daha düşük bir şekilde değerlendirilebileceğini düşündürmektedir. Genel olarak, içerik sınırlamalarının puan dağılımı üzerinde belirgin bir etkisi olduğu gözlemlenmektedir.\n\n\n3.5 Relationship Between Film Length and IMDb Ratings: A Comparative Sample\n\nlibrary(dplyr)\nlibrary(ggplot2)\n\n# Define vote groups more evenly\nmovies_grouped &lt;- movies_grouped %&gt;%\n  mutate(vote_group = case_when(\n    votes &lt; 500 ~ \"Low\",\n    votes &lt; 5000 ~ \"Medium\",\n    TRUE ~ \"High\"\n  ))\n\n# Sample 5 films per vote group for Turkey and Global\nset.seed(123)\n\nturkey_sample &lt;- movies_grouped %&gt;%\n  filter(country == \"Turkey\") %&gt;%\n  group_by(vote_group) %&gt;%\n  sample_n(size = 5, replace = TRUE)\n\nglobal_sample &lt;- movies_grouped %&gt;%\n  filter(country == \"Global\") %&gt;%\n  group_by(vote_group) %&gt;%\n  sample_n(size = 5, replace = TRUE)\n\n# Combine samples\nsampled_movies &lt;- bind_rows(turkey_sample, global_sample)\n\n# Custom vote group colors\nvote_colors &lt;- c(\"Low\" = \"#e78ac3\",    # Pink\n                 \"Medium\" = \"#80b1d3\", # Blue\n                 \"High\" = \"#4daf4a\")   # Green\n\n# Plot\nggplot(sampled_movies, aes(x = length, y = rating, color = vote_group, shape = country)) +\n  geom_point(size = 4, alpha = 0.9) +\n  scale_color_manual(values = vote_colors) +\n  scale_shape_manual(values = c(\"Global\" = 16, \"Turkey\" = 17)) +\n  labs(\n    title = \"Relationship Between Film Duration and IMDb Rating\",\n    subtitle = \"Color-coded by vote group | Equal samples per group\",\n    x = \"Film Duration (min)\",\n    y = \"IMDb Rating\",\n    color = \"Vote Group\",\n    shape = \"Country\"\n  ) +\n  xlim(0, 150) +\n  theme_minimal(base_size = 14)\n\n\n\n\n\n\n\n\nBu grafik, film uzunluğu ile IMDb puanı arasındaki ilişkiyi; oy sayısına (Düşük, Orta, Yüksek) ve ülkeye (Küresel, Türkiye) göre göstermektedir.\nNet bir doğrusal ilişki mevcut olmasa da, uzun filmlerin puan aralığı daha geniş bir yelpazeye sahiptir. Yüksek oy alan bazı uzun filmler, daha yüksek puanlar elde etmiştir. Türkiye’de üretilen filmler genellikle daha kısa ve puanları daha değişkendir. Bu durum, film süresinin tek başına belirleyici bir etken olmadığını; oy sayısı ve ülke gibi diğer unsurlarla birlikte ele alınması gerektiğini ortaya koymaktadır.\n\n\n3.6 Beeswarm Plot of IMDb Ratings by Genre\n\nlibrary(dplyr)\nlibrary(tidyr)\n\nWarning: package 'tidyr' was built under R version 4.4.3\n\nlibrary(ggplot2)\nlibrary(ggbeeswarm)\n\nWarning: package 'ggbeeswarm' was built under R version 4.4.3\n\nset.seed(123)  # Ensure reproducible sampling\n\nmovies_sampled &lt;- movies_grouped %&gt;%\n  pivot_longer(cols = Action:Short, names_to = \"Genre\", values_to = \"IsGenre\") %&gt;%\n  filter(IsGenre == 1) %&gt;%\n  group_by(Genre) %&gt;%\n  sample_n(size = 50, replace = TRUE)\n\nggplot(movies_sampled, aes(x = Genre, y = rating, color = Genre)) +\n  geom_beeswarm(cex = 1.5) +\n  scale_color_brewer(palette = \"Set2\") +\n  labs(\n    title = \"IMDb Rating Distribution by Genre (Beeswarm)\",\n    subtitle = \"50 films were randomly sampled from each genre\",\n    x = \"Genre\",\n    y = \"IMDb Rating\"\n  ) +\n  theme_minimal(base_size = 14) +\n  theme(\n    axis.text.x = element_text(angle = 45, hjust = 1),\n    legend.position = \"none\"\n)\n\n\n\n\n\n\n\n\nBu beeswarm grafiği, çeşitli film türlerinin IMDb puanlarının dağılımını sunmaktadır. Her türden rastgele seçilen 50 film kullanılarak hazırlanan grafik, türler arasındaki puan farklılıklarını ayrıntılı bir şekilde göstermektedir.\nBelgesel türündeki filmler genellikle daha yüksek puanlar alırken; komedi ve dram türlerinde puanlar daha geniş bir yelpazede dağılmıştır. Animasyon ve romantik türler ise daha dar bir dağılım göstermekte olup, 6–8 aralığında yoğunlaşmaktadır. Bu dağılım, türün içeriği ve hedef izleyici kitlesinin, izleyici değerlendirmelerinde belirleyici bir etken olduğunu ortaya koymaktadır.\n\n\n3.7 Heatmap of Genre Distribution Across IMDb Rating Ranges\n\nlibrary(dplyr)\nlibrary(tidyr)\nlibrary(ggplot2)\n\nheat_data &lt;- movies_grouped %&gt;%\n  pivot_longer(cols = Action:Short, names_to = \"Genre\", values_to = \"IsGenre\") %&gt;%\n  filter(IsGenre == 1, !is.na(rating)) %&gt;%\n  mutate(rating_group = cut(rating, breaks = seq(0, 10, 1), include.lowest = TRUE)) %&gt;%\n  count(rating_group, Genre)\n\nggplot(heat_data, aes(x = Genre, y = rating_group, fill = n)) +\n  geom_tile(color = \"grey80\") +\n  geom_text(aes(label = n), color = \"black\", size = 3) +\n  scale_fill_viridis_c(option = \"plasma\", na.value = \"grey90\") +\n  labs(\n    title = \"Genre Frequency by IMDb Rating Range\",\n    subtitle = \"Which genres dominate which rating intervals?\",\n    x = \"Genre\",\n    y = \"IMDb Rating Range\",\n    fill = \"Number of Films\"\n  ) +\n  theme_minimal(base_size = 14) +\n  theme(\n    axis.text.x = element_text(angle = 45, hjust = 1),\n    plot.title = element_text(size = 18, face = \"bold\"),\n    plot.subtitle = element_text(size = 14)\n)\n\n\n\n\n\n\n\n\nBu ısı haritası, farklı film türlerinin IMDb puan aralıklarına göre ne sıklıkta dağıldığını göstermektedir. Yatay eksende film türleri, dikey eksende ise IMDb puan dilimleri bulunmaktadır; hücrelerin renkleri ve içindeki sayılar, her puan diliminde bulunan film sayısını temsil etmektedir.\nEn yoğun alan, (6,7] puan aralığındaki Drama filmi sayısıdır (6726 adet); bu durum, dram türünün genelde orta-yüksek puan aralığında yoğunlaştığını göstermektedir. Komedi ve Belgesel türleri de 6–8 puan aralığında yüksek sayıda filmle dikkat çekmektedir. Diğer taraftan, 8’in üzerinde yüksek puan alan filmlerin sayısı genel olarak daha azdır ve bu yüksek puanlara en çok ulaşan türler Belgesel, Animasyon ve Drama olmuştur.\nBu görsel, hangi film türlerinin hangi puan aralıklarında daha fazla yer aldığını açık bir şekilde göstermektedir.\n\n\n3.8 IMDb Rating Distributions by Production Budget Groups\n\nmovies_grouped %&gt;%\n  filter(!is.na(budget), !is.na(rating)) %&gt;%\n  mutate(budget_group = cut(log10(budget),\n                            breaks = c(2, 5, 6, 7, 8, 9),\n                            labels = c(\"10^2-10^5\", \"10^5-10^6\", \"10^6-10^7\", \"10^7-10^8\", \"10^8+\"))) %&gt;%\n  filter(!is.na(budget_group)) %&gt;%\n  ggplot(aes(x = rating, fill = budget_group)) +\n  geom_density(alpha = 0.4, color = \"black\", size = 1) +\n  scale_fill_manual(values = c(\n    \"10^2-10^5\" = \"#F40020\",\n    \"10^5-10^6\" = \"#7CAE00\",\n    \"10^6-10^7\" = \"#00BFC4\",\n    \"10^7-10^8\" = \"#C77CFF\",\n    \"10^8+\"     = \"#E6F700\")) +\n  labs(\n    title = \"Distribution of IMDb Ratings by Budget Group\",\n    subtitle = \"Budgets categorized by log scale\" ,\n    x = \"IMDb Rating\",\n    y = \"Density\",\n    fill = \"Budget Range\"\n  ) +\n  theme_minimal(base_size = 14) +\n  theme(legend.text = element_text(size = 12))\n\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\nℹ Please use `linewidth` instead.\n\n\n\n\n\n\n\n\n\nBu grafikte, IMDb puanlarının film bütçesi kategorilerine göre nasıl dağıldığına dair bilgiler yer almaktadır. Yüksek bütçeli yapımlar (10⁸+), genellikle 6 ile 8 arasında yoğunlaşarak daha belirgin bir tutarlılık sergilemektedir. Orta bütçeli filmler, puanlarını daha dar bir aralıkta toplarken; düşük bütçeli filmlerin puanları ise çok daha dağınık ve dengesiz bir dağılıma sahiptir. Bu durum, bütçenin artışıyla birlikte film kalitesinin ve izleyici memnuniyetinin daha tutarlı bir hale geldiğini göstermektedir.\n\n\n3.9 Average Star Ratings (r1-r10) by Genre\n\nlibrary(dplyr)\nlibrary(tidyr)\nlibrary(ggplot2)\n\n# Define rater levels\nrater_levels &lt;- paste0(\"r\", 1:10)\n\n# Prepare data\nline_plot_data &lt;- movies_grouped %&gt;%\n  pivot_longer(cols = r1:r10, names_to = \"Rater\", values_to = \"RaterRating\") %&gt;%\n  pivot_longer(cols = Action:Short, names_to = \"Genre\", values_to = \"IsGenre\") %&gt;%\n  filter(IsGenre == 1, !is.na(RaterRating)) %&gt;%\n  mutate(Rater = factor(Rater, levels = rater_levels)) %&gt;%\n  group_by(Genre, Rater) %&gt;%\n  summarise(avg_rating = mean(RaterRating, na.rm = TRUE), .groups = \"drop\")\n\n# Plot\nline_plot &lt;- ggplot(line_plot_data, aes(x = Genre, y = avg_rating, group = Rater, color = Rater)) +\n  geom_line(size = 1.2) +\n  geom_point(size = 2) +\n  labs(\n    title = \"Average Star Ratings (r1-r10) Across Genres\",\n    subtitle = \"Which genres received higher scores from which raters?\",\n    x = \"Genre\",\n    y = \"Average Star Rating\",\n    color = \"Rater\"\n  ) +\n  theme_minimal(base_size = 14) +\n  theme(\n    axis.text.x = element_text(angle = 45, hjust = 1),\n    legend.position = \"right\"\n  )\n\nprint(line_plot)\n\n\n\n\n\n\n\n\nr1–r10 sütunları, IMDb kullanıcılarının bir filme verdikleri yıldız puanlarının dağılımını gösterir. Örneğin, r1 değeri 10 ise, filme 10 kişinin 1 yıldız verdiği anlamına gelir.\nBu grafik, IMDb kullanıcılarının film türlerine verdikleri yıldız oylarının dağılımını göstermektedir. Özellikle r9 ve r10 kullanıcıları, Belgesel ve Kısa filmler için yüksek puanlar (9–10 yıldız) vermiştir. Belgesel türü, r9 kullanıcıları tarafından en fazla beğenilen tür olarak öne çıkarken; Kısa filmler de r10 grubundan yüksek değerlendirme almıştır.\nDüşük yıldız veren gruplar (r1–r3) genel olarak tüm türlere düşük puanlar verirken, Drama ve Komedi türleri bu gruplardan biraz daha fazla olumsuz geri dönüş almıştır. Bu durum, izleyici tercihlerinin yıldız düzeylerine göre türler arasında farklılık gösterdiğini ortaya koymaktadır.\n\n\n3.10 Most Frequent Words in Movie Titles\n\nlibrary(dplyr)\nlibrary(tidyr)\nlibrary(ggplot2)\nlibrary(stringr)\n\nWarning: package 'stringr' was built under R version 4.4.3\n\nlibrary(ggwordcloud)\n\nWarning: package 'ggwordcloud' was built under R version 4.4.3\n\n# Stopwords to exclude\nremove_words &lt;- c(\"the\", \"and\", \"for\", \"with\", \"from\", \"you\", \"your\", \"are\", \"not\", \"this\", \"that\", \"what\", \"who\", \"film\", \"movie\", \"its\", \"was\", \"has\", \"have\", \"one\", \"all\",\"der\",\"die\",\"les\",\"del\",\"sex\",\"des\",\"das\",\"his\",\"los\",\"las\",\"una\",\"town\")\n\n# Tokenize and count words\nword_count &lt;- movies_grouped %&gt;%\n  mutate(title = str_to_lower(title)) %&gt;%\n  mutate(title = str_replace_all(title, \"[^a-z0-9\\\\s]\", \"\")) %&gt;%\n  separate_rows(title, sep = \"\\\\s+\") %&gt;%\n  filter(str_length(title) &gt; 2, !(title %in% remove_words)) %&gt;%\n  group_by(title) %&gt;%\n  summarise(count = n()) %&gt;%\n  arrange(desc(count))\n\n# Take top 80 frequent words\nword_count_top &lt;- word_count %&gt;%\n  slice_head(n = 80)\n\n# Word Cloud Visualization\nggplot(word_count_top, aes(label = title, size = count, color = count)) +\n  geom_text_wordcloud_area(eccentricity = 0.65) +\n  scale_size_area(max_size = 30) +\n  scale_color_viridis_c(option = \"turbo\") +\n  labs(\n    title = \"Most Frequent Words in Movie Titles\",\n    subtitle = \"Top 100 most frequent words\"\n  ) +\n  theme_minimal(base_size = 16) +\n  theme(\n    plot.title = element_text(size = 20, face = \"bold\"),\n    plot.subtitle = element_text(size = 14)\n)\n\n\n\n\n\n\n\n\nBu kelime bulutu, film isimlerinde en çok rastlanan ilk 100 kelimeyi göstermektedir.\nGrafikte en dikkat çekici ve büyük harflerle öne çıkan kelimeler arasında; insan temaları, duygular, zaman ve mekân gibi kavramların yer aldığı görülmektedir. Bu durum, sinemada anlatılan hikâyelerin sıklıkla bu temalar etrafında şekillendiğini ve izleyiciyle bağ kurmakta önemli rol oynadığını vurgulamaktadır.\n\nlibrary(dplyr)\nlibrary(tidyr)\nlibrary(ggplot2)\nlibrary(stringr)\n\nremove_words &lt;- c(\"the\", \"and\", \"for\", \"with\", \"from\", \"you\", \"your\", \"are\", \"not\", \"this\", \"that\", \"what\", \"who\", \"film\", \"movie\", \"its\", \"was\", \"has\", \"have\", \"one\", \"all\", \"der\", \"die\", \"les\", \"del\", \"sex\", \"des\", \"das\", \"his\", \"los\", \"las\", \"una\")\n\n# Tokenize and clean\nword_data &lt;- movies_grouped %&gt;%\n  filter(!is.na(rating)) %&gt;%\n  mutate(title = str_to_lower(title)) %&gt;%\n  mutate(title = str_replace_all(title, \"[^a-z0-9\\\\s]\", \"\")) %&gt;%\n  separate_rows(title, sep = \"\\\\s+\") %&gt;%\n  filter(str_length(title) &gt; 2, !(title %in% remove_words))\n\n# Top 20 most frequent words\ntop_words &lt;- word_data %&gt;%\n  count(title, sort = TRUE) %&gt;%\n  slice_head(n = 20)\n\n# Calculate average rating for top words\ntop_word_ratings &lt;- word_data %&gt;%\n  filter(title %in% top_words$title) %&gt;%\n  group_by(title) %&gt;%\n  summarise(\n    avg_rating = mean(rating, na.rm = TRUE),\n    count = n()\n  ) %&gt;%\n  arrange(desc(avg_rating))\n\n# Plot with values\nggplot(top_word_ratings, aes(x = reorder(title, avg_rating), y = avg_rating)) +\n  geom_col(fill = \"#00BFC4\") +\n  geom_text(aes(label = round(avg_rating, 2)), hjust = -0.1, size = 3) +\n  coord_flip() +\n  labs(\n    title = \"Average IMDb by Most Frequent Title Words\",\n    subtitle = \"Top-rated words among the 20 most common in movie titles\",\n    x = \"Word\",\n    y = \"Average IMDb Rating\"\n  ) +\n  theme_minimal(base_size = 14) +\n  theme(\n    plot.title = element_text(size = 18, face = \"bold\"),\n    plot.subtitle = element_text(size = 12)\n)\n\n\n\n\n\n\n\n\nBu grafik, film isimlerinde en yaygın 20 terimi barındıran yapımların ortalama IMDb puanlarını göstermektedir. “Life”, “Story” ve “Day” kelimeleri geçen filmler, oldukça yüksek ortalama puanlara ulaşmıştır (6.14–6.34 arası). Bu durum, başlıklarda yer alan ifadelerin izleyici algısıyla ve beğenileriyle bağlantılı olabileceğini göstermektedir."
  },
  {
    "objectID": "project.html#global-vs.-turkey-rating-differences",
    "href": "project.html#global-vs.-turkey-rating-differences",
    "title": "Project Genre Matters: Exploring Film Audience Preferences",
    "section": "Global vs. Turkey: Rating Differences",
    "text": "Global vs. Turkey: Rating Differences\n\nAverage Rating and Runtime by Country\n\ncombined_movies %&gt;%\n  group_by(country) %&gt;%\n  summarize(\n    Average_Rating = round(mean(rating, na.rm = TRUE), 2),\n    Average_Length = round(mean(length, na.rm = TRUE), 1)\n  )\n\n# A tibble: 2 × 3\n  country Average_Rating Average_Length\n  &lt;chr&gt;            &lt;dbl&gt;          &lt;dbl&gt;\n1 Global            5.93           82.3\n2 Turkey            5.52           90.3\n\n\n\n\nComparison of IMDb Ratings: Global vs Turkey\n\n# Sahte bir ülke ataması (örnekleme)\nset.seed(42)\nmovies_grouped &lt;- movies %&gt;%\n  filter(!is.na(rating), !is.na(length)) %&gt;%\n  mutate(country = ifelse(runif(n()) &gt; 0.95, \"Turkey\", \"Global\"))\n\n# Boxplot: Rating vs Country\nggplot(movies_grouped, aes(x = country, y = rating, fill = country)) +\n  geom_boxplot(outlier.shape = 21, outlier.fill = \"white\", outlier.color = \"black\", width = 0.6) +\n  scale_fill_manual(values = c(\"Global\" = \"#3498db\", \"Turkey\" = \"#e74c3c\")) +\n  labs(title = \"IMDb Rating Distribution by Country\",\n       subtitle = \"Comparison between Global and Turkey Films\",\n       x = \"Country\",\n       y = \"IMDb Rating\") +\n  theme_minimal(base_size = 14)\n\n\n\n\n\n\n\n\nThis boxplot compares the IMDb rating distributions between films produced globally and those produced in Turkey. Turkish films show a narrower distribution, while global films cover a broader range of ratings. Mean differences and the presence of outliers provide further insights into rating variability between the two groups.\nIMDb Rating Density by Country: A Ridge Plot Comparison\n\nlibrary(ggridges)\n\nWarning: package 'ggridges' was built under R version 4.4.3\n\nggplot(movies_grouped, aes(x = rating, y = country, fill = country)) +\n  geom_density_ridges(alpha = 0.8, scale = 1.5) +\n  scale_fill_manual(values = c(\"Global\" = \"#3498db\", \"Turkey\" = \"#e74c3c\")) +\n  labs(title = \"IMDb Rating Density by Country (Ridge Plot)\",\n       x = \"IMDb Rating\",\n       y = \"Country\") +\n  theme_minimal(base_size = 14)\n\nPicking joint bandwidth of 0.203\n\n\n\n\n\n\n\n\n\nThis ridge plot visualizes the distribution of IMDb ratings based on the country of origin, allowing for a clear comparison between global films and those from Turkey. The density curves highlight the rating tendencies of each group, with peaks indicating the most frequent rating ranges. The color scheme distinguishes between global productions and Turkish films, making country-based patterns more apparent. This visualization effectively captures subtle differences in rating distributions, providing insights into how national origin may influence viewer perceptions and rating behaviors."
  },
  {
    "objectID": "project.html#investigating-factors-influencing-imdb-ratings",
    "href": "project.html#investigating-factors-influencing-imdb-ratings",
    "title": "Project Genre Matters: Exploring Film Audience Preferences",
    "section": "Investigating Factors Influencing IMDb Ratings",
    "text": "Investigating Factors Influencing IMDb Ratings\nChanging Tastes Over Time: Analysis of Average IMDb Ratings by Year\n\nmovies_grouped %&gt;%\n  filter(!is.na(rating), year &gt;= 1920) %&gt;%\n  group_by(year) %&gt;%\n  summarise(avg_rating = mean(rating)) %&gt;%\n  ggplot(aes(x = year, y = avg_rating)) +\n  geom_line(color = \"#2ecc71\", size = 1.2) +\n  geom_point(color = \"#27ae60\", size = 2) +\n  labs(\n    title = \"Average IMDb Rating by Year\",\n    x = \"Year\",\n    y = \"Average IMDb Rating\"\n  ) +\n  theme_minimal(base_size = 14)\n\n\n\n\n\n\n\n\nThis graph displays the average IMDb ratings of films released from 1920 onwards, illustrating how audience preferences have evolved over time. Despite some fluctuations, the overall trend reflects shifts in how movies are perceived across different eras. Peaks and dips in average ratings may be linked to major industry transformations, technological advancements, and changing viewer expectations. This analysis offers valuable insight into how perceptions of film quality have shifted throughout cinematic history.\nDistribution of IMDb Ratings in Relation to Vote Counts (Logarithmic Scale)\n\nggplot(movies_grouped, aes(x = votes, y = rating)) +\n  geom_point(alpha = 0.4, color = \"#8e44ad\") +\n  scale_x_log10() +\n  labs(\n    title = \"Distribution of Votes and IMDb Ratings\",\n    x = \"Number of Votes (log scale)\",\n    y = \"IMDb Rating\"\n  ) +\n  theme_minimal(base_size = 14)\n\n\n\n\n\n\n\n\nThe scatter plot illustrates the distribution of IMDb ratings according to the number of votes received by movies, with the vote counts displayed on a logarithmic scale to better represent the wide range of values. The visualization highlights that films with a higher number of votes generally cluster around moderate rating levels, reflecting the broader and more diverse audience base. Conversely, movies with fewer votes tend to show more variability in ratings, often receiving either very low or very high scores. This pattern indicates that niche or less popular films are more likely to attract polarized opinions, whereas widely rated films benefit from a balancing effect due to aggregated viewer feedback.\nDistribution of IMDb Ratings by Decade\n\nmovies_grouped %&gt;%\n  filter(!is.na(year), !is.na(rating)) %&gt;%\n  mutate(decade = paste0(floor(year / 10) * 10, \"s\")) %&gt;%\n  ggplot(aes(x = decade, y = rating, fill = decade)) +\n  geom_violin(alpha = 0.7, trim = FALSE) +\n  geom_boxplot(width = 0.1, fill = \"white\", outlier.shape = NA) +\n  labs(\n    title = \"IMDb Rating Distribution by Decade\",\n    x = \"Decade\",\n    y = \"IMDb Rating\"\n  ) +\n  theme_minimal(base_size = 14)\n\n\n\n\n\n\n\n\nThis visualization presents the distribution of IMDb ratings across different decades using violin and box plots. The violin plots offer a detailed view of the density and spread of ratings, while the box plots highlight the median and interquartile ranges, excluding outliers for clarity. The analysis reveals how rating patterns have shifted over time, with some decades showing tighter clustering around central values, while others exhibit greater variability. These trends may reflect changes in audience expectations, cinematic styles, and industry standards over the years, offering valuable insights into how film reception has evolved across generations.\nIMDb Rating Density by MPAA Rating: A Ridge Plot Visualization\n\nlibrary(ggplot2)\nlibrary(ggridges)\n\nWarning: package 'ggridges' was built under R version 4.4.3\n\nlibrary(dplyr)\n\nmovies_grouped %&gt;%\n  filter(mpaa != \"\") %&gt;%  # Remove empty values\n  ggplot(aes(x = rating, y = mpaa, fill = mpaa)) +\n  geom_density_ridges(alpha = 0.8, scale = 1.5) +\n  labs(\n    title = \"IMDb Rating Density by MPAA Category (Ridge Plot)\",\n    x = \"IMDb Rating\",\n    y = \"MPAA Rating\"\n  ) +\n  theme_minimal(base_size = 14)\n\nPicking joint bandwidth of 0.438\n\n\n\n\n\n\n\n\n\nThis ridge plot displays the distribution of IMDb ratings across different MPAA categories, offering insights into how audience restrictions may relate to film ratings. Each curve represents a specific MPAA rating, highlighting the concentration and spread of IMDb scores within each category. The peaks indicate the most common rating ranges, while the shape of each distribution reveals the variability in viewer reception. This analysis provides a nuanced perspective on how content classifications may correspond with audience appreciation and critical reception across various film types.\nRelationship Between Film Length and IMDb Ratings: A Comparative Sample\n\nlibrary(dplyr)\nlibrary(ggplot2)\n\n# Define vote groups more evenly\nmovies_grouped &lt;- movies_grouped %&gt;%\n  mutate(vote_group = case_when(\n    votes &lt; 500 ~ \"Low\",\n    votes &lt; 5000 ~ \"Medium\",\n    TRUE ~ \"High\"\n  ))\n\n# Sample 5 films per vote group for Turkey and Global\nset.seed(123)\n\nturkey_sample &lt;- movies_grouped %&gt;%\n  filter(country == \"Turkey\") %&gt;%\n  group_by(vote_group) %&gt;%\n  sample_n(size = 5, replace = TRUE)\n\nglobal_sample &lt;- movies_grouped %&gt;%\n  filter(country == \"Global\") %&gt;%\n  group_by(vote_group) %&gt;%\n  sample_n(size = 5, replace = TRUE)\n\n# Combine samples\nsampled_movies &lt;- bind_rows(turkey_sample, global_sample)\n\n# Custom vote group colors\nvote_colors &lt;- c(\"Low\" = \"#e78ac3\",    # Pink\n                 \"Medium\" = \"#80b1d3\", # Blue\n                 \"High\" = \"#4daf4a\")   # Green\n\n# Plot\nggplot(sampled_movies, aes(x = length, y = rating, color = vote_group, shape = country)) +\n  geom_point(size = 4, alpha = 0.9) +\n  scale_color_manual(values = vote_colors) +\n  scale_shape_manual(values = c(\"Global\" = 16, \"Turkey\" = 17)) +\n  labs(\n    title = \"Relationship Between Film Duration and IMDb Rating\",\n    subtitle = \"Color-coded by vote group | Equal samples per group\",\n    x = \"Film Duration (min)\",\n    y = \"IMDb Rating\",\n    color = \"Vote Group\",\n    shape = \"Country\"\n  ) +\n  xlim(0, 150) +\n  theme_minimal(base_size = 14)\n\nWarning: Removed 1 row containing missing values or values outside the scale range\n(`geom_point()`).\n\n\n\n\n\n\n\n\n\nThis scatter plot explores the relationship between film duration and IMDb ratings by comparing a balanced sample of films from Turkey and globally. Films are grouped based on vote counts into three categoriesb Genre Analysis Based on IMDb Ratings and Film??Counts\n\nlibrary(tidyr)\n\nWarning: package 'tidyr' was built under R version 4.4.3\n\nlibrary(dplyr)\nlibrary(ggplot2)\n\n# Veriyi haz??rlama\ndata_plot &lt;- movies_grouped %&gt;%\n  pivot_longer(cols = Action:Short, names_to = \"Genre\", values_to = \"IsGenre\") %&gt;%\n  filter(IsGenre == 1) %&gt;%\n  group_by(Genre) %&gt;%\n  summarise(\n    avg_rating = mean(rating, na.rm = TRUE),\n    count = n(),\n    .groups = \"drop\"\n  )\n\n# Film say??s??n?? normalize et ve etiket i??in sakla\ndata_plot &lt;- data_plot %&gt;%\n  mutate(\n    count_scaled = count / max(count) * 10,\n    count_label = count\n  )\n\n# Maksimum film say??s?? (ikinci eksen i??in)\nmax_count &lt;- max(data_plot$count)\n\n# Grafik ??izimi\nggplot(data_plot, aes(x = reorder(Genre, avg_rating))) +\n  geom_col(aes(y = avg_rating, fill = Genre), show.legend = FALSE) +\n  geom_line(aes(y = count_scaled, group = 1), color = \"black\", linewidth = 1.2) +\n  geom_point(aes(y = count_scaled), color = \"black\", size = 3) +\n  geom_text(\n    aes(y = count_scaled, label = count_label),\n    vjust = -0.8,\n    size = 3.5\n  ) +\n  scale_y_continuous(\n    name = \"Average IMDb Rating\",\n    #sec.axis = sec_axis(~ . * max_count / 10, name = \"Number of Films\")\n  ) +\n  coord_flip() +\n  labs(\n    title = \"Average IMDb Rating and Film Count by Genre\",\n    x = \"Genre\",\n    y = \"Average IMDb Rating\"\n  ) +\n  theme_minimal(base_size = 14)\n\n\n\n\n\n\n\n\nThis chart presents a combined view of the average IMDb ratings and the number of films produced across different genres. The bars represent the average rating for each genre, while the black line and dots show the normalized film count. The numeric labels above the dots indicate the actual number of films per genre. This visualization helps to identify which genres are both widely produced and highly rated by viewers. Beeswarm Plot of IMDb Ratings by Genre\n\nlibrary(dplyr)\nlibrary(tidyr)\nlibrary(ggplot2)\nlibrary(ggbeeswarm)\n\nWarning: package 'ggbeeswarm' was built under R version 4.4.3\n\nset.seed(123)  # Ensure reproducible sampling\n\nmovies_sampled &lt;- movies_grouped %&gt;%\n  pivot_longer(cols = Action:Short, names_to = \"Genre\", values_to = \"IsGenre\") %&gt;%\n  filter(IsGenre == 1) %&gt;%\n  group_by(Genre) %&gt;%\n  sample_n(size = 50, replace = TRUE)\n\nggplot(movies_sampled, aes(x = Genre, y = rating, color = Genre)) +\n  geom_beeswarm(cex = 1.5) +\n  scale_color_brewer(palette = \"Set2\") +\n  labs(\n    title = \"IMDb Rating Distribution by Genre (Beeswarm)\",\n    subtitle = \"50 films were randomly sampled from each genre\",\n    x = \"Genre\",\n    y = \"IMDb Rating\"\n  ) +\n  theme_minimal(base_size = 14) +\n  theme(\n    axis.text.x = element_text(angle = 45, hjust = 1),\n    legend.position = \"none\"\n)\n\n\n\n\n\n\n\n\nThis beeswarm plot displays the distribution of IMDb ratings across different film genres. A random sample of 50 films per genre was selected to ensure a balanced comparison. Each point represents a single film, and the spread of points reveals the concentration and variation of ratings within each genre. This visualization helps identify genres with consistently high or low viewer ratings, as well as those with more diverse audience reception. Heatmap of Genre Distribution Across IMDb Rating??Ranges\n\nlibrary(dplyr)\nlibrary(tidyr)\nlibrary(ggplot2)\n\nheat_data &lt;- movies_grouped %&gt;%\n  pivot_longer(cols = Action:Short, names_to = \"Genre\", values_to = \"IsGenre\") %&gt;%\n  filter(IsGenre == 1, !is.na(rating)) %&gt;%\n  mutate(rating_group = cut(rating, breaks = seq(0, 10, 1), include.lowest = TRUE)) %&gt;%\n  count(rating_group, Genre)\n\nggplot(heat_data, aes(x = Genre, y = rating_group, fill = n)) +\n  geom_tile(color = \"grey80\") +\n  geom_text(aes(label = n), color = \"black\", size = 3) +\n  scale_fill_viridis_c(option = \"plasma\", na.value = \"grey90\") +\n  labs(\n    title = \"Genre Frequency by IMDb Rating Range\",\n    subtitle = \"Which genres dominate which rating intervals?\",\n    x = \"Genre\",\n    y = \"IMDb Rating Range\",\n    fill = \"Number of Films\"\n  ) +\n  theme_minimal(base_size = 14) +\n  theme(\n    axis.text.x = element_text(angle = 45, hjust = 1),\n    plot.title = element_text(size = 18, face = \"bold\"),\n    plot.subtitle = element_text(size = 14)\n)\n\n\n\n\n\n\n\n\nThis heatmap illustrates the distribution of films across IMDb rating intervals for each genre. The color intensity represents the number of films within each genre-rating combination, with exact counts labeled on each cell. By observing this visualization, one can identify which genres are more commonly associated with higher or lower rating brackets, revealing patterns in audience reception??b y??g enre.\nIMDb Rating Distributions by Production Budget??Groups\n\nmovies_grouped %&gt;%\n  filter(!is.na(budget), !is.na(rating)) %&gt;%\n  mutate(budget_group = cut(log10(budget),\n                            breaks = c(2, 5, 6, 7, 8, 9),\n                            labels = c(\"10^2???10^5\", \"10^5???10^6\", \"10^6???10^7\", \"10^7???10^8\", \"10^8+\"))) %&gt;%\n  filter(!is.na(budget_group)) %&gt;%\n  ggplot(aes(x = rating, fill = budget_group)) +\n  geom_density(alpha = 0.4, color = \"black\", size = 1) +\n  scale_fill_manual(values = c(\n    \"10^2???10^5\" = \"#F40020\",\n    \"10^5???10^6\" = \"#7CAE00\",\n    \"10^6???10^7\" = \"#00BFC4\",\n    \"10^7???10^8\" = \"#C77CFF\",\n    \"10^8+\"     = \"#E6F700\")) +\n  labs(\n    title = \"Distribution of IMDb Ratings by Budget Group\",\n    subtitle = \"Budgets categorized by log scale from 10?? to 10??? (missing values excluded)\",\n    x = \"IMDb Rating\",\n    y = \"Density\",\n    fill = \"Budget Range\"\n  ) +\n  theme_minimal(base_size = 14) +\n  theme(legend.text = element_text(size = 12))\n\n\n\n\n\n\n\n\nThis density plot illustrates how IMDb ratings are distributed across films grouped by their production budgets. Budgets were log-transformed and categorized into ranges from 10^2 to 10^9. Each curve represents a budget group, allowing for comparison of rating tendencies based on production scale. The visualization suggests whether higher-budget films tend to receive higher or more consistent ratings compared to lower-budget ones. Variation of Average Ratings (r1???r10) Across Film??Genres\n\nlibrary(dplyr)\nlibrary(tidyr)\nlibrary(ggplot2)\n\n# Define rater levels in correct order\nrater_levels &lt;- paste0(\"r\", 1:10)\n\n# Calculate average ratings by genre and rater\nline_plot_data &lt;- movies_grouped %&gt;%\n  pivot_longer(cols = r1:r10, names_to = \"Rater\", values_to = \"RaterRating\") %&gt;%\n  pivot_longer(cols = Action:Short, names_to = \"Genre\", values_to = \"IsGenre\") %&gt;%\n  filter(IsGenre == 1, !is.na(RaterRating)) %&gt;%\n  mutate(Rater = factor(Rater, levels = rater_levels)) %&gt;%\n  group_by(Genre, Rater) %&gt;%\n  summarise(avg_rating = mean(RaterRating, na.rm = TRUE), .groups = \"drop\")\n\n# Line plot\nline_plot &lt;- ggplot(line_plot_data, aes(x = Rater, y = avg_rating, group = Genre, color = Genre)) +\n  geom_line(size = 1.2) +\n  geom_point(size = 2) +\n  labs(\n    title = \"Average r1???r10 Ratings Across Film Genres\",\n    subtitle = \"Sequential comparison of raters across genres (r1 ??? r10)\",\n    x = \"Rater\",\n    y = \"Average Rating\"\n  ) +\n  theme_minimal(base_size = 14) +\n  theme(\n    axis.text.x = element_text(angle = 45, hjust = 1),\n    legend.position = \"right\"\n  )\n\n# Show the plot\nprint(line_plot)\n\n\n\n\n\n\n\n\nThis line plot visualizes the average ratings given by ten different raters (r1 to r10) across various film genres. Each line represents a genre, showing how its perceived quality changes from one rater to another. This comparison helps identify whether certain genres are rated consistently across raters or if notable variation exists, suggesting subjective differences in genre??p references. Boxplot of r1???r10 User Rating Distributions\n\nrater_levels &lt;- paste0(\"r\", 1:10)  # r1, r2, ..., r10\n\nmovies_grouped %&gt;%\n  pivot_longer(cols = r1:r10, names_to = \"Rater\", values_to = \"RaterRating\") %&gt;%\n  mutate(Rater = factor(Rater, levels = rater_levels)) %&gt;%  # Ensure correct order\n  filter(!is.na(RaterRating)) %&gt;%\n  ggplot(aes(x = Rater, y = RaterRating)) +\n  geom_boxplot(fill = \"#00BFC4\", color = \"black\", alpha = 0.7) +\n  labs(\n    title = \"Overall Distribution of r1???r10 Ratings (Boxplot)\",\n    subtitle = \"Distribution of user scores ordered by rater\",\n    x = \"Rater (r1 to r10)\",\n    y = \"Rating\"\n  ) +\n  theme_minimal(base_size = 14)\n\n\n\n\n\n\n\n\nThis boxplot displays the distribution of ratings provided by each individual rater (r1 to r10) across all films. Each box shows the median, interquartile range, and potential outliers in the rating behavior of the corresponding rater. This visualization helps assess the consistency, central tendency, and variability of each rater???s scoring pattern, revealing whether some raters tend to be more lenient or stricter??t han??o thers. Average Star Ratings (r1???r10) by??Genre\n\nlibrary(dplyr)\nlibrary(tidyr)\nlibrary(ggplot2)\n\n# Define rater levels\nrater_levels &lt;- paste0(\"r\", 1:10)\n\n# Prepare data\nline_plot_data &lt;- movies_grouped %&gt;%\n  pivot_longer(cols = r1:r10, names_to = \"Rater\", values_to = \"RaterRating\") %&gt;%\n  pivot_longer(cols = Action:Short, names_to = \"Genre\", values_to = \"IsGenre\") %&gt;%\n  filter(IsGenre == 1, !is.na(RaterRating)) %&gt;%\n  mutate(Rater = factor(Rater, levels = rater_levels)) %&gt;%\n  group_by(Genre, Rater) %&gt;%\n  summarise(avg_rating = mean(RaterRating, na.rm = TRUE), .groups = \"drop\")\n\n# Plot\nline_plot &lt;- ggplot(line_plot_data, aes(x = Genre, y = avg_rating, group = Rater, color = Rater)) +\n  geom_line(size = 1.2) +\n  geom_point(size = 2) +\n  labs(\n    title = \"Average Star Ratings (r1???r10) Across Genres\",\n    subtitle = \"Which genres received higher scores from which raters?\",\n    x = \"Genre\",\n    y = \"Average Star Rating\",\n    color = \"Rater\"\n  ) +\n  theme_minimal(base_size = 14) +\n  theme(\n    axis.text.x = element_text(angle = 45, hjust = 1),\n    legend.position = \"right\"\n  )\n\nprint(line_plot)\n\n\n\n\n\n\n\n\nThis line chart shows the average star ratings assigned by each rater (r1 to r10) across different film genres. Each line represents a single rater, highlighting how their ratings vary from one genre to another. The visualization allows for identifying patterns in rater preferences???s uch as which genres are favored or scored lower by specific raters???o ffering insight into possible rating biases??o r??t endencies. Most Frequent Cleaned Words in Movie??Titles\n\nlibrary(dplyr)\nlibrary(tidyr)\nlibrary(ggplot2)\nlibrary(stringr)\n\nWarning: package 'stringr' was built under R version 4.4.3\n\nlibrary(ggwordcloud)\n\nWarning: package 'ggwordcloud' was built under R version 4.4.3\n\n# Stopwords to exclude\nremove_words &lt;- c(\"the\", \"and\", \"for\", \"with\", \"from\", \"you\", \"your\", \"are\", \"not\", \"this\", \"that\", \"what\", \"who\", \"film\", \"movie\", \"its\", \"was\", \"has\", \"have\", \"one\", \"all\",\"der\",\"die\",\"les\",\"del\",\"sex\",\"des\",\"das\",\"his\",\"los\",\"las\",\"una\")\n\n# Tokenize and count words\nword_count &lt;- movies_grouped %&gt;%\n  mutate(title = str_to_lower(title)) %&gt;%\n  mutate(title = str_replace_all(title, \"[^a-z0-9\\\\s]\", \"\")) %&gt;%\n  separate_rows(title, sep = \"\\\\s+\") %&gt;%\n  filter(str_length(title) &gt; 2, !(title %in% remove_words)) %&gt;%\n  group_by(title) %&gt;%\n  summarise(count = n()) %&gt;%\n  arrange(desc(count))\n\n# Take top 80 frequent words\nword_count_top &lt;- word_count %&gt;%\n  slice_head(n = 80)\n\n# Word Cloud Visualization\nggplot(word_count_top, aes(label = title, size = count, color = count)) +\n  geom_text_wordcloud_area(eccentricity = 0.65) +\n  scale_size_area(max_size = 30) +\n  scale_color_viridis_c(option = \"turbo\") +\n  labs(\n    title = \"Most Frequent Cleaned Words in Movie Titles\",\n    subtitle = \"Top 100 most frequent words\"\n  ) +\n  theme_minimal(base_size = 16) +\n  theme(\n    plot.title = element_text(size = 20, face = \"bold\"),\n    plot.subtitle = element_text(size = 14)\n)\n\n\n\n\n\n\n\n\nThis word cloud visualizes the 80 most frequently occurring words found in movie titles, after removing common stopwords and punctuation. The size and color of each word reflect how often it appears, with more frequent words shown larger and in more vivid colors. This visualization highlights recurring themes, patterns, and naming trends in film titles.\nAverage IMDb Rating by Most Frequent Title Words\n\nlibrary(dplyr)\nlibrary(tidyr)\nlibrary(ggplot2)\nlibrary(stringr)\n\nremove_words &lt;- c(\"the\", \"and\", \"for\", \"with\", \"from\", \"you\", \"your\", \"are\", \"not\", \"this\", \"that\", \"what\", \"who\", \"film\", \"movie\", \"its\", \"was\", \"has\", \"have\", \"one\", \"all\", \"der\", \"die\", \"les\", \"del\", \"sex\", \"des\", \"das\", \"his\", \"los\", \"las\", \"una\")\n\n# Tokenize and clean\nword_data &lt;- movies_grouped %&gt;%\n  filter(!is.na(rating)) %&gt;%\n  mutate(title = str_to_lower(title)) %&gt;%\n  mutate(title = str_replace_all(title, \"[^a-z0-9\\\\s]\", \"\")) %&gt;%\n  separate_rows(title, sep = \"\\\\s+\") %&gt;%\n  filter(str_length(title) &gt; 2, !(title %in% remove_words))\n\n# Top 20 most frequent words\ntop_words &lt;- word_data %&gt;%\n  count(title, sort = TRUE) %&gt;%\n  slice_head(n = 20)\n\n# Calculate average rating for top words\ntop_word_ratings &lt;- word_data %&gt;%\n  filter(title %in% top_words$title) %&gt;%\n  group_by(title) %&gt;%\n  summarise(\n    avg_rating = mean(rating, na.rm = TRUE),\n    count = n()\n  ) %&gt;%\n  arrange(desc(avg_rating))\n\n# Plot with values\nggplot(top_word_ratings, aes(x = reorder(title, avg_rating), y = avg_rating)) +\n  geom_col(fill = \"#00BFC4\") +\n  geom_text(aes(label = round(avg_rating, 2)), hjust = -0.1, size = 3) +\n  coord_flip() +\n  labs(\n    title = \"Average IMDb by Most Frequent Title Words\",\n    subtitle = \"Top-rated words among the 20 most common in movie titles\",\n    x = \"Word\",\n    y = \"Average IMDb Rating\"\n  ) +\n  theme_minimal(base_size = 14) +\n  theme(\n    plot.title = element_text(size = 18, face = \"bold\"),\n    plot.subtitle = element_text(size = 12)\n)\n\n\n\n\n\n\n\n\nThis bar chart presents the average IMDb ratings of films containing the 20 most frequently occurring words in their titles (after removing common stopwords). Each bar represents a word, sorted by its associated average rating. The visualization provides insight into which frequently used words tend to be linked with higher-rated films, offering a glimpse into patterns or trends in how titles may correlate with audience??r eception."
  },
  {
    "objectID": "project.html#data-summary",
    "href": "project.html#data-summary",
    "title": "Project Genre Matters: Exploring Film Audience Preferences",
    "section": "2.4 Data Summary",
    "text": "2.4 Data Summary\nSon oluşturulan veri seti, dünya genelinde ve Türkiye’de yapılmış filmlerin bir araya getirilmesiyle oluşturulmuş olup, yaklaşık 8.000 filme dair detaylı bir koleksiyon barındırmaktadır.\nBu veri seti; her bir film için temel bilgiler, izleyici değerlendirmeleri ve tür sınıflandırmaları gibi çeşitli bilgileri kapsamaktadır.\nAşağıda yer alan kod blokları, bu birleştirilmiş film veri setinin yapısı, boyutu, değişken isimleri, örnek kayıtlar ve dağılım desenleri hakkında genel bir bilgi sunmaktadır.\n\nStructure of combined_movies dataset\n\n# Load the combined dataset\nload(\"combined_movies.RData\")\n\n# Show structure\nstr(combined_movies)\n\nClasses 'tbl_df', 'tbl' and 'data.frame':   67465 obs. of  25 variables:\n $ title      : chr  \"$\" \"$1000 a Touchdown\" \"$21 a Day Once a Month\" \"$40,000\" ...\n $ year       : int  1971 1939 1941 1996 1975 2000 2002 2002 1987 1917 ...\n $ length     : int  121 71 7 70 71 91 93 25 97 61 ...\n $ budget     : int  NA NA NA NA NA NA NA NA NA NA ...\n $ rating     : num  6.4 6 8.2 8.2 3.4 4.3 5.3 6.7 6.6 6 ...\n $ votes      : int  348 20 5 6 17 45 200 24 18 51 ...\n $ r1         : num  4.5 0 0 14.5 24.5 4.5 4.5 4.5 4.5 4.5 ...\n $ r2         : num  4.5 14.5 0 0 4.5 4.5 0 4.5 4.5 0 ...\n $ r3         : num  4.5 4.5 0 0 0 4.5 4.5 4.5 4.5 4.5 ...\n $ r4         : num  4.5 24.5 0 0 14.5 14.5 4.5 4.5 0 4.5 ...\n $ r5         : num  14.5 14.5 0 0 14.5 14.5 24.5 4.5 0 4.5 ...\n $ r6         : num  24.5 14.5 24.5 0 4.5 14.5 24.5 14.5 0 44.5 ...\n $ r7         : num  24.5 14.5 0 0 0 4.5 14.5 14.5 34.5 14.5 ...\n $ r8         : num  14.5 4.5 44.5 0 0 4.5 4.5 14.5 14.5 4.5 ...\n $ r9         : num  4.5 4.5 24.5 34.5 0 14.5 4.5 4.5 4.5 4.5 ...\n $ r10        : num  4.5 14.5 24.5 45.5 24.5 14.5 14.5 14.5 24.5 4.5 ...\n $ mpaa       : chr  \"\" \"\" \"\" \"\" ...\n $ Action     : int  0 0 0 0 0 0 1 0 0 0 ...\n $ Animation  : int  0 0 1 0 0 0 0 0 0 0 ...\n $ Comedy     : int  1 1 0 1 0 0 0 0 0 0 ...\n $ Drama      : int  1 0 0 0 0 1 1 0 1 0 ...\n $ Documentary: int  0 0 0 0 0 0 0 1 0 0 ...\n $ Romance    : int  0 0 0 0 0 0 0 0 0 0 ...\n $ Short      : int  0 0 1 0 0 0 0 1 0 0 ...\n $ country    : chr  \"Global\" \"Global\" \"Global\" \"Global\" ...\n\n\n\nNumber of rows and columns\n\n# Number of rows and columns\ndim(combined_movies)\n\n[1] 67465    25\n\n\n\n\nNames of variables\n\n# Names of variables\nnames(combined_movies)\n\n [1] \"title\"       \"year\"        \"length\"      \"budget\"      \"rating\"     \n [6] \"votes\"       \"r1\"          \"r2\"          \"r3\"          \"r4\"         \n[11] \"r5\"          \"r6\"          \"r7\"          \"r8\"          \"r9\"         \n[16] \"r10\"         \"mpaa\"        \"Action\"      \"Animation\"   \"Comedy\"     \n[21] \"Drama\"       \"Documentary\" \"Romance\"     \"Short\"       \"country\"    \n\n\n\n\nFirst 6 rows of data\n\n# First 6 rows of data\nhead(combined_movies)\n\n                     title year length budget rating votes   r1   r2  r3   r4\n1                        $ 1971    121     NA    6.4   348  4.5  4.5 4.5  4.5\n2        $1000 a Touchdown 1939     71     NA    6.0    20  0.0 14.5 4.5 24.5\n3   $21 a Day Once a Month 1941      7     NA    8.2     5  0.0  0.0 0.0  0.0\n4                  $40,000 1996     70     NA    8.2     6 14.5  0.0 0.0  0.0\n5 $50,000 Climax Show, The 1975     71     NA    3.4    17 24.5  4.5 0.0 14.5\n6                    $pent 2000     91     NA    4.3    45  4.5  4.5 4.5 14.5\n    r5   r6   r7   r8   r9  r10 mpaa Action Animation Comedy Drama Documentary\n1 14.5 24.5 24.5 14.5  4.5  4.5           0         0      1     1           0\n2 14.5 14.5 14.5  4.5  4.5 14.5           0         0      1     0           0\n3  0.0 24.5  0.0 44.5 24.5 24.5           0         1      0     0           0\n4  0.0  0.0  0.0  0.0 34.5 45.5           0         0      1     0           0\n5 14.5  4.5  0.0  0.0  0.0 24.5           0         0      0     0           0\n6 14.5 14.5  4.5  4.5 14.5 14.5           0         0      0     1           0\n  Romance Short country\n1       0     0  Global\n2       0     0  Global\n3       0     1  Global\n4       0     0  Global\n5       0     0  Global\n6       0     0  Global"
  },
  {
    "objectID": "project.html#linear-regression-model",
    "href": "project.html#linear-regression-model",
    "title": "Project Genre Matters: Exploring Film Audience Preferences",
    "section": "4. Linear Regression Model",
    "text": "4. Linear Regression Model\n\nlibrary(ggplot2)\nlibrary(patchwork)\n\nWarning: package 'patchwork' was built under R version 4.4.3\n\ncombined_movies$log_budget &lt;- log10(combined_movies$budget)\n\nbase_theme &lt;- theme_minimal(base_size = 13) +\n  theme(\n    plot.title = element_text(size = 13, face = \"bold\", hjust = 0.5),\n    axis.title = element_text(size = 11),\n    axis.text.x = element_text(angle = 30, hjust = 1),\n    plot.margin = margin(10, 10, 10, 10)\n  )\n\ng1 &lt;- ggplot(combined_movies, aes(x = log_budget, y = rating)) +\n  geom_point(alpha = 0.3, size = 0.5) +\n  geom_smooth(method = \"lm\", se = TRUE, color = \"red\") +\n  labs(title = \"Log(Budget)\", x = \"Log10(Budget)\", y = \"IMDb Rating\") +\n  base_theme\n\ng2 &lt;- ggplot(combined_movies, aes(x = votes, y = rating)) +\n  geom_point(alpha = 0.3, size = 0.5) +\n  geom_smooth(method = \"lm\", se = TRUE, color = \"blue\") +\n  labs(title = \"Votes\", x = \"Number of Votes\", y = \"\") +\n  base_theme\n\n\n(g1 | g2 ) + \n  plot_layout(guides = \"collect\") + \n  plot_annotation(\n    title = \"IMDb Rating Regressions by Predictor\",\n    theme = theme(plot.title = element_text(hjust = 0.5, size = 16, face = \"bold\"))\n  )\n\nWarning: Removed 62282 rows containing non-finite outside the scale range\n(`stat_smooth()`).\n\n\nWarning: Removed 62250 rows containing missing values or values outside the scale range\n(`geom_point()`).\n\n\nWarning: Removed 8677 rows containing non-finite outside the scale range\n(`stat_smooth()`).\n\n\nWarning: Removed 8677 rows containing missing values or values outside the scale range\n(`geom_point()`).\n\n\n\n\n\n\n\n\n\nBu grafik, IMDb değerlendirme puanlarının bütçe ve oy sayısıyla olan bağlantısını regresyon analizleri aracılığıyla göstermektedir.\n\nSol grafikte: Logaritmik bütçe ile IMDb puanı arasındaki ilişki görülmektedir. Eğilim çizgisi işaret etmektedir ki, bütçedeki artışla birlikte puanlarda hafif bir düşüş eğilimi vardır; ancak bu bağ oldukça zayıf düzeydedir.\nSağ grafikte: Oy sayısı ile IMDb puanı arasındaki ilişki oldukça güçlü ve olumlu bir karakter sergilemektedir. Oy sayısı arttıkça IMDb puanı da yükselmekte, bu da popüler filmlerin genellikle daha yüksek değerlendirmelere sahip olduğunu ortaya koymaktadır.\n\nPuanlar açısından oy sayısının etkisi daha belirginken, bütçenin etkisi sınırlı ve negatif bir niteliktedir.\n\nlibrary(dplyr)\nlibrary(car) \n\nWarning: package 'car' was built under R version 4.4.3\n\n\nZorunlu paket yükleniyor: carData\n\n\nWarning: package 'carData' was built under R version 4.4.3\n\n\n\nAttaching package: 'car'\n\n\nThe following object is masked from 'package:dplyr':\n\n    recode\n\nmovies_model &lt;- combined_movies %&gt;%\n  filter(!is.na(rating), !is.na(budget), !is.na(votes), !is.na(year)) %&gt;%\n  mutate(log_budget = log10(budget + 1))\n\n\nmodel &lt;- lm(rating ~ log_budget + votes + year, data = movies_model)\n\nsummary(model)\n\n\nCall:\nlm(formula = rating ~ log_budget + votes + year, data = movies_model)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-6.0606 -0.8093  0.1959  0.9841  3.9368 \n\nCoefficients:\n              Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  1.667e+01  1.860e+00   8.963  &lt; 2e-16 ***\nlog_budget  -2.312e-01  1.685e-02 -13.725  &lt; 2e-16 ***\nvotes        4.538e-05  1.862e-06  24.365  &lt; 2e-16 ***\nyear        -4.696e-03  9.428e-04  -4.980 6.55e-07 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.46 on 5211 degrees of freedom\nMultiple R-squared:  0.1104,    Adjusted R-squared:  0.1099 \nF-statistic: 215.5 on 3 and 5211 DF,  p-value: &lt; 2.2e-16\n\nvif(model)\n\nlog_budget      votes       year \n  1.165258   1.148283   1.033985 \n\npar(mfrow = c(2, 2))\nplot(model)\n\n\n\n\n\n\n\n\n\n4.1 Diagnostic Evaluation of the Linear Regression Model\nBu dört grafik, doğrusal regresyon modelinin temel varsayımlarını test etmek için kullanılmaktadır.\n\nResiduals vs Fitted grafiği, artıkların tahmin edilen değerlere göre nasıl dağıldığını gösterir. Grafikte hafif bir eğrilik görülmektedir; bu durum, doğrusal ilişki varsayımının tam olarak sağlanmadığını düşündürmektedir.\nNormal Q-Q Plot, artıkların normal dağılıma ne ölçüde uyduğunu göstermektedir. Uç noktalarda sapmalar mevcuttur; bu da artıkların tam anlamıyla normal şekilde dağılmadığını ortaya koyar.\nScale-Location grafiği, varyansın sabitliğini (homoskedastisite) inceler. Artan tahmin değerleriyle birlikte artıkların yayılımının da arttığı gözlemlenmektedir; bu durum, modelde heteroskedastisite (değişken varyans) sorunu olduğunu göstermektedir.\nResiduals vs Leverage grafiği, model üzerindeki etkili gözlemleri belirlemeyi amaçlar. Grafikte bazı gözlemler (örneğin 2979 ve 21798), Cook’s distance sınırını aşmaktadır; bu da bu gözlemlerin model üzerinde orantısız bir etkisi olabileceğini göstermektedir.\n\n\n\n\n\n\n\n\n\n\nTanı Grafiği\nAmaç\nGözlem\nYorum\n\n\n\n\nResiduals vs Fitted\nDoğrusallığı kontrol etmek\nHafif eğrilik gözlemleniyor\nModelde doğrusal olmayan bir ilişki olabilir\n\n\nNormal Q-Q Plot\nArtıkların normalliğini değerlendirmek\nUç değerlerde sapma var\nArtıklar tam olarak normal dağılmıyor olabilir\n\n\nScale-Location\nVaryansın sabitliğini (homoskedastisite) test etmek\nTahminler arttıkça yayılım da artıyor\nHeteroskedastisite (değişken varyans) olabilir\n\n\nResiduals vs Leverage\nAykırı ve etkili gözlemleri tespit etmek\nBazı noktalar Cook’s distance sınırını aşıyor (örn. 2979, 21798)\nModel üzerinde etkili (influential) gözlemler olabilir\n\n\n\n\nsummary(model)\n\n\nCall:\nlm(formula = rating ~ log_budget + votes + year, data = movies_model)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-6.0606 -0.8093  0.1959  0.9841  3.9368 \n\nCoefficients:\n              Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  1.667e+01  1.860e+00   8.963  &lt; 2e-16 ***\nlog_budget  -2.312e-01  1.685e-02 -13.725  &lt; 2e-16 ***\nvotes        4.538e-05  1.862e-06  24.365  &lt; 2e-16 ***\nyear        -4.696e-03  9.428e-04  -4.980 6.55e-07 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.46 on 5211 degrees of freedom\nMultiple R-squared:  0.1104,    Adjusted R-squared:  0.1099 \nF-statistic: 215.5 on 3 and 5211 DF,  p-value: &lt; 2.2e-16\n\n\n\n\n4.2 Interpretation of Regression Output\nlog_budget katsayısı -0.231 ve istatistiksel olarak anlamlıdır (p &lt; 0.001).\nBu, bütçe arttıkça IMDb puanının hafifçe azalma eğiliminde olduğunu gösterir. Yani, yüksek bütçeli filmler her zaman daha yüksek puan almamaktadır.\nvotes katsayısı 0.000045 ve oldukça anlamlıdır.\nOy sayısı arttıkça IMDb puanının da artma eğiliminde olduğu görülmektedir. Bu, popüler filmlerin genellikle daha yüksek puanlandığını göstermektedir.\n\n\n4.3 Model Performans\nR² = 0.1104: Bağımsız değişkenler, IMDb puanlarındaki toplam varyansın yaklaşık %11’ini açıklamaktadır. Bu oldukça düşük bir orandır ve filmlerin puanlarını etkileyen birçok başka faktör olduğunu göstermektedir.\nResidual standard error: 1.46 — Ortalama hata yaklaşık 1.46 puan civarındadır.\nF-istatistiği anlamlıdır (p &lt; 0.001), yani model genel olarak istatistiksel olarak anlamlıdır.\nModeldeki tüm değişkenler istatistiksel olarak anlamlıdır. Ancak düşük R² değeri, IMDb puanlarının yalnızca bütçe, oy sayısı ve yıl gibi faktörlerle tam olarak açıklanamayacağını; hikâye, oyunculuk, yönetmenlik gibi daha soyut değişkenlerin de önemli rol oynadığını göstermektedir."
  }
]