[
  {
    "objectID": "project.html",
    "href": "project.html",
    "title": "Project X",
    "section": "",
    "text": "Welcome to my/our project page.\nKeep an eye on this space to stay updated with my project activities.\n(The titles below are provided as examples; please feel free to adjust them as necessary.)"
  },
  {
    "objectID": "project.html#data-source",
    "href": "project.html#data-source",
    "title": "Project X",
    "section": "2.1 Data Source",
    "text": "2.1 Data Source\nxxxxxx"
  },
  {
    "objectID": "project.html#general-information-about-data",
    "href": "project.html#general-information-about-data",
    "title": "Project X",
    "section": "2.2 General Information About Data",
    "text": "2.2 General Information About Data\nxxxxxx"
  },
  {
    "objectID": "project.html#reason-of-choice",
    "href": "project.html#reason-of-choice",
    "title": "Project X",
    "section": "2.3 Reason of Choice",
    "text": "2.3 Reason of Choice\nxxxxxx"
  },
  {
    "objectID": "project.html#preprocessing",
    "href": "project.html#preprocessing",
    "title": "Project X",
    "section": "2.4 Preprocessing",
    "text": "2.4 Preprocessing\nxxxxxx"
  },
  {
    "objectID": "project.html#exploratory-data-analysis",
    "href": "project.html#exploratory-data-analysis",
    "title": "Project X",
    "section": "3.1 Exploratory Data Analysis",
    "text": "3.1 Exploratory Data Analysis\nxxxxxx"
  },
  {
    "objectID": "project.html#trend-analysis",
    "href": "project.html#trend-analysis",
    "title": "Project X",
    "section": "3.2 Trend Analysis",
    "text": "3.2 Trend Analysis\nxxxxxx"
  },
  {
    "objectID": "project.html#model-fitting",
    "href": "project.html#model-fitting",
    "title": "Project X",
    "section": "3.3 Model Fitting",
    "text": "3.3 Model Fitting\nxxxxxx"
  },
  {
    "objectID": "project.html#results",
    "href": "project.html#results",
    "title": "Project X",
    "section": "3.4 Results",
    "text": "3.4 Results\nxxxxxx"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Welcome to My Analytics Lab",
    "section": "",
    "text": "Hello! I‚Äôm Eda G√∂nen.\nWelcome to my personal website! Here, I share my work in data analytics, blog posts, and a few different projects. I enjoy working with data and finding new ways to understand it. I‚Äôll also be sharing my thoughts on technology from time to time.\nStay tuned, there‚Äôs plenty to discover and learn together!"
  },
  {
    "objectID": "index.html#deneme",
    "href": "index.html#deneme",
    "title": "Welcome to My Analytics Lab",
    "section": "Deneme",
    "text": "Deneme"
  },
  {
    "objectID": "assignments/statisticsofmrcars.html",
    "href": "assignments/statisticsofmrcars.html",
    "title": "Statistical Analysis",
    "section": "",
    "text": "In R, data(mtcars) loads the mtcars dataset, which contains features of 32 cars. str(mtcars) then displays the dataset‚Äôs structure, revealing the types and initial values of its columns, providing a quick overview.\n\ndata(mtcars)\nstr(mtcars)\n\n'data.frame':   32 obs. of  11 variables:\n $ mpg : num  21 21 22.8 21.4 18.7 18.1 14.3 24.4 22.8 19.2 ...\n $ cyl : num  6 6 4 6 8 6 8 4 4 6 ...\n $ disp: num  160 160 108 258 360 ...\n $ hp  : num  110 110 93 110 175 105 245 62 95 123 ...\n $ drat: num  3.9 3.9 3.85 3.08 3.15 2.76 3.21 3.69 3.92 3.92 ...\n $ wt  : num  2.62 2.88 2.32 3.21 3.44 ...\n $ qsec: num  16.5 17 18.6 19.4 17 ...\n $ vs  : num  0 0 1 1 0 1 0 1 1 1 ...\n $ am  : num  1 1 1 0 0 0 0 0 0 0 ...\n $ gear: num  4 4 4 3 3 3 3 4 4 4 ...\n $ carb: num  4 4 1 1 2 1 4 2 2 4 ...\n\n\n\n\n\nThis R code calculates basic statistics for numerical columns in the mtcars dataset. It defines a function, compute_stats, to find the mean, median, variance, IQR, min, and max of a numeric vector, handling potential missing values. A for loop iterates through each column of mtcars, applying compute_stats to numerical ones. The results, with column names, are stored in a list and printed, providing a summary of each numerical column‚Äôs statistics.\n\n# ƒ∞statistikleri hesaplayan fonksiyon\ncompute_stats &lt;- function(x) {\n  # Girdi sayƒ±sal mƒ± kontrol et\n  if (!is.numeric(x)) {\n    stop(\"Hata: Girdi sayƒ±sal bir vekt√∂r olmalƒ±dƒ±r.\")\n  }\n\n  # ƒ∞statistik hesaplamalarƒ±\n  mean_x &lt;- mean(x, na.rm = TRUE)\n  median_x &lt;- median(x, na.rm = TRUE)\n  var_x &lt;- var(x, na.rm = TRUE)\n  iqr_x &lt;- IQR(x, na.rm = TRUE)\n  min_x &lt;- min(x, na.rm = TRUE)\n  max_x &lt;- max(x, na.rm = TRUE)\n\n  # Sonu√ßlarƒ± i√ßeren listeyi d√∂nd√ºr\n  compute_stats_list &lt;- list(\n    mean = mean_x,\n    median = median_x,\n    variance = var_x,\n    IQR = iqr_x,\n    min = min_x,\n    maks = max_x\n  )\n\n  return(compute_stats_list)\n}\n\n# mtcars veri seti i√ßin t√ºm sayƒ±sal s√ºtunlarƒ±n istatistiklerini hesapla\nmtcars_istatistikleri &lt;- list() # Bo≈ü bir liste olu≈ütur\n\nfor (header in names(mtcars)) {\n  if (is.numeric(mtcars[[header]])) {\n    mtcars_istatistikleri[[header]] &lt;- compute_stats(mtcars[[header]]) # Sonu√ßlarƒ± listeye ekle\n  }\n}\n\n# Sonu√ßlarƒ± yazdƒ±r\nprint(mtcars_istatistikleri)\n\n$mpg\n$mpg$mean\n[1] 20.09062\n\n$mpg$median\n[1] 19.2\n\n$mpg$variance\n[1] 36.3241\n\n$mpg$IQR\n[1] 7.375\n\n$mpg$min\n[1] 10.4\n\n$mpg$maks\n[1] 33.9\n\n\n$cyl\n$cyl$mean\n[1] 6.1875\n\n$cyl$median\n[1] 6\n\n$cyl$variance\n[1] 3.189516\n\n$cyl$IQR\n[1] 4\n\n$cyl$min\n[1] 4\n\n$cyl$maks\n[1] 8\n\n\n$disp\n$disp$mean\n[1] 230.7219\n\n$disp$median\n[1] 196.3\n\n$disp$variance\n[1] 15360.8\n\n$disp$IQR\n[1] 205.175\n\n$disp$min\n[1] 71.1\n\n$disp$maks\n[1] 472\n\n\n$hp\n$hp$mean\n[1] 146.6875\n\n$hp$median\n[1] 123\n\n$hp$variance\n[1] 4700.867\n\n$hp$IQR\n[1] 83.5\n\n$hp$min\n[1] 52\n\n$hp$maks\n[1] 335\n\n\n$drat\n$drat$mean\n[1] 3.596563\n\n$drat$median\n[1] 3.695\n\n$drat$variance\n[1] 0.2858814\n\n$drat$IQR\n[1] 0.84\n\n$drat$min\n[1] 2.76\n\n$drat$maks\n[1] 4.93\n\n\n$wt\n$wt$mean\n[1] 3.21725\n\n$wt$median\n[1] 3.325\n\n$wt$variance\n[1] 0.957379\n\n$wt$IQR\n[1] 1.02875\n\n$wt$min\n[1] 1.513\n\n$wt$maks\n[1] 5.424\n\n\n$qsec\n$qsec$mean\n[1] 17.84875\n\n$qsec$median\n[1] 17.71\n\n$qsec$variance\n[1] 3.193166\n\n$qsec$IQR\n[1] 2.0075\n\n$qsec$min\n[1] 14.5\n\n$qsec$maks\n[1] 22.9\n\n\n$vs\n$vs$mean\n[1] 0.4375\n\n$vs$median\n[1] 0\n\n$vs$variance\n[1] 0.2540323\n\n$vs$IQR\n[1] 1\n\n$vs$min\n[1] 0\n\n$vs$maks\n[1] 1\n\n\n$am\n$am$mean\n[1] 0.40625\n\n$am$median\n[1] 0\n\n$am$variance\n[1] 0.2489919\n\n$am$IQR\n[1] 1\n\n$am$min\n[1] 0\n\n$am$maks\n[1] 1\n\n\n$gear\n$gear$mean\n[1] 3.6875\n\n$gear$median\n[1] 4\n\n$gear$variance\n[1] 0.5443548\n\n$gear$IQR\n[1] 1\n\n$gear$min\n[1] 3\n\n$gear$maks\n[1] 5\n\n\n$carb\n$carb$mean\n[1] 2.8125\n\n$carb$median\n[1] 2\n\n$carb$variance\n[1] 2.608871\n\n$carb$IQR\n[1] 2\n\n$carb$min\n[1] 1\n\n$carb$maks\n[1] 8\n\n\nTo automate statistical analysis of numerical columns within the mtcars dataset, a for loop iterates through each column name. Utilizing is.numeric(), the loop identifies numerical columns and applies the compute_stats function. This function calculates key statistics like mean, median, and variance, returning them in a named list. The loop then stores these results, indexed by column names, within a comprehensive list, which is subsequently printed. This approach efficiently provides a structured statistical overview of all numerical columns in the dataset.\n\n\n\nThe sapply function in R is a user-friendly and efficient way to apply a function over a list or vector. In the context of the mtcars dataset, sapply iterates through each column, applying the compute_stats function to those that are numeric. This streamlines the process of calculating statistics for multiple columns, returning the results in a simplified format, such as a vector or matrix. Its ability to directly handle data frames makes it a powerful tool for quick statistical analysis.\n\n# sapply ile t√ºm s√ºtunlara compute_stats fonksiyonunu uygula\nmtcars_istatistikleri_sapply &lt;- sapply(mtcars, compute_stats)\n\n# Sonu√ßlarƒ± yazdƒ±r\nprint(mtcars_istatistikleri_sapply)\n\n         mpg      cyl      disp     hp       drat      wt       qsec    \nmean     20.09062 6.1875   230.7219 146.6875 3.596563  3.21725  17.84875\nmedian   19.2     6        196.3    123      3.695     3.325    17.71   \nvariance 36.3241  3.189516 15360.8  4700.867 0.2858814 0.957379 3.193166\nIQR      7.375    4        205.175  83.5     0.84      1.02875  2.0075  \nmin      10.4     4        71.1     52       2.76      1.513    14.5    \nmaks     33.9     8        472      335      4.93      5.424    22.9    \n         vs        am        gear      carb    \nmean     0.4375    0.40625   3.6875    2.8125  \nmedian   0         0         4         2       \nvariance 0.2540323 0.2489919 0.5443548 2.608871\nIQR      1         1         1         2       \nmin      0         0         3         1       \nmaks     1         1         5         8       \n\n\nThe apply function in R is designed to apply a function over the rows or columns of a matrix or array. In this scenario, the mtcars data frame is first converted to a matrix. Then, apply is used to iterate over the columns, applying the compute_stats function to each. This approach allows for consistent application of statistical calculations across all columns, returning the results in a structured format. While apply is versatile, it requires the data to be in a matrix format, making it slightly less direct for data frames compared to sapply.\n\n# apply ile t√ºm s√ºtunlara compute_stats fonksiyonunu uygula\nmtcars_istatistikleri_apply &lt;- apply(mtcars, MARGIN = 2, compute_stats)\n\n# Sonu√ßlarƒ± yazdƒ±r\nprint(mtcars_istatistikleri_apply)\n\n$mpg\n$mpg$mean\n[1] 20.09062\n\n$mpg$median\n[1] 19.2\n\n$mpg$variance\n[1] 36.3241\n\n$mpg$IQR\n[1] 7.375\n\n$mpg$min\n[1] 10.4\n\n$mpg$maks\n[1] 33.9\n\n\n$cyl\n$cyl$mean\n[1] 6.1875\n\n$cyl$median\n[1] 6\n\n$cyl$variance\n[1] 3.189516\n\n$cyl$IQR\n[1] 4\n\n$cyl$min\n[1] 4\n\n$cyl$maks\n[1] 8\n\n\n$disp\n$disp$mean\n[1] 230.7219\n\n$disp$median\n[1] 196.3\n\n$disp$variance\n[1] 15360.8\n\n$disp$IQR\n[1] 205.175\n\n$disp$min\n[1] 71.1\n\n$disp$maks\n[1] 472\n\n\n$hp\n$hp$mean\n[1] 146.6875\n\n$hp$median\n[1] 123\n\n$hp$variance\n[1] 4700.867\n\n$hp$IQR\n[1] 83.5\n\n$hp$min\n[1] 52\n\n$hp$maks\n[1] 335\n\n\n$drat\n$drat$mean\n[1] 3.596563\n\n$drat$median\n[1] 3.695\n\n$drat$variance\n[1] 0.2858814\n\n$drat$IQR\n[1] 0.84\n\n$drat$min\n[1] 2.76\n\n$drat$maks\n[1] 4.93\n\n\n$wt\n$wt$mean\n[1] 3.21725\n\n$wt$median\n[1] 3.325\n\n$wt$variance\n[1] 0.957379\n\n$wt$IQR\n[1] 1.02875\n\n$wt$min\n[1] 1.513\n\n$wt$maks\n[1] 5.424\n\n\n$qsec\n$qsec$mean\n[1] 17.84875\n\n$qsec$median\n[1] 17.71\n\n$qsec$variance\n[1] 3.193166\n\n$qsec$IQR\n[1] 2.0075\n\n$qsec$min\n[1] 14.5\n\n$qsec$maks\n[1] 22.9\n\n\n$vs\n$vs$mean\n[1] 0.4375\n\n$vs$median\n[1] 0\n\n$vs$variance\n[1] 0.2540323\n\n$vs$IQR\n[1] 1\n\n$vs$min\n[1] 0\n\n$vs$maks\n[1] 1\n\n\n$am\n$am$mean\n[1] 0.40625\n\n$am$median\n[1] 0\n\n$am$variance\n[1] 0.2489919\n\n$am$IQR\n[1] 1\n\n$am$min\n[1] 0\n\n$am$maks\n[1] 1\n\n\n$gear\n$gear$mean\n[1] 3.6875\n\n$gear$median\n[1] 4\n\n$gear$variance\n[1] 0.5443548\n\n$gear$IQR\n[1] 1\n\n$gear$min\n[1] 3\n\n$gear$maks\n[1] 5\n\n\n$carb\n$carb$mean\n[1] 2.8125\n\n$carb$median\n[1] 2\n\n$carb$variance\n[1] 2.608871\n\n$carb$IQR\n[1] 2\n\n$carb$min\n[1] 1\n\n$carb$maks\n[1] 8",
    "crumbs": [
      "MRCars Statistics"
    ]
  },
  {
    "objectID": "assignments/statisticsofmrcars.html#statistical-analysis-of-the-mtcars-dataset-in-r",
    "href": "assignments/statisticsofmrcars.html#statistical-analysis-of-the-mtcars-dataset-in-r",
    "title": "Statistical Analysis",
    "section": "",
    "text": "In R, data(mtcars) loads the mtcars dataset, which contains features of 32 cars. str(mtcars) then displays the dataset‚Äôs structure, revealing the types and initial values of its columns, providing a quick overview.\n\ndata(mtcars)\nstr(mtcars)\n\n'data.frame':   32 obs. of  11 variables:\n $ mpg : num  21 21 22.8 21.4 18.7 18.1 14.3 24.4 22.8 19.2 ...\n $ cyl : num  6 6 4 6 8 6 8 4 4 6 ...\n $ disp: num  160 160 108 258 360 ...\n $ hp  : num  110 110 93 110 175 105 245 62 95 123 ...\n $ drat: num  3.9 3.9 3.85 3.08 3.15 2.76 3.21 3.69 3.92 3.92 ...\n $ wt  : num  2.62 2.88 2.32 3.21 3.44 ...\n $ qsec: num  16.5 17 18.6 19.4 17 ...\n $ vs  : num  0 0 1 1 0 1 0 1 1 1 ...\n $ am  : num  1 1 1 0 0 0 0 0 0 0 ...\n $ gear: num  4 4 4 3 3 3 3 4 4 4 ...\n $ carb: num  4 4 1 1 2 1 4 2 2 4 ...\n\n\n\n\n\nThis R code calculates basic statistics for numerical columns in the mtcars dataset. It defines a function, compute_stats, to find the mean, median, variance, IQR, min, and max of a numeric vector, handling potential missing values. A for loop iterates through each column of mtcars, applying compute_stats to numerical ones. The results, with column names, are stored in a list and printed, providing a summary of each numerical column‚Äôs statistics.\n\n# ƒ∞statistikleri hesaplayan fonksiyon\ncompute_stats &lt;- function(x) {\n  # Girdi sayƒ±sal mƒ± kontrol et\n  if (!is.numeric(x)) {\n    stop(\"Hata: Girdi sayƒ±sal bir vekt√∂r olmalƒ±dƒ±r.\")\n  }\n\n  # ƒ∞statistik hesaplamalarƒ±\n  mean_x &lt;- mean(x, na.rm = TRUE)\n  median_x &lt;- median(x, na.rm = TRUE)\n  var_x &lt;- var(x, na.rm = TRUE)\n  iqr_x &lt;- IQR(x, na.rm = TRUE)\n  min_x &lt;- min(x, na.rm = TRUE)\n  max_x &lt;- max(x, na.rm = TRUE)\n\n  # Sonu√ßlarƒ± i√ßeren listeyi d√∂nd√ºr\n  compute_stats_list &lt;- list(\n    mean = mean_x,\n    median = median_x,\n    variance = var_x,\n    IQR = iqr_x,\n    min = min_x,\n    maks = max_x\n  )\n\n  return(compute_stats_list)\n}\n\n# mtcars veri seti i√ßin t√ºm sayƒ±sal s√ºtunlarƒ±n istatistiklerini hesapla\nmtcars_istatistikleri &lt;- list() # Bo≈ü bir liste olu≈ütur\n\nfor (header in names(mtcars)) {\n  if (is.numeric(mtcars[[header]])) {\n    mtcars_istatistikleri[[header]] &lt;- compute_stats(mtcars[[header]]) # Sonu√ßlarƒ± listeye ekle\n  }\n}\n\n# Sonu√ßlarƒ± yazdƒ±r\nprint(mtcars_istatistikleri)\n\n$mpg\n$mpg$mean\n[1] 20.09062\n\n$mpg$median\n[1] 19.2\n\n$mpg$variance\n[1] 36.3241\n\n$mpg$IQR\n[1] 7.375\n\n$mpg$min\n[1] 10.4\n\n$mpg$maks\n[1] 33.9\n\n\n$cyl\n$cyl$mean\n[1] 6.1875\n\n$cyl$median\n[1] 6\n\n$cyl$variance\n[1] 3.189516\n\n$cyl$IQR\n[1] 4\n\n$cyl$min\n[1] 4\n\n$cyl$maks\n[1] 8\n\n\n$disp\n$disp$mean\n[1] 230.7219\n\n$disp$median\n[1] 196.3\n\n$disp$variance\n[1] 15360.8\n\n$disp$IQR\n[1] 205.175\n\n$disp$min\n[1] 71.1\n\n$disp$maks\n[1] 472\n\n\n$hp\n$hp$mean\n[1] 146.6875\n\n$hp$median\n[1] 123\n\n$hp$variance\n[1] 4700.867\n\n$hp$IQR\n[1] 83.5\n\n$hp$min\n[1] 52\n\n$hp$maks\n[1] 335\n\n\n$drat\n$drat$mean\n[1] 3.596563\n\n$drat$median\n[1] 3.695\n\n$drat$variance\n[1] 0.2858814\n\n$drat$IQR\n[1] 0.84\n\n$drat$min\n[1] 2.76\n\n$drat$maks\n[1] 4.93\n\n\n$wt\n$wt$mean\n[1] 3.21725\n\n$wt$median\n[1] 3.325\n\n$wt$variance\n[1] 0.957379\n\n$wt$IQR\n[1] 1.02875\n\n$wt$min\n[1] 1.513\n\n$wt$maks\n[1] 5.424\n\n\n$qsec\n$qsec$mean\n[1] 17.84875\n\n$qsec$median\n[1] 17.71\n\n$qsec$variance\n[1] 3.193166\n\n$qsec$IQR\n[1] 2.0075\n\n$qsec$min\n[1] 14.5\n\n$qsec$maks\n[1] 22.9\n\n\n$vs\n$vs$mean\n[1] 0.4375\n\n$vs$median\n[1] 0\n\n$vs$variance\n[1] 0.2540323\n\n$vs$IQR\n[1] 1\n\n$vs$min\n[1] 0\n\n$vs$maks\n[1] 1\n\n\n$am\n$am$mean\n[1] 0.40625\n\n$am$median\n[1] 0\n\n$am$variance\n[1] 0.2489919\n\n$am$IQR\n[1] 1\n\n$am$min\n[1] 0\n\n$am$maks\n[1] 1\n\n\n$gear\n$gear$mean\n[1] 3.6875\n\n$gear$median\n[1] 4\n\n$gear$variance\n[1] 0.5443548\n\n$gear$IQR\n[1] 1\n\n$gear$min\n[1] 3\n\n$gear$maks\n[1] 5\n\n\n$carb\n$carb$mean\n[1] 2.8125\n\n$carb$median\n[1] 2\n\n$carb$variance\n[1] 2.608871\n\n$carb$IQR\n[1] 2\n\n$carb$min\n[1] 1\n\n$carb$maks\n[1] 8\n\n\nTo automate statistical analysis of numerical columns within the mtcars dataset, a for loop iterates through each column name. Utilizing is.numeric(), the loop identifies numerical columns and applies the compute_stats function. This function calculates key statistics like mean, median, and variance, returning them in a named list. The loop then stores these results, indexed by column names, within a comprehensive list, which is subsequently printed. This approach efficiently provides a structured statistical overview of all numerical columns in the dataset.\n\n\n\nThe sapply function in R is a user-friendly and efficient way to apply a function over a list or vector. In the context of the mtcars dataset, sapply iterates through each column, applying the compute_stats function to those that are numeric. This streamlines the process of calculating statistics for multiple columns, returning the results in a simplified format, such as a vector or matrix. Its ability to directly handle data frames makes it a powerful tool for quick statistical analysis.\n\n# sapply ile t√ºm s√ºtunlara compute_stats fonksiyonunu uygula\nmtcars_istatistikleri_sapply &lt;- sapply(mtcars, compute_stats)\n\n# Sonu√ßlarƒ± yazdƒ±r\nprint(mtcars_istatistikleri_sapply)\n\n         mpg      cyl      disp     hp       drat      wt       qsec    \nmean     20.09062 6.1875   230.7219 146.6875 3.596563  3.21725  17.84875\nmedian   19.2     6        196.3    123      3.695     3.325    17.71   \nvariance 36.3241  3.189516 15360.8  4700.867 0.2858814 0.957379 3.193166\nIQR      7.375    4        205.175  83.5     0.84      1.02875  2.0075  \nmin      10.4     4        71.1     52       2.76      1.513    14.5    \nmaks     33.9     8        472      335      4.93      5.424    22.9    \n         vs        am        gear      carb    \nmean     0.4375    0.40625   3.6875    2.8125  \nmedian   0         0         4         2       \nvariance 0.2540323 0.2489919 0.5443548 2.608871\nIQR      1         1         1         2       \nmin      0         0         3         1       \nmaks     1         1         5         8       \n\n\nThe apply function in R is designed to apply a function over the rows or columns of a matrix or array. In this scenario, the mtcars data frame is first converted to a matrix. Then, apply is used to iterate over the columns, applying the compute_stats function to each. This approach allows for consistent application of statistical calculations across all columns, returning the results in a structured format. While apply is versatile, it requires the data to be in a matrix format, making it slightly less direct for data frames compared to sapply.\n\n# apply ile t√ºm s√ºtunlara compute_stats fonksiyonunu uygula\nmtcars_istatistikleri_apply &lt;- apply(mtcars, MARGIN = 2, compute_stats)\n\n# Sonu√ßlarƒ± yazdƒ±r\nprint(mtcars_istatistikleri_apply)\n\n$mpg\n$mpg$mean\n[1] 20.09062\n\n$mpg$median\n[1] 19.2\n\n$mpg$variance\n[1] 36.3241\n\n$mpg$IQR\n[1] 7.375\n\n$mpg$min\n[1] 10.4\n\n$mpg$maks\n[1] 33.9\n\n\n$cyl\n$cyl$mean\n[1] 6.1875\n\n$cyl$median\n[1] 6\n\n$cyl$variance\n[1] 3.189516\n\n$cyl$IQR\n[1] 4\n\n$cyl$min\n[1] 4\n\n$cyl$maks\n[1] 8\n\n\n$disp\n$disp$mean\n[1] 230.7219\n\n$disp$median\n[1] 196.3\n\n$disp$variance\n[1] 15360.8\n\n$disp$IQR\n[1] 205.175\n\n$disp$min\n[1] 71.1\n\n$disp$maks\n[1] 472\n\n\n$hp\n$hp$mean\n[1] 146.6875\n\n$hp$median\n[1] 123\n\n$hp$variance\n[1] 4700.867\n\n$hp$IQR\n[1] 83.5\n\n$hp$min\n[1] 52\n\n$hp$maks\n[1] 335\n\n\n$drat\n$drat$mean\n[1] 3.596563\n\n$drat$median\n[1] 3.695\n\n$drat$variance\n[1] 0.2858814\n\n$drat$IQR\n[1] 0.84\n\n$drat$min\n[1] 2.76\n\n$drat$maks\n[1] 4.93\n\n\n$wt\n$wt$mean\n[1] 3.21725\n\n$wt$median\n[1] 3.325\n\n$wt$variance\n[1] 0.957379\n\n$wt$IQR\n[1] 1.02875\n\n$wt$min\n[1] 1.513\n\n$wt$maks\n[1] 5.424\n\n\n$qsec\n$qsec$mean\n[1] 17.84875\n\n$qsec$median\n[1] 17.71\n\n$qsec$variance\n[1] 3.193166\n\n$qsec$IQR\n[1] 2.0075\n\n$qsec$min\n[1] 14.5\n\n$qsec$maks\n[1] 22.9\n\n\n$vs\n$vs$mean\n[1] 0.4375\n\n$vs$median\n[1] 0\n\n$vs$variance\n[1] 0.2540323\n\n$vs$IQR\n[1] 1\n\n$vs$min\n[1] 0\n\n$vs$maks\n[1] 1\n\n\n$am\n$am$mean\n[1] 0.40625\n\n$am$median\n[1] 0\n\n$am$variance\n[1] 0.2489919\n\n$am$IQR\n[1] 1\n\n$am$min\n[1] 0\n\n$am$maks\n[1] 1\n\n\n$gear\n$gear$mean\n[1] 3.6875\n\n$gear$median\n[1] 4\n\n$gear$variance\n[1] 0.5443548\n\n$gear$IQR\n[1] 1\n\n$gear$min\n[1] 3\n\n$gear$maks\n[1] 5\n\n\n$carb\n$carb$mean\n[1] 2.8125\n\n$carb$median\n[1] 2\n\n$carb$variance\n[1] 2.608871\n\n$carb$IQR\n[1] 2\n\n$carb$min\n[1] 1\n\n$carb$maks\n[1] 8",
    "crumbs": [
      "MRCars Statistics"
    ]
  },
  {
    "objectID": "assignments/statisticsofmrcars.html#handling-missing-values-in-the-dslabs-na_example-dataset-methods-and-comparisons",
    "href": "assignments/statisticsofmrcars.html#handling-missing-values-in-the-dslabs-na_example-dataset-methods-and-comparisons",
    "title": "Statistical Analysis",
    "section": "Handling Missing Values in the dslabs ‚Äòna_example‚Äô Dataset: Methods and Comparisons",
    "text": "Handling Missing Values in the dslabs ‚Äòna_example‚Äô Dataset: Methods and Comparisons\n\nInstalling and Loading the ‚Äòdslaps‚Äô\n\n#install.packages(\"dslabs\")\nlibrary(dslabs)\n\nWarning: package 'dslabs' was built under R version 4.4.3\n\n\nAfter successfully installing and loading the ‚Äòdslabs‚Äô library, we can now print the desired dataset.\n\nprint(na_example)\n\n   [1]  2  1  3  2  1  3  1  4  3  2  2 NA  2  2  1  4 NA  1  1  2  1  2  2  1\n  [25]  2  5 NA  2  2  3  1  2  4  1  1  1  4  5  2  3  4  1  2  4  1  1  2  1\n  [49]  5 NA NA NA  1  1  5  1  3  1 NA  4  4  7  3  2 NA NA  1 NA  4  1  2  2\n  [73]  3  2  1  2  2  4  3  4  2  3  1  3  2  1  1  1  3  1 NA  3  1  2  2  1\n  [97]  2  2  1  1  4  1  1  2  3  3  2  2  3  3  3  4  1  1  1  2 NA  4  3  4\n [121]  3  1  2  1 NA NA NA NA  1  5  1  2  1  3  5  3  2  2 NA NA NA NA  3  5\n [145]  3  1  1  4  2  4  3  3 NA  2  3  2  6 NA  1  1  2  2  1  3  1  1  5 NA\n [169] NA  2  4 NA  2  5  1  4  3  3 NA  4  3  1  4  1  1  3  1  1 NA NA  3  5\n [193]  2  2  2  3  1  2  2  3  2  1 NA  2 NA  1 NA NA  2  1  1 NA  3 NA  1  2\n [217]  2  1  3  2  2  1  1  2  3  1  1  1  4  3  4  2  2  1  4  1 NA  5  1  4\n [241] NA  3 NA NA  1  1  5  2  3  3  2  4 NA  3  2  5 NA  2  3  4  6  2  2  2\n [265] NA  2 NA  2 NA  3  3  2  2  4  3  1  4  2 NA  2  4 NA  6  2  3  1 NA  2\n [289]  2 NA  1  1  3  2  3  3  1 NA  1  4  2  1  1  3  2  1  2  3  1 NA  2  3\n [313]  3  2  1  2  3  5  5  1  2  3  3  1 NA NA  1  2  4 NA  2  1  1  1  3  2\n [337]  1  1  3  4 NA  1  2  1  1  3  3 NA  1  1  3  5  3  2  3  4  1  4  3  1\n [361] NA  2  1  2  2  1  2  2  6  1  2  4  5 NA  3  4  2  1  1  4  2  1  1  1\n [385]  1  2  1  4  4  1  3 NA  3  3 NA  2 NA  1  2  1  1  4  2  1  4  4 NA  1\n [409]  2 NA  3  2  2  2  1  4  3  6  1  2  3  1  3  2  2  2  1  1  3  2  1  1\n [433]  1  3  2  2 NA  4  4  4  1  1 NA  4  3 NA  1  3  1  3  2  4  2  2  2  3\n [457]  2  1  4  3 NA  1  4  3  1  3  2 NA  3 NA  1  3  1  4  1  1  1  2  4  3\n [481]  1  2  2  2  3  2  3  1  1 NA  3  2  1  1  2 NA  2  2  2  3  3  1  1  2\n [505] NA  1  2  1  1  3  3  1  3  1  1  1  1  1  2  5  1  1  2  2  1  1 NA  1\n [529]  4  1  2  4  1  3  2 NA  1  1 NA  2  1  1  4  2  3  3  1  5  3  1  1  2\n [553] NA  1  1  3  1  3  2  4 NA  2  3  2  1  2  1  1  1  2  2  3  1  5  2 NA\n [577]  2 NA  3  2  2  2  1  5  3  2  3  1 NA  3  1  2  2  2  1  2  2  4 NA  6\n [601]  1  2 NA  1  1  2  2  3 NA  3  2  3  3  4  2 NA  2 NA  4 NA  1  1  2  2\n [625]  3  1  1  1  3 NA  2  5 NA  7  1 NA  4  3  3  1 NA  1  1  1  1  3  2  4\n [649]  2  2  3 NA NA  1  4  3  2  2  2  3  2  4  2  2  4 NA NA NA  6  3  3  1\n [673]  4  4  2  1 NA  1  6 NA  3  3  2  1  1  6 NA  1  5  1 NA  2  6  2 NA  4\n [697]  1  3  1  2 NA  1  1  3  1  2  4  2  1  3  2  4  3  2  2  1  1  5  6  4\n [721]  2  2  2  2  4 NA  1  2  2  2  2  4  5 NA NA NA  4  3  3  3  2  4  2  4\n [745] NA NA NA NA  2  1 NA  2  4  3  2 NA  2  3  1  3  4 NA  1  2  1  2 NA  3\n [769]  1  2  1  2  1  2  1  2  2  2  2  1  1  3  3  1  3  4  3 NA NA  4  2  3\n [793]  2  1  3  2  4  2  2  3  1  2  4  3  3  4 NA  1  4  2  1  1  1  3  1  5\n [817]  2  2  4  2 NA  1  3  1  2 NA  1  2  1  2  1 NA  1  3  2  3  2 NA  2  1\n [841]  4  2 NA NA NA  2  4  2 NA NA  3  1 NA  5  5  2  2  2 NA  2  1  3  1  3\n [865]  2  4  2  4 NA  4  1  2  3  2  3  3  2  3  2  2  2  1  3  2  4  2 NA  3\n [889]  3  2  2 NA NA  3  2  1  2  4  1  1  1  1  4  3  2 NA  3  2 NA  1 NA  3\n [913]  2  1  1  1  2 NA  2  2  3  3  2 NA NA  4  5  2  2  2  1  2  3  1  3  3\n [937]  4  3 NA  1  1  1 NA  4  3  5  1  1  2 NA  2  2  2  2  5  2  2  3  1  2\n [961]  3 NA  1  2 NA NA  2 NA  3  1  1  2  5  3  5  1  1  4 NA  2  1  3  1  1\n [985]  2  4  3  3  3 NA  1  1  2  2  1  1  2  2 NA  2\n\n\n\n\nNumber and Locations of NA Values\nThis R code calculates the missing values (NA) within the ‚Äòna_example‚Äô dataset. Initially, we determined the total count of NA values present and identified their index positions within the dataset.\n\ntotal_na &lt;- sum(is.na(na_example))\ncat(\"Total NA values:\", total_na)\n\nTotal NA values: 145\n\n\n\nwhich(is.na(na_example))\n\n  [1]  12  17  27  50  51  52  59  65  66  68  91 117 125 126 127 128 139 140\n [19] 141 142 153 158 168 169 172 179 189 190 203 205 207 208 212 214 237 241\n [37] 243 244 253 257 265 267 269 279 282 287 290 298 310 325 326 330 341 348\n [55] 361 374 392 395 397 407 410 437 443 446 461 468 470 490 496 505 527 536\n [73] 539 553 561 576 578 589 599 603 609 616 618 620 630 633 636 641 652 653\n [91] 666 667 668 677 680 687 691 695 701 726 734 735 736 745 746 747 748 751\n[109] 756 762 767 788 789 807 821 826 832 838 843 844 845 849 850 853 859 869\n[127] 887 892 893 906 909 911 918 924 925 939 943 950 962 965 966 968 979 990\n[145] 999\n\n\n\n\nStatistical Calculation Ignoring NA Values\n\n# NA deƒüerleri g√∂z ardƒ± ederek ortalama ve standart sapma hesapla\nmean_value &lt;- mean(na_example, na.rm = TRUE)\nsd_value &lt;- sd(na_example, na.rm = TRUE)\n\n# Sonu√ßlarƒ± ekrana yazdƒ±r\ncat(\"Mean:\", mean_value, \"\\n\")\n\nMean: 2.301754 \n\ncat(\"Standart Deviation:\", sd_value)\n\nStandart Deviation: 1.22338\n\n\n\n\nReplacing NA Values with the Median\nIn this process, we replace all missing (NA) values in the na_example dataset with the median of the non-missing values. The median is chosen because it is less sensitive to extreme values (outliers) compared to the mean.\n\n# NA olmayan deƒüerlerin medyanƒ±nƒ± hesapla\nmedian_others &lt;- median(na_example, na.rm = TRUE)\n\n# NA deƒüerleri medyan ile deƒüi≈ütir\nna_example_median &lt;- ifelse(is.na(na_example), median_others, na_example)\n\n# Sonucu yazdƒ±r\ncat(\"Medyan:\", median_others, \"\\n\")\n\nMedyan: 2 \n\nprint(na_example_median)\n\n   [1] 2 1 3 2 1 3 1 4 3 2 2 2 2 2 1 4 2 1 1 2 1 2 2 1 2 5 2 2 2 3 1 2 4 1 1 1 4\n  [38] 5 2 3 4 1 2 4 1 1 2 1 5 2 2 2 1 1 5 1 3 1 2 4 4 7 3 2 2 2 1 2 4 1 2 2 3 2\n  [75] 1 2 2 4 3 4 2 3 1 3 2 1 1 1 3 1 2 3 1 2 2 1 2 2 1 1 4 1 1 2 3 3 2 2 3 3 3\n [112] 4 1 1 1 2 2 4 3 4 3 1 2 1 2 2 2 2 1 5 1 2 1 3 5 3 2 2 2 2 2 2 3 5 3 1 1 4\n [149] 2 4 3 3 2 2 3 2 6 2 1 1 2 2 1 3 1 1 5 2 2 2 4 2 2 5 1 4 3 3 2 4 3 1 4 1 1\n [186] 3 1 1 2 2 3 5 2 2 2 3 1 2 2 3 2 1 2 2 2 1 2 2 2 1 1 2 3 2 1 2 2 1 3 2 2 1\n [223] 1 2 3 1 1 1 4 3 4 2 2 1 4 1 2 5 1 4 2 3 2 2 1 1 5 2 3 3 2 4 2 3 2 5 2 2 3\n [260] 4 6 2 2 2 2 2 2 2 2 3 3 2 2 4 3 1 4 2 2 2 4 2 6 2 3 1 2 2 2 2 1 1 3 2 3 3\n [297] 1 2 1 4 2 1 1 3 2 1 2 3 1 2 2 3 3 2 1 2 3 5 5 1 2 3 3 1 2 2 1 2 4 2 2 1 1\n [334] 1 3 2 1 1 3 4 2 1 2 1 1 3 3 2 1 1 3 5 3 2 3 4 1 4 3 1 2 2 1 2 2 1 2 2 6 1\n [371] 2 4 5 2 3 4 2 1 1 4 2 1 1 1 1 2 1 4 4 1 3 2 3 3 2 2 2 1 2 1 1 4 2 1 4 4 2\n [408] 1 2 2 3 2 2 2 1 4 3 6 1 2 3 1 3 2 2 2 1 1 3 2 1 1 1 3 2 2 2 4 4 4 1 1 2 4\n [445] 3 2 1 3 1 3 2 4 2 2 2 3 2 1 4 3 2 1 4 3 1 3 2 2 3 2 1 3 1 4 1 1 1 2 4 3 1\n [482] 2 2 2 3 2 3 1 1 2 3 2 1 1 2 2 2 2 2 3 3 1 1 2 2 1 2 1 1 3 3 1 3 1 1 1 1 1\n [519] 2 5 1 1 2 2 1 1 2 1 4 1 2 4 1 3 2 2 1 1 2 2 1 1 4 2 3 3 1 5 3 1 1 2 2 1 1\n [556] 3 1 3 2 4 2 2 3 2 1 2 1 1 1 2 2 3 1 5 2 2 2 2 3 2 2 2 1 5 3 2 3 1 2 3 1 2\n [593] 2 2 1 2 2 4 2 6 1 2 2 1 1 2 2 3 2 3 2 3 3 4 2 2 2 2 4 2 1 1 2 2 3 1 1 1 3\n [630] 2 2 5 2 7 1 2 4 3 3 1 2 1 1 1 1 3 2 4 2 2 3 2 2 1 4 3 2 2 2 3 2 4 2 2 4 2\n [667] 2 2 6 3 3 1 4 4 2 1 2 1 6 2 3 3 2 1 1 6 2 1 5 1 2 2 6 2 2 4 1 3 1 2 2 1 1\n [704] 3 1 2 4 2 1 3 2 4 3 2 2 1 1 5 6 4 2 2 2 2 4 2 1 2 2 2 2 4 5 2 2 2 4 3 3 3\n [741] 2 4 2 4 2 2 2 2 2 1 2 2 4 3 2 2 2 3 1 3 4 2 1 2 1 2 2 3 1 2 1 2 1 2 1 2 2\n [778] 2 2 1 1 3 3 1 3 4 3 2 2 4 2 3 2 1 3 2 4 2 2 3 1 2 4 3 3 4 2 1 4 2 1 1 1 3\n [815] 1 5 2 2 4 2 2 1 3 1 2 2 1 2 1 2 1 2 1 3 2 3 2 2 2 1 4 2 2 2 2 2 4 2 2 2 3\n [852] 1 2 5 5 2 2 2 2 2 1 3 1 3 2 4 2 4 2 4 1 2 3 2 3 3 2 3 2 2 2 1 3 2 4 2 2 3\n [889] 3 2 2 2 2 3 2 1 2 4 1 1 1 1 4 3 2 2 3 2 2 1 2 3 2 1 1 1 2 2 2 2 3 3 2 2 2\n [926] 4 5 2 2 2 1 2 3 1 3 3 4 3 2 1 1 1 2 4 3 5 1 1 2 2 2 2 2 2 5 2 2 3 1 2 3 2\n [963] 1 2 2 2 2 2 3 1 1 2 5 3 5 1 1 4 2 2 1 3 1 1 2 4 3 3 3 2 1 1 2 2 1 1 2 2 2\n[1000] 2\n\n\n\nversion1_median &lt;- median(na_example_median)\nversion1_sd &lt;- sd(na_example_median)\n\n# Sonu√ßlarƒ± yazdƒ±r\ncat(\"Versiyon 1 Medyan:\", version1_median, \"\\n\")\n\nVersiyon 1 Medyan: 2 \n\ncat(\"Versiyon 1 Sapma:\", version1_sd)\n\nVersiyon 1 Sapma: 1.136102\n\n\n\n\nReplacing NA Values with Randomly Selected Non-missing Value\nThis process replaces all NA values in the dataset with a randomly selected non-missing value from the same dataset. First, we extract all non-missing values, then for each NA, a random value from the non-missing values is chosen to fill in the missing spot.\n\n# NA olmayan deƒüerleri al\nnon_na_values &lt;- na_example[!is.na(na_example)]\n\n# NA deƒüerlerini rastgele bir NA olmayan deƒüerle deƒüi≈ütir\nna_example_random &lt;- ifelse(is.na(na_example), sample(non_na_values, 1), na_example)\n\n# Sonu√ßlarƒ± yazdƒ±r\nprint(na_example_random)\n\n   [1] 2 1 3 2 1 3 1 4 3 2 2 3 2 2 1 4 3 1 1 2 1 2 2 1 2 5 3 2 2 3 1 2 4 1 1 1 4\n  [38] 5 2 3 4 1 2 4 1 1 2 1 5 3 3 3 1 1 5 1 3 1 3 4 4 7 3 2 3 3 1 3 4 1 2 2 3 2\n  [75] 1 2 2 4 3 4 2 3 1 3 2 1 1 1 3 1 3 3 1 2 2 1 2 2 1 1 4 1 1 2 3 3 2 2 3 3 3\n [112] 4 1 1 1 2 3 4 3 4 3 1 2 1 3 3 3 3 1 5 1 2 1 3 5 3 2 2 3 3 3 3 3 5 3 1 1 4\n [149] 2 4 3 3 3 2 3 2 6 3 1 1 2 2 1 3 1 1 5 3 3 2 4 3 2 5 1 4 3 3 3 4 3 1 4 1 1\n [186] 3 1 1 3 3 3 5 2 2 2 3 1 2 2 3 2 1 3 2 3 1 3 3 2 1 1 3 3 3 1 2 2 1 3 2 2 1\n [223] 1 2 3 1 1 1 4 3 4 2 2 1 4 1 3 5 1 4 3 3 3 3 1 1 5 2 3 3 2 4 3 3 2 5 3 2 3\n [260] 4 6 2 2 2 3 2 3 2 3 3 3 2 2 4 3 1 4 2 3 2 4 3 6 2 3 1 3 2 2 3 1 1 3 2 3 3\n [297] 1 3 1 4 2 1 1 3 2 1 2 3 1 3 2 3 3 2 1 2 3 5 5 1 2 3 3 1 3 3 1 2 4 3 2 1 1\n [334] 1 3 2 1 1 3 4 3 1 2 1 1 3 3 3 1 1 3 5 3 2 3 4 1 4 3 1 3 2 1 2 2 1 2 2 6 1\n [371] 2 4 5 3 3 4 2 1 1 4 2 1 1 1 1 2 1 4 4 1 3 3 3 3 3 2 3 1 2 1 1 4 2 1 4 4 3\n [408] 1 2 3 3 2 2 2 1 4 3 6 1 2 3 1 3 2 2 2 1 1 3 2 1 1 1 3 2 2 3 4 4 4 1 1 3 4\n [445] 3 3 1 3 1 3 2 4 2 2 2 3 2 1 4 3 3 1 4 3 1 3 2 3 3 3 1 3 1 4 1 1 1 2 4 3 1\n [482] 2 2 2 3 2 3 1 1 3 3 2 1 1 2 3 2 2 2 3 3 1 1 2 3 1 2 1 1 3 3 1 3 1 1 1 1 1\n [519] 2 5 1 1 2 2 1 1 3 1 4 1 2 4 1 3 2 3 1 1 3 2 1 1 4 2 3 3 1 5 3 1 1 2 3 1 1\n [556] 3 1 3 2 4 3 2 3 2 1 2 1 1 1 2 2 3 1 5 2 3 2 3 3 2 2 2 1 5 3 2 3 1 3 3 1 2\n [593] 2 2 1 2 2 4 3 6 1 2 3 1 1 2 2 3 3 3 2 3 3 4 2 3 2 3 4 3 1 1 2 2 3 1 1 1 3\n [630] 3 2 5 3 7 1 3 4 3 3 1 3 1 1 1 1 3 2 4 2 2 3 3 3 1 4 3 2 2 2 3 2 4 2 2 4 3\n [667] 3 3 6 3 3 1 4 4 2 1 3 1 6 3 3 3 2 1 1 6 3 1 5 1 3 2 6 2 3 4 1 3 1 2 3 1 1\n [704] 3 1 2 4 2 1 3 2 4 3 2 2 1 1 5 6 4 2 2 2 2 4 3 1 2 2 2 2 4 5 3 3 3 4 3 3 3\n [741] 2 4 2 4 3 3 3 3 2 1 3 2 4 3 2 3 2 3 1 3 4 3 1 2 1 2 3 3 1 2 1 2 1 2 1 2 2\n [778] 2 2 1 1 3 3 1 3 4 3 3 3 4 2 3 2 1 3 2 4 2 2 3 1 2 4 3 3 4 3 1 4 2 1 1 1 3\n [815] 1 5 2 2 4 2 3 1 3 1 2 3 1 2 1 2 1 3 1 3 2 3 2 3 2 1 4 2 3 3 3 2 4 2 3 3 3\n [852] 1 3 5 5 2 2 2 3 2 1 3 1 3 2 4 2 4 3 4 1 2 3 2 3 3 2 3 2 2 2 1 3 2 4 2 3 3\n [889] 3 2 2 3 3 3 2 1 2 4 1 1 1 1 4 3 2 3 3 2 3 1 3 3 2 1 1 1 2 3 2 2 3 3 2 3 3\n [926] 4 5 2 2 2 1 2 3 1 3 3 4 3 3 1 1 1 3 4 3 5 1 1 2 3 2 2 2 2 5 2 2 3 1 2 3 3\n [963] 1 2 3 3 2 3 3 1 1 2 5 3 5 1 1 4 3 2 1 3 1 1 2 4 3 3 3 3 1 1 2 2 1 1 2 2 3\n[1000] 2\n\n\n\nversion2_median &lt;- median(na_example_random)\nversion2_sd &lt;- sd(na_example_random)\n\n# Sonu√ßlarƒ± yazdƒ±r\ncat(\"Versiyon 2 Medyan:\", version2_median, \"\\n\")\n\nVersiyon 2 Medyan: 2 \n\ncat(\"Versiyon 2 Sapma:\", version2_sd)\n\nVersiyon 2 Sapma: 1.157554\n\n\n\nlibrary(knitr)  # kable fonksiyonu i√ßin\n\nWarning: package 'knitr' was built under R version 4.4.3\n\n\n\n# Bu kod bloƒüu tamamen AI tarafƒ±ndan yazƒ±lmƒ±stƒ±r.\n# Sonu√ßlarƒ± birle≈ütirip tabloyu olu≈ütur\n\nstatistics_table &lt;- data.frame(\n  Method = c(\"Original (Mean)\", \"Original (SD)\", \n             \"Imputed (Median, Mean)\", \"Imputed (Median, SD)\", \n             \"Imputed (Random, Mean)\", \"Imputed (Random, SD)\"),\n  Value = c(mean_value, sd_value,\n            mean(na_example_median), sd(na_example_median),\n            mean(na_example_random), sd(na_example_random))\n)\n\n# Tabloyu yazdƒ±r\nkable(statistics_table, caption = \"Comparison of Statistics Before and After Handling NA Values\")\n\n\nComparison of Statistics Before and After Handling NA Values\n\n\nMethod\nValue\n\n\n\n\nOriginal (Mean)\n2.301754\n\n\nOriginal (SD)\n1.223380\n\n\nImputed (Median, Mean)\n2.258000\n\n\nImputed (Median, SD)\n1.136102\n\n\nImputed (Random, Mean)\n2.403000\n\n\nImputed (Random, SD)\n1.157554\n\n\n\n\n\nRegarding the data, imputing with the median seems more appropriate as it preserves the central tendency without being affected by outliers. Imputing with random values could better reflect the distribution of the data, but it may introduce some variability. Looking at the original data, if the number of missing values is minimal, ignoring them could be acceptable. However, if the missing values are not random, it could introduce bias in the data.",
    "crumbs": [
      "MRCars Statistics"
    ]
  },
  {
    "objectID": "assignments/datascience.html",
    "href": "assignments/datascience.html",
    "title": "On Data Science and Industrial Engineering",
    "section": "",
    "text": "Below, you will find a brief summary of the discussion video on data analytics and industrial engineering, available at the following link:\nWatch the video here",
    "crumbs": [
      "On Data Science and Industrial Engineering"
    ]
  },
  {
    "objectID": "assignments/datascience.html#the-role-of-data-science-and-its-applications-insights-from-kerem-demirta≈ü",
    "href": "assignments/datascience.html#the-role-of-data-science-and-its-applications-insights-from-kerem-demirta≈ü",
    "title": "On Data Science and Industrial Engineering",
    "section": "The Role of Data Science and Its Applications: Insights from Kerem Demirta≈ü",
    "text": "The Role of Data Science and Its Applications: Insights from Kerem Demirta≈ü\nKerem Demirta≈ü is a Data Scientist currently working at Invent Analytics. Previously, he worked at Spyke Games and Smart Kiwi. One of his significant projects was Royal Reachers, where he focused on analyzing users‚Äô gaming behaviors and demographic structures to deliver the most suitable offers at the most optimal times, thereby maximizing sales. Later in his career, he contributed to a project aimed at optimizing inventory management in retail. This involved developing software that determines how much stock should be held at various locations and for which models, ultimately helping businesses maximize their sales.\nHis research interests revolve around autonomous vehicles, traffic flow modeling, transportation simulations, and optimization techniques in mobility systems.",
    "crumbs": [
      "On Data Science and Industrial Engineering"
    ]
  },
  {
    "objectID": "assignments/datascience.html#the-scope-of-data-science",
    "href": "assignments/datascience.html#the-scope-of-data-science",
    "title": "On Data Science and Industrial Engineering",
    "section": "The Scope of Data Science",
    "text": "The Scope of Data Science\nData science finds applications in various fields, including:\n\nEpidemiology: Predicting the likelihood of disease outbreaks, identifying high-risk regions, and implementing preventive measures.\nRetail: Optimizing stock levels and sales strategies to enhance profitability.\nAutonomous Vehicles: Improving traffic efficiency, reducing congestion, and enhancing the decision-making capabilities of self-driving cars.",
    "crumbs": [
      "On Data Science and Industrial Engineering"
    ]
  },
  {
    "objectID": "assignments/datascience.html#what-data-science-is-not",
    "href": "assignments/datascience.html#what-data-science-is-not",
    "title": "On Data Science and Industrial Engineering",
    "section": "What Data Science is NOT",
    "text": "What Data Science is NOT\n\nIt is not merely an exaggerated form of statistics.\nIt is not just about building models.\nIt is not exclusively tied to Big Data.\nWriting Python code does not make someone a data analyst.\nData analysis does not always provide definitive answers to every question.",
    "crumbs": [
      "On Data Science and Industrial Engineering"
    ]
  },
  {
    "objectID": "assignments/datascience.html#the-data-science-workflow",
    "href": "assignments/datascience.html#the-data-science-workflow",
    "title": "On Data Science and Industrial Engineering",
    "section": "The Data Science Workflow",
    "text": "The Data Science Workflow\n\nProblem Identification: Clearly defining the problem is the first step in data science. A historical example of this is the analysis conducted during World War II on aircraft durability. Engineers initially focused on reinforcing the most frequently damaged parts of returning planes, but statistician Abraham Wald proposed a different approach‚Äîsuggesting that undamaged areas of returning planes were actually where the planes that were shot down had suffered critical damage. This shift in thinking led to more effective reinforcement strategies.\nData Collection: Gathering unbiased data is crucial. Abraham Wald‚Äôs unbiased thinking methodology is a key example. His research showed that survivorship bias can mislead analyses if data from unsuccessful cases (e.g., planes that didn‚Äôt return) is not considered.\nExploratory Data Analysis (EDA): Before building models, it is essential to understand and visualize the data. A classic example is John Snow‚Äôs study on cholera outbreaks in 1854 London. By mapping out cases and identifying contaminated water sources, he demonstrated that cholera was waterborne‚Äîlong before germ theory was widely accepted. This showcases how data visualization and pattern recognition can lead to groundbreaking discoveries.\nModel Building: At this stage, predictive and analytical models are developed. A relevant example is Lewis Fry Richardson‚Äôs pioneering work on weather forecasting, where he proposed numerical methods for predicting atmospheric conditions. Another example is the World War II Diet Problem, which used linear programming to optimize military rations by balancing nutrition and cost.\nModel Evaluation: Assessing model performance and avoiding overfitting are crucial aspects of data science. Overfitting occurs when a model learns noise instead of actual patterns, reducing its real-world applicability. An illustrative case is the Deep Blue vs.¬†Garry Kasparov chess match, where the AI was trained to analyze millions of moves but had to generalize its strategies to defeat a world champion.\nProduction and Live Performance: Once a model is finalized, it must be deployed in a real-world setting. This step involves monitoring AI tools and ensuring their effectiveness. Examples include AI-driven recommendation systems in e-commerce, self-learning fraud detection systems in banking, and real-time traffic prediction tools in transportation networks.",
    "crumbs": [
      "On Data Science and Industrial Engineering"
    ]
  },
  {
    "objectID": "assignments/datascience.html#kerem-demirta≈üs-research-on-autonomous-vehicles",
    "href": "assignments/datascience.html#kerem-demirta≈üs-research-on-autonomous-vehicles",
    "title": "On Data Science and Industrial Engineering",
    "section": "Kerem Demirta≈ü‚Äôs Research on Autonomous Vehicles",
    "text": "Kerem Demirta≈ü‚Äôs Research on Autonomous Vehicles\nHis thesis, ‚ÄúObject-driven Cellular Automaton Model for Platooning of Autonomous Vehicles on Freeways with Multiple Lanes‚Äù, explores how autonomous vehicles can form convoys and adapt to complex road conditions. The primary motivation behind his research is to minimize the following distance between vehicles, optimize acceleration and deceleration during lane changes, and reduce the impact of stop-and-go waves in traffic flow. By refining the mechanics of platooning, his work contributes to the development of more efficient and safer autonomous driving systems.\nUltimately, his work highlights the power of data science in solving complex real-world problems, from optimizing business operations to transforming the future of mobility.",
    "crumbs": [
      "On Data Science and Industrial Engineering"
    ]
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About Me",
    "section": "",
    "text": "As an industrial engineer with a passion for data analysis, broadcasting, and artificial intelligence, I have built my career on exploring innovative solutions in these fields. After graduating from TOBB University, I began working as a data analyst in the broadcasting sector, specifically at TRT1, where I focused on broadcast planning and data analysis.\nCurrently, I am pursuing a master‚Äôs degree in industrial engineering while developing projects that integrate AI and innovation into the broadcasting industry. I also share insights on industry trends through blog writing and continuously work on enhancing my professional expertise."
  },
  {
    "objectID": "about.html#education",
    "href": "about.html#education",
    "title": "About Me",
    "section": "Education",
    "text": "Education\n\nM.S, Industrial Engineering, Hacettepe University, Turkey\n2025 - ongoing \n\n\n\nM.S, Business Administration, Hacettepe University, Turkey\n\n2022 - 2023 \n\n\n\n\nB.S, Industrial Engineering, TOBB University of Economics and Technology, Turkey\n\n2015 - 2020"
  },
  {
    "objectID": "about.html#work-experience",
    "href": "about.html#work-experience",
    "title": "About Me",
    "section": "Work Experience",
    "text": "Work Experience\n\nTRT, Planning Specialist, Turkey \n\nDec 2021 - ongoing\nBroadcast Planning & Performance Analysis: Managing and monitoring TV broadcasts, analyzing rating performance, and optimizing scheduling and discount strategies.\nData-Driven Decision Making: Conducting data analysis, preparing reports, and ensuring effective team coordination for strategic planning.\n\nLC WAIKIKI , International Store Merchandiser, Turkey \n\nJan 2021 - Dec 2021\nManaging international store stocks, analyzing performance metrics, and optimizing shipping strategies based on regional clothing preferences.\nDeveloping and implementing discount strategies to enhance sales.\n\nTURK PATENT VE MARKA KURUMU, Intern, Turkey \n\nDec 2019 - Sep 2019\n\nMAN TURKIYE, Quality Control Engineer Intern, Turkey \n\nJan 2019 - Apr 2019\n\nERSA OFIS MOBILYALARI , IT Intern, Turkey \n\nAug 2018- May 2019"
  },
  {
    "objectID": "about.html#competencies",
    "href": "about.html#competencies",
    "title": "About Me",
    "section": "Competencies",
    "text": "Competencies\n\nMathematical Modelling\nMS Office\nR\nCPLEX\nMySQL\nMS Office"
  },
  {
    "objectID": "about.html#hobbies",
    "href": "about.html#hobbies",
    "title": "About Me",
    "section": "Hobbies",
    "text": "Hobbies\n\nPainting & Crafts üé®üñåÔ∏è\nCinema & Theatre üé¨üé≠\nTraveling & Exploring New Places ‚úàÔ∏èüåç\nPhotography üì∏\nCooking üç≥\n\nLearn More -&gt; Download CV"
  },
  {
    "objectID": "assignments/handlingna.html",
    "href": "assignments/handlingna.html",
    "title": "NA_Example",
    "section": "",
    "text": "#install.packages(\"dslabs\")\nlibrary(dslabs)\n\nWarning: package 'dslabs' was built under R version 4.4.3\n\n\nAfter successfully installing and loading the ‚Äòdslabs‚Äô library, we can now print the desired dataset.\n\nprint(na_example)\n\n   [1]  2  1  3  2  1  3  1  4  3  2  2 NA  2  2  1  4 NA  1  1  2  1  2  2  1\n  [25]  2  5 NA  2  2  3  1  2  4  1  1  1  4  5  2  3  4  1  2  4  1  1  2  1\n  [49]  5 NA NA NA  1  1  5  1  3  1 NA  4  4  7  3  2 NA NA  1 NA  4  1  2  2\n  [73]  3  2  1  2  2  4  3  4  2  3  1  3  2  1  1  1  3  1 NA  3  1  2  2  1\n  [97]  2  2  1  1  4  1  1  2  3  3  2  2  3  3  3  4  1  1  1  2 NA  4  3  4\n [121]  3  1  2  1 NA NA NA NA  1  5  1  2  1  3  5  3  2  2 NA NA NA NA  3  5\n [145]  3  1  1  4  2  4  3  3 NA  2  3  2  6 NA  1  1  2  2  1  3  1  1  5 NA\n [169] NA  2  4 NA  2  5  1  4  3  3 NA  4  3  1  4  1  1  3  1  1 NA NA  3  5\n [193]  2  2  2  3  1  2  2  3  2  1 NA  2 NA  1 NA NA  2  1  1 NA  3 NA  1  2\n [217]  2  1  3  2  2  1  1  2  3  1  1  1  4  3  4  2  2  1  4  1 NA  5  1  4\n [241] NA  3 NA NA  1  1  5  2  3  3  2  4 NA  3  2  5 NA  2  3  4  6  2  2  2\n [265] NA  2 NA  2 NA  3  3  2  2  4  3  1  4  2 NA  2  4 NA  6  2  3  1 NA  2\n [289]  2 NA  1  1  3  2  3  3  1 NA  1  4  2  1  1  3  2  1  2  3  1 NA  2  3\n [313]  3  2  1  2  3  5  5  1  2  3  3  1 NA NA  1  2  4 NA  2  1  1  1  3  2\n [337]  1  1  3  4 NA  1  2  1  1  3  3 NA  1  1  3  5  3  2  3  4  1  4  3  1\n [361] NA  2  1  2  2  1  2  2  6  1  2  4  5 NA  3  4  2  1  1  4  2  1  1  1\n [385]  1  2  1  4  4  1  3 NA  3  3 NA  2 NA  1  2  1  1  4  2  1  4  4 NA  1\n [409]  2 NA  3  2  2  2  1  4  3  6  1  2  3  1  3  2  2  2  1  1  3  2  1  1\n [433]  1  3  2  2 NA  4  4  4  1  1 NA  4  3 NA  1  3  1  3  2  4  2  2  2  3\n [457]  2  1  4  3 NA  1  4  3  1  3  2 NA  3 NA  1  3  1  4  1  1  1  2  4  3\n [481]  1  2  2  2  3  2  3  1  1 NA  3  2  1  1  2 NA  2  2  2  3  3  1  1  2\n [505] NA  1  2  1  1  3  3  1  3  1  1  1  1  1  2  5  1  1  2  2  1  1 NA  1\n [529]  4  1  2  4  1  3  2 NA  1  1 NA  2  1  1  4  2  3  3  1  5  3  1  1  2\n [553] NA  1  1  3  1  3  2  4 NA  2  3  2  1  2  1  1  1  2  2  3  1  5  2 NA\n [577]  2 NA  3  2  2  2  1  5  3  2  3  1 NA  3  1  2  2  2  1  2  2  4 NA  6\n [601]  1  2 NA  1  1  2  2  3 NA  3  2  3  3  4  2 NA  2 NA  4 NA  1  1  2  2\n [625]  3  1  1  1  3 NA  2  5 NA  7  1 NA  4  3  3  1 NA  1  1  1  1  3  2  4\n [649]  2  2  3 NA NA  1  4  3  2  2  2  3  2  4  2  2  4 NA NA NA  6  3  3  1\n [673]  4  4  2  1 NA  1  6 NA  3  3  2  1  1  6 NA  1  5  1 NA  2  6  2 NA  4\n [697]  1  3  1  2 NA  1  1  3  1  2  4  2  1  3  2  4  3  2  2  1  1  5  6  4\n [721]  2  2  2  2  4 NA  1  2  2  2  2  4  5 NA NA NA  4  3  3  3  2  4  2  4\n [745] NA NA NA NA  2  1 NA  2  4  3  2 NA  2  3  1  3  4 NA  1  2  1  2 NA  3\n [769]  1  2  1  2  1  2  1  2  2  2  2  1  1  3  3  1  3  4  3 NA NA  4  2  3\n [793]  2  1  3  2  4  2  2  3  1  2  4  3  3  4 NA  1  4  2  1  1  1  3  1  5\n [817]  2  2  4  2 NA  1  3  1  2 NA  1  2  1  2  1 NA  1  3  2  3  2 NA  2  1\n [841]  4  2 NA NA NA  2  4  2 NA NA  3  1 NA  5  5  2  2  2 NA  2  1  3  1  3\n [865]  2  4  2  4 NA  4  1  2  3  2  3  3  2  3  2  2  2  1  3  2  4  2 NA  3\n [889]  3  2  2 NA NA  3  2  1  2  4  1  1  1  1  4  3  2 NA  3  2 NA  1 NA  3\n [913]  2  1  1  1  2 NA  2  2  3  3  2 NA NA  4  5  2  2  2  1  2  3  1  3  3\n [937]  4  3 NA  1  1  1 NA  4  3  5  1  1  2 NA  2  2  2  2  5  2  2  3  1  2\n [961]  3 NA  1  2 NA NA  2 NA  3  1  1  2  5  3  5  1  1  4 NA  2  1  3  1  1\n [985]  2  4  3  3  3 NA  1  1  2  2  1  1  2  2 NA  2\n\n\n\n\n\nThis R code calculates the missing values (NA) within the ‚Äòna_example‚Äô dataset. Initially, we determined the total count of NA values present and identified their index positions within the dataset.\n\ntotal_na &lt;- sum(is.na(na_example))\ncat(\"Total NA values:\", total_na)\n\nTotal NA values: 145\n\n\n\nwhich(is.na(na_example))\n\n  [1]  12  17  27  50  51  52  59  65  66  68  91 117 125 126 127 128 139 140\n [19] 141 142 153 158 168 169 172 179 189 190 203 205 207 208 212 214 237 241\n [37] 243 244 253 257 265 267 269 279 282 287 290 298 310 325 326 330 341 348\n [55] 361 374 392 395 397 407 410 437 443 446 461 468 470 490 496 505 527 536\n [73] 539 553 561 576 578 589 599 603 609 616 618 620 630 633 636 641 652 653\n [91] 666 667 668 677 680 687 691 695 701 726 734 735 736 745 746 747 748 751\n[109] 756 762 767 788 789 807 821 826 832 838 843 844 845 849 850 853 859 869\n[127] 887 892 893 906 909 911 918 924 925 939 943 950 962 965 966 968 979 990\n[145] 999\n\n\n\n\n\n\n# NA deƒüerleri g√∂z ardƒ± ederek ortalama ve standart sapma hesapla\nmean_value &lt;- mean(na_example, na.rm = TRUE)\nsd_value &lt;- sd(na_example, na.rm = TRUE)\n\n# Sonu√ßlarƒ± ekrana yazdƒ±r\ncat(\"Mean:\", mean_value, \"\\n\")\n\nMean: 2.301754 \n\ncat(\"Standart Deviation:\", sd_value)\n\nStandart Deviation: 1.22338\n\n\n\n\n\nIn this process, we replace all missing (NA) values in the na_example dataset with the median of the non-missing values. The median is chosen because it is less sensitive to extreme values (outliers) compared to the mean.\n\n# NA olmayan deƒüerlerin medyanƒ±nƒ± hesapla\nmedian_others &lt;- median(na_example, na.rm = TRUE)\n\n# NA deƒüerleri medyan ile deƒüi≈ütir\nna_example_median &lt;- ifelse(is.na(na_example), median_others, na_example)\n\n# Sonucu yazdƒ±r\ncat(\"Medyan:\", median_others, \"\\n\")\n\nMedyan: 2 \n\nprint(na_example_median)\n\n   [1] 2 1 3 2 1 3 1 4 3 2 2 2 2 2 1 4 2 1 1 2 1 2 2 1 2 5 2 2 2 3 1 2 4 1 1 1 4\n  [38] 5 2 3 4 1 2 4 1 1 2 1 5 2 2 2 1 1 5 1 3 1 2 4 4 7 3 2 2 2 1 2 4 1 2 2 3 2\n  [75] 1 2 2 4 3 4 2 3 1 3 2 1 1 1 3 1 2 3 1 2 2 1 2 2 1 1 4 1 1 2 3 3 2 2 3 3 3\n [112] 4 1 1 1 2 2 4 3 4 3 1 2 1 2 2 2 2 1 5 1 2 1 3 5 3 2 2 2 2 2 2 3 5 3 1 1 4\n [149] 2 4 3 3 2 2 3 2 6 2 1 1 2 2 1 3 1 1 5 2 2 2 4 2 2 5 1 4 3 3 2 4 3 1 4 1 1\n [186] 3 1 1 2 2 3 5 2 2 2 3 1 2 2 3 2 1 2 2 2 1 2 2 2 1 1 2 3 2 1 2 2 1 3 2 2 1\n [223] 1 2 3 1 1 1 4 3 4 2 2 1 4 1 2 5 1 4 2 3 2 2 1 1 5 2 3 3 2 4 2 3 2 5 2 2 3\n [260] 4 6 2 2 2 2 2 2 2 2 3 3 2 2 4 3 1 4 2 2 2 4 2 6 2 3 1 2 2 2 2 1 1 3 2 3 3\n [297] 1 2 1 4 2 1 1 3 2 1 2 3 1 2 2 3 3 2 1 2 3 5 5 1 2 3 3 1 2 2 1 2 4 2 2 1 1\n [334] 1 3 2 1 1 3 4 2 1 2 1 1 3 3 2 1 1 3 5 3 2 3 4 1 4 3 1 2 2 1 2 2 1 2 2 6 1\n [371] 2 4 5 2 3 4 2 1 1 4 2 1 1 1 1 2 1 4 4 1 3 2 3 3 2 2 2 1 2 1 1 4 2 1 4 4 2\n [408] 1 2 2 3 2 2 2 1 4 3 6 1 2 3 1 3 2 2 2 1 1 3 2 1 1 1 3 2 2 2 4 4 4 1 1 2 4\n [445] 3 2 1 3 1 3 2 4 2 2 2 3 2 1 4 3 2 1 4 3 1 3 2 2 3 2 1 3 1 4 1 1 1 2 4 3 1\n [482] 2 2 2 3 2 3 1 1 2 3 2 1 1 2 2 2 2 2 3 3 1 1 2 2 1 2 1 1 3 3 1 3 1 1 1 1 1\n [519] 2 5 1 1 2 2 1 1 2 1 4 1 2 4 1 3 2 2 1 1 2 2 1 1 4 2 3 3 1 5 3 1 1 2 2 1 1\n [556] 3 1 3 2 4 2 2 3 2 1 2 1 1 1 2 2 3 1 5 2 2 2 2 3 2 2 2 1 5 3 2 3 1 2 3 1 2\n [593] 2 2 1 2 2 4 2 6 1 2 2 1 1 2 2 3 2 3 2 3 3 4 2 2 2 2 4 2 1 1 2 2 3 1 1 1 3\n [630] 2 2 5 2 7 1 2 4 3 3 1 2 1 1 1 1 3 2 4 2 2 3 2 2 1 4 3 2 2 2 3 2 4 2 2 4 2\n [667] 2 2 6 3 3 1 4 4 2 1 2 1 6 2 3 3 2 1 1 6 2 1 5 1 2 2 6 2 2 4 1 3 1 2 2 1 1\n [704] 3 1 2 4 2 1 3 2 4 3 2 2 1 1 5 6 4 2 2 2 2 4 2 1 2 2 2 2 4 5 2 2 2 4 3 3 3\n [741] 2 4 2 4 2 2 2 2 2 1 2 2 4 3 2 2 2 3 1 3 4 2 1 2 1 2 2 3 1 2 1 2 1 2 1 2 2\n [778] 2 2 1 1 3 3 1 3 4 3 2 2 4 2 3 2 1 3 2 4 2 2 3 1 2 4 3 3 4 2 1 4 2 1 1 1 3\n [815] 1 5 2 2 4 2 2 1 3 1 2 2 1 2 1 2 1 2 1 3 2 3 2 2 2 1 4 2 2 2 2 2 4 2 2 2 3\n [852] 1 2 5 5 2 2 2 2 2 1 3 1 3 2 4 2 4 2 4 1 2 3 2 3 3 2 3 2 2 2 1 3 2 4 2 2 3\n [889] 3 2 2 2 2 3 2 1 2 4 1 1 1 1 4 3 2 2 3 2 2 1 2 3 2 1 1 1 2 2 2 2 3 3 2 2 2\n [926] 4 5 2 2 2 1 2 3 1 3 3 4 3 2 1 1 1 2 4 3 5 1 1 2 2 2 2 2 2 5 2 2 3 1 2 3 2\n [963] 1 2 2 2 2 2 3 1 1 2 5 3 5 1 1 4 2 2 1 3 1 1 2 4 3 3 3 2 1 1 2 2 1 1 2 2 2\n[1000] 2\n\n\n\nversion1_median &lt;- median(na_example_median)\nversion1_sd &lt;- sd(na_example_median)\n\n# Sonu√ßlarƒ± yazdƒ±r\ncat(\"Versiyon 1 Medyan:\", version1_median, \"\\n\")\n\nVersiyon 1 Medyan: 2 \n\ncat(\"Versiyon 1 Sapma:\", version1_sd)\n\nVersiyon 1 Sapma: 1.136102\n\n\n\n\n\nThis process replaces all NA values in the dataset with a randomly selected non-missing value from the same dataset. First, we extract all non-missing values, then for each NA, a random value from the non-missing values is chosen to fill in the missing spot.\n\n# NA olmayan deƒüerleri al\nnon_na_values &lt;- na_example[!is.na(na_example)]\n\n# NA deƒüerlerini rastgele bir NA olmayan deƒüerle deƒüi≈ütir\nna_example_random &lt;- ifelse(is.na(na_example), sample(non_na_values, 1), na_example)\n\n# Sonu√ßlarƒ± yazdƒ±r\nprint(na_example_random)\n\n   [1] 2 1 3 2 1 3 1 4 3 2 2 6 2 2 1 4 6 1 1 2 1 2 2 1 2 5 6 2 2 3 1 2 4 1 1 1 4\n  [38] 5 2 3 4 1 2 4 1 1 2 1 5 6 6 6 1 1 5 1 3 1 6 4 4 7 3 2 6 6 1 6 4 1 2 2 3 2\n  [75] 1 2 2 4 3 4 2 3 1 3 2 1 1 1 3 1 6 3 1 2 2 1 2 2 1 1 4 1 1 2 3 3 2 2 3 3 3\n [112] 4 1 1 1 2 6 4 3 4 3 1 2 1 6 6 6 6 1 5 1 2 1 3 5 3 2 2 6 6 6 6 3 5 3 1 1 4\n [149] 2 4 3 3 6 2 3 2 6 6 1 1 2 2 1 3 1 1 5 6 6 2 4 6 2 5 1 4 3 3 6 4 3 1 4 1 1\n [186] 3 1 1 6 6 3 5 2 2 2 3 1 2 2 3 2 1 6 2 6 1 6 6 2 1 1 6 3 6 1 2 2 1 3 2 2 1\n [223] 1 2 3 1 1 1 4 3 4 2 2 1 4 1 6 5 1 4 6 3 6 6 1 1 5 2 3 3 2 4 6 3 2 5 6 2 3\n [260] 4 6 2 2 2 6 2 6 2 6 3 3 2 2 4 3 1 4 2 6 2 4 6 6 2 3 1 6 2 2 6 1 1 3 2 3 3\n [297] 1 6 1 4 2 1 1 3 2 1 2 3 1 6 2 3 3 2 1 2 3 5 5 1 2 3 3 1 6 6 1 2 4 6 2 1 1\n [334] 1 3 2 1 1 3 4 6 1 2 1 1 3 3 6 1 1 3 5 3 2 3 4 1 4 3 1 6 2 1 2 2 1 2 2 6 1\n [371] 2 4 5 6 3 4 2 1 1 4 2 1 1 1 1 2 1 4 4 1 3 6 3 3 6 2 6 1 2 1 1 4 2 1 4 4 6\n [408] 1 2 6 3 2 2 2 1 4 3 6 1 2 3 1 3 2 2 2 1 1 3 2 1 1 1 3 2 2 6 4 4 4 1 1 6 4\n [445] 3 6 1 3 1 3 2 4 2 2 2 3 2 1 4 3 6 1 4 3 1 3 2 6 3 6 1 3 1 4 1 1 1 2 4 3 1\n [482] 2 2 2 3 2 3 1 1 6 3 2 1 1 2 6 2 2 2 3 3 1 1 2 6 1 2 1 1 3 3 1 3 1 1 1 1 1\n [519] 2 5 1 1 2 2 1 1 6 1 4 1 2 4 1 3 2 6 1 1 6 2 1 1 4 2 3 3 1 5 3 1 1 2 6 1 1\n [556] 3 1 3 2 4 6 2 3 2 1 2 1 1 1 2 2 3 1 5 2 6 2 6 3 2 2 2 1 5 3 2 3 1 6 3 1 2\n [593] 2 2 1 2 2 4 6 6 1 2 6 1 1 2 2 3 6 3 2 3 3 4 2 6 2 6 4 6 1 1 2 2 3 1 1 1 3\n [630] 6 2 5 6 7 1 6 4 3 3 1 6 1 1 1 1 3 2 4 2 2 3 6 6 1 4 3 2 2 2 3 2 4 2 2 4 6\n [667] 6 6 6 3 3 1 4 4 2 1 6 1 6 6 3 3 2 1 1 6 6 1 5 1 6 2 6 2 6 4 1 3 1 2 6 1 1\n [704] 3 1 2 4 2 1 3 2 4 3 2 2 1 1 5 6 4 2 2 2 2 4 6 1 2 2 2 2 4 5 6 6 6 4 3 3 3\n [741] 2 4 2 4 6 6 6 6 2 1 6 2 4 3 2 6 2 3 1 3 4 6 1 2 1 2 6 3 1 2 1 2 1 2 1 2 2\n [778] 2 2 1 1 3 3 1 3 4 3 6 6 4 2 3 2 1 3 2 4 2 2 3 1 2 4 3 3 4 6 1 4 2 1 1 1 3\n [815] 1 5 2 2 4 2 6 1 3 1 2 6 1 2 1 2 1 6 1 3 2 3 2 6 2 1 4 2 6 6 6 2 4 2 6 6 3\n [852] 1 6 5 5 2 2 2 6 2 1 3 1 3 2 4 2 4 6 4 1 2 3 2 3 3 2 3 2 2 2 1 3 2 4 2 6 3\n [889] 3 2 2 6 6 3 2 1 2 4 1 1 1 1 4 3 2 6 3 2 6 1 6 3 2 1 1 1 2 6 2 2 3 3 2 6 6\n [926] 4 5 2 2 2 1 2 3 1 3 3 4 3 6 1 1 1 6 4 3 5 1 1 2 6 2 2 2 2 5 2 2 3 1 2 3 6\n [963] 1 2 6 6 2 6 3 1 1 2 5 3 5 1 1 4 6 2 1 3 1 1 2 4 3 3 3 6 1 1 2 2 1 1 2 2 6\n[1000] 2\n\n\n\nversion2_median &lt;- median(na_example_random)\nversion2_sd &lt;- sd(na_example_random)\n\n# Sonu√ßlarƒ± yazdƒ±r\ncat(\"Versiyon 2 Medyan:\", version2_median, \"\\n\")\n\nVersiyon 2 Medyan: 2 \n\ncat(\"Versiyon 2 Sapma:\", version2_sd)\n\nVersiyon 2 Sapma: 1.725321\n\n\n\nlibrary(knitr)  # kable fonksiyonu i√ßin\n\nWarning: package 'knitr' was built under R version 4.4.3\n\n\n\n# Bu kod bloƒüu tamamen AI tarafƒ±ndan yazƒ±lmƒ±stƒ±r.\n# Sonu√ßlarƒ± birle≈ütirip tabloyu olu≈ütur\n\nstatistics_table &lt;- data.frame(\n  Method = c(\"Original (Mean)\", \"Original (SD)\", \n             \"Imputed (Median, Mean)\", \"Imputed (Median, SD)\", \n             \"Imputed (Random, Mean)\", \"Imputed (Random, SD)\"),\n  Value = c(mean_value, sd_value,\n            mean(na_example_median), sd(na_example_median),\n            mean(na_example_random), sd(na_example_random))\n)\n\n# Tabloyu yazdƒ±r\nkable(statistics_table, caption = \"Comparison of Statistics Before and After Handling NA Values\")\n\n\nComparison of Statistics Before and After Handling NA Values\n\n\nMethod\nValue\n\n\n\n\nOriginal (Mean)\n2.301754\n\n\nOriginal (SD)\n1.223380\n\n\nImputed (Median, Mean)\n2.258000\n\n\nImputed (Median, SD)\n1.136102\n\n\nImputed (Random, Mean)\n2.838000\n\n\nImputed (Random, SD)\n1.725321\n\n\n\n\n\nRegarding the data, imputing with the median seems more appropriate as it preserves the central tendency without being affected by outliers. Imputing with random values could better reflect the distribution of the data, but it may introduce some variability. Looking at the original data, if the number of missing values is minimal, ignoring them could be acceptable. However, if the missing values are not random, it could introduce bias in the data.",
    "crumbs": [
      "Handling Missing Values"
    ]
  },
  {
    "objectID": "assignments/handlingna.html#handling-missing-values-in-the-dslabs-na_example-dataset-methods-and-comparisons",
    "href": "assignments/handlingna.html#handling-missing-values-in-the-dslabs-na_example-dataset-methods-and-comparisons",
    "title": "NA_Example",
    "section": "",
    "text": "#install.packages(\"dslabs\")\nlibrary(dslabs)\n\nWarning: package 'dslabs' was built under R version 4.4.3\n\n\nAfter successfully installing and loading the ‚Äòdslabs‚Äô library, we can now print the desired dataset.\n\nprint(na_example)\n\n   [1]  2  1  3  2  1  3  1  4  3  2  2 NA  2  2  1  4 NA  1  1  2  1  2  2  1\n  [25]  2  5 NA  2  2  3  1  2  4  1  1  1  4  5  2  3  4  1  2  4  1  1  2  1\n  [49]  5 NA NA NA  1  1  5  1  3  1 NA  4  4  7  3  2 NA NA  1 NA  4  1  2  2\n  [73]  3  2  1  2  2  4  3  4  2  3  1  3  2  1  1  1  3  1 NA  3  1  2  2  1\n  [97]  2  2  1  1  4  1  1  2  3  3  2  2  3  3  3  4  1  1  1  2 NA  4  3  4\n [121]  3  1  2  1 NA NA NA NA  1  5  1  2  1  3  5  3  2  2 NA NA NA NA  3  5\n [145]  3  1  1  4  2  4  3  3 NA  2  3  2  6 NA  1  1  2  2  1  3  1  1  5 NA\n [169] NA  2  4 NA  2  5  1  4  3  3 NA  4  3  1  4  1  1  3  1  1 NA NA  3  5\n [193]  2  2  2  3  1  2  2  3  2  1 NA  2 NA  1 NA NA  2  1  1 NA  3 NA  1  2\n [217]  2  1  3  2  2  1  1  2  3  1  1  1  4  3  4  2  2  1  4  1 NA  5  1  4\n [241] NA  3 NA NA  1  1  5  2  3  3  2  4 NA  3  2  5 NA  2  3  4  6  2  2  2\n [265] NA  2 NA  2 NA  3  3  2  2  4  3  1  4  2 NA  2  4 NA  6  2  3  1 NA  2\n [289]  2 NA  1  1  3  2  3  3  1 NA  1  4  2  1  1  3  2  1  2  3  1 NA  2  3\n [313]  3  2  1  2  3  5  5  1  2  3  3  1 NA NA  1  2  4 NA  2  1  1  1  3  2\n [337]  1  1  3  4 NA  1  2  1  1  3  3 NA  1  1  3  5  3  2  3  4  1  4  3  1\n [361] NA  2  1  2  2  1  2  2  6  1  2  4  5 NA  3  4  2  1  1  4  2  1  1  1\n [385]  1  2  1  4  4  1  3 NA  3  3 NA  2 NA  1  2  1  1  4  2  1  4  4 NA  1\n [409]  2 NA  3  2  2  2  1  4  3  6  1  2  3  1  3  2  2  2  1  1  3  2  1  1\n [433]  1  3  2  2 NA  4  4  4  1  1 NA  4  3 NA  1  3  1  3  2  4  2  2  2  3\n [457]  2  1  4  3 NA  1  4  3  1  3  2 NA  3 NA  1  3  1  4  1  1  1  2  4  3\n [481]  1  2  2  2  3  2  3  1  1 NA  3  2  1  1  2 NA  2  2  2  3  3  1  1  2\n [505] NA  1  2  1  1  3  3  1  3  1  1  1  1  1  2  5  1  1  2  2  1  1 NA  1\n [529]  4  1  2  4  1  3  2 NA  1  1 NA  2  1  1  4  2  3  3  1  5  3  1  1  2\n [553] NA  1  1  3  1  3  2  4 NA  2  3  2  1  2  1  1  1  2  2  3  1  5  2 NA\n [577]  2 NA  3  2  2  2  1  5  3  2  3  1 NA  3  1  2  2  2  1  2  2  4 NA  6\n [601]  1  2 NA  1  1  2  2  3 NA  3  2  3  3  4  2 NA  2 NA  4 NA  1  1  2  2\n [625]  3  1  1  1  3 NA  2  5 NA  7  1 NA  4  3  3  1 NA  1  1  1  1  3  2  4\n [649]  2  2  3 NA NA  1  4  3  2  2  2  3  2  4  2  2  4 NA NA NA  6  3  3  1\n [673]  4  4  2  1 NA  1  6 NA  3  3  2  1  1  6 NA  1  5  1 NA  2  6  2 NA  4\n [697]  1  3  1  2 NA  1  1  3  1  2  4  2  1  3  2  4  3  2  2  1  1  5  6  4\n [721]  2  2  2  2  4 NA  1  2  2  2  2  4  5 NA NA NA  4  3  3  3  2  4  2  4\n [745] NA NA NA NA  2  1 NA  2  4  3  2 NA  2  3  1  3  4 NA  1  2  1  2 NA  3\n [769]  1  2  1  2  1  2  1  2  2  2  2  1  1  3  3  1  3  4  3 NA NA  4  2  3\n [793]  2  1  3  2  4  2  2  3  1  2  4  3  3  4 NA  1  4  2  1  1  1  3  1  5\n [817]  2  2  4  2 NA  1  3  1  2 NA  1  2  1  2  1 NA  1  3  2  3  2 NA  2  1\n [841]  4  2 NA NA NA  2  4  2 NA NA  3  1 NA  5  5  2  2  2 NA  2  1  3  1  3\n [865]  2  4  2  4 NA  4  1  2  3  2  3  3  2  3  2  2  2  1  3  2  4  2 NA  3\n [889]  3  2  2 NA NA  3  2  1  2  4  1  1  1  1  4  3  2 NA  3  2 NA  1 NA  3\n [913]  2  1  1  1  2 NA  2  2  3  3  2 NA NA  4  5  2  2  2  1  2  3  1  3  3\n [937]  4  3 NA  1  1  1 NA  4  3  5  1  1  2 NA  2  2  2  2  5  2  2  3  1  2\n [961]  3 NA  1  2 NA NA  2 NA  3  1  1  2  5  3  5  1  1  4 NA  2  1  3  1  1\n [985]  2  4  3  3  3 NA  1  1  2  2  1  1  2  2 NA  2\n\n\n\n\n\nThis R code calculates the missing values (NA) within the ‚Äòna_example‚Äô dataset. Initially, we determined the total count of NA values present and identified their index positions within the dataset.\n\ntotal_na &lt;- sum(is.na(na_example))\ncat(\"Total NA values:\", total_na)\n\nTotal NA values: 145\n\n\n\nwhich(is.na(na_example))\n\n  [1]  12  17  27  50  51  52  59  65  66  68  91 117 125 126 127 128 139 140\n [19] 141 142 153 158 168 169 172 179 189 190 203 205 207 208 212 214 237 241\n [37] 243 244 253 257 265 267 269 279 282 287 290 298 310 325 326 330 341 348\n [55] 361 374 392 395 397 407 410 437 443 446 461 468 470 490 496 505 527 536\n [73] 539 553 561 576 578 589 599 603 609 616 618 620 630 633 636 641 652 653\n [91] 666 667 668 677 680 687 691 695 701 726 734 735 736 745 746 747 748 751\n[109] 756 762 767 788 789 807 821 826 832 838 843 844 845 849 850 853 859 869\n[127] 887 892 893 906 909 911 918 924 925 939 943 950 962 965 966 968 979 990\n[145] 999\n\n\n\n\n\n\n# NA deƒüerleri g√∂z ardƒ± ederek ortalama ve standart sapma hesapla\nmean_value &lt;- mean(na_example, na.rm = TRUE)\nsd_value &lt;- sd(na_example, na.rm = TRUE)\n\n# Sonu√ßlarƒ± ekrana yazdƒ±r\ncat(\"Mean:\", mean_value, \"\\n\")\n\nMean: 2.301754 \n\ncat(\"Standart Deviation:\", sd_value)\n\nStandart Deviation: 1.22338\n\n\n\n\n\nIn this process, we replace all missing (NA) values in the na_example dataset with the median of the non-missing values. The median is chosen because it is less sensitive to extreme values (outliers) compared to the mean.\n\n# NA olmayan deƒüerlerin medyanƒ±nƒ± hesapla\nmedian_others &lt;- median(na_example, na.rm = TRUE)\n\n# NA deƒüerleri medyan ile deƒüi≈ütir\nna_example_median &lt;- ifelse(is.na(na_example), median_others, na_example)\n\n# Sonucu yazdƒ±r\ncat(\"Medyan:\", median_others, \"\\n\")\n\nMedyan: 2 \n\nprint(na_example_median)\n\n   [1] 2 1 3 2 1 3 1 4 3 2 2 2 2 2 1 4 2 1 1 2 1 2 2 1 2 5 2 2 2 3 1 2 4 1 1 1 4\n  [38] 5 2 3 4 1 2 4 1 1 2 1 5 2 2 2 1 1 5 1 3 1 2 4 4 7 3 2 2 2 1 2 4 1 2 2 3 2\n  [75] 1 2 2 4 3 4 2 3 1 3 2 1 1 1 3 1 2 3 1 2 2 1 2 2 1 1 4 1 1 2 3 3 2 2 3 3 3\n [112] 4 1 1 1 2 2 4 3 4 3 1 2 1 2 2 2 2 1 5 1 2 1 3 5 3 2 2 2 2 2 2 3 5 3 1 1 4\n [149] 2 4 3 3 2 2 3 2 6 2 1 1 2 2 1 3 1 1 5 2 2 2 4 2 2 5 1 4 3 3 2 4 3 1 4 1 1\n [186] 3 1 1 2 2 3 5 2 2 2 3 1 2 2 3 2 1 2 2 2 1 2 2 2 1 1 2 3 2 1 2 2 1 3 2 2 1\n [223] 1 2 3 1 1 1 4 3 4 2 2 1 4 1 2 5 1 4 2 3 2 2 1 1 5 2 3 3 2 4 2 3 2 5 2 2 3\n [260] 4 6 2 2 2 2 2 2 2 2 3 3 2 2 4 3 1 4 2 2 2 4 2 6 2 3 1 2 2 2 2 1 1 3 2 3 3\n [297] 1 2 1 4 2 1 1 3 2 1 2 3 1 2 2 3 3 2 1 2 3 5 5 1 2 3 3 1 2 2 1 2 4 2 2 1 1\n [334] 1 3 2 1 1 3 4 2 1 2 1 1 3 3 2 1 1 3 5 3 2 3 4 1 4 3 1 2 2 1 2 2 1 2 2 6 1\n [371] 2 4 5 2 3 4 2 1 1 4 2 1 1 1 1 2 1 4 4 1 3 2 3 3 2 2 2 1 2 1 1 4 2 1 4 4 2\n [408] 1 2 2 3 2 2 2 1 4 3 6 1 2 3 1 3 2 2 2 1 1 3 2 1 1 1 3 2 2 2 4 4 4 1 1 2 4\n [445] 3 2 1 3 1 3 2 4 2 2 2 3 2 1 4 3 2 1 4 3 1 3 2 2 3 2 1 3 1 4 1 1 1 2 4 3 1\n [482] 2 2 2 3 2 3 1 1 2 3 2 1 1 2 2 2 2 2 3 3 1 1 2 2 1 2 1 1 3 3 1 3 1 1 1 1 1\n [519] 2 5 1 1 2 2 1 1 2 1 4 1 2 4 1 3 2 2 1 1 2 2 1 1 4 2 3 3 1 5 3 1 1 2 2 1 1\n [556] 3 1 3 2 4 2 2 3 2 1 2 1 1 1 2 2 3 1 5 2 2 2 2 3 2 2 2 1 5 3 2 3 1 2 3 1 2\n [593] 2 2 1 2 2 4 2 6 1 2 2 1 1 2 2 3 2 3 2 3 3 4 2 2 2 2 4 2 1 1 2 2 3 1 1 1 3\n [630] 2 2 5 2 7 1 2 4 3 3 1 2 1 1 1 1 3 2 4 2 2 3 2 2 1 4 3 2 2 2 3 2 4 2 2 4 2\n [667] 2 2 6 3 3 1 4 4 2 1 2 1 6 2 3 3 2 1 1 6 2 1 5 1 2 2 6 2 2 4 1 3 1 2 2 1 1\n [704] 3 1 2 4 2 1 3 2 4 3 2 2 1 1 5 6 4 2 2 2 2 4 2 1 2 2 2 2 4 5 2 2 2 4 3 3 3\n [741] 2 4 2 4 2 2 2 2 2 1 2 2 4 3 2 2 2 3 1 3 4 2 1 2 1 2 2 3 1 2 1 2 1 2 1 2 2\n [778] 2 2 1 1 3 3 1 3 4 3 2 2 4 2 3 2 1 3 2 4 2 2 3 1 2 4 3 3 4 2 1 4 2 1 1 1 3\n [815] 1 5 2 2 4 2 2 1 3 1 2 2 1 2 1 2 1 2 1 3 2 3 2 2 2 1 4 2 2 2 2 2 4 2 2 2 3\n [852] 1 2 5 5 2 2 2 2 2 1 3 1 3 2 4 2 4 2 4 1 2 3 2 3 3 2 3 2 2 2 1 3 2 4 2 2 3\n [889] 3 2 2 2 2 3 2 1 2 4 1 1 1 1 4 3 2 2 3 2 2 1 2 3 2 1 1 1 2 2 2 2 3 3 2 2 2\n [926] 4 5 2 2 2 1 2 3 1 3 3 4 3 2 1 1 1 2 4 3 5 1 1 2 2 2 2 2 2 5 2 2 3 1 2 3 2\n [963] 1 2 2 2 2 2 3 1 1 2 5 3 5 1 1 4 2 2 1 3 1 1 2 4 3 3 3 2 1 1 2 2 1 1 2 2 2\n[1000] 2\n\n\n\nversion1_median &lt;- median(na_example_median)\nversion1_sd &lt;- sd(na_example_median)\n\n# Sonu√ßlarƒ± yazdƒ±r\ncat(\"Versiyon 1 Medyan:\", version1_median, \"\\n\")\n\nVersiyon 1 Medyan: 2 \n\ncat(\"Versiyon 1 Sapma:\", version1_sd)\n\nVersiyon 1 Sapma: 1.136102\n\n\n\n\n\nThis process replaces all NA values in the dataset with a randomly selected non-missing value from the same dataset. First, we extract all non-missing values, then for each NA, a random value from the non-missing values is chosen to fill in the missing spot.\n\n# NA olmayan deƒüerleri al\nnon_na_values &lt;- na_example[!is.na(na_example)]\n\n# NA deƒüerlerini rastgele bir NA olmayan deƒüerle deƒüi≈ütir\nna_example_random &lt;- ifelse(is.na(na_example), sample(non_na_values, 1), na_example)\n\n# Sonu√ßlarƒ± yazdƒ±r\nprint(na_example_random)\n\n   [1] 2 1 3 2 1 3 1 4 3 2 2 6 2 2 1 4 6 1 1 2 1 2 2 1 2 5 6 2 2 3 1 2 4 1 1 1 4\n  [38] 5 2 3 4 1 2 4 1 1 2 1 5 6 6 6 1 1 5 1 3 1 6 4 4 7 3 2 6 6 1 6 4 1 2 2 3 2\n  [75] 1 2 2 4 3 4 2 3 1 3 2 1 1 1 3 1 6 3 1 2 2 1 2 2 1 1 4 1 1 2 3 3 2 2 3 3 3\n [112] 4 1 1 1 2 6 4 3 4 3 1 2 1 6 6 6 6 1 5 1 2 1 3 5 3 2 2 6 6 6 6 3 5 3 1 1 4\n [149] 2 4 3 3 6 2 3 2 6 6 1 1 2 2 1 3 1 1 5 6 6 2 4 6 2 5 1 4 3 3 6 4 3 1 4 1 1\n [186] 3 1 1 6 6 3 5 2 2 2 3 1 2 2 3 2 1 6 2 6 1 6 6 2 1 1 6 3 6 1 2 2 1 3 2 2 1\n [223] 1 2 3 1 1 1 4 3 4 2 2 1 4 1 6 5 1 4 6 3 6 6 1 1 5 2 3 3 2 4 6 3 2 5 6 2 3\n [260] 4 6 2 2 2 6 2 6 2 6 3 3 2 2 4 3 1 4 2 6 2 4 6 6 2 3 1 6 2 2 6 1 1 3 2 3 3\n [297] 1 6 1 4 2 1 1 3 2 1 2 3 1 6 2 3 3 2 1 2 3 5 5 1 2 3 3 1 6 6 1 2 4 6 2 1 1\n [334] 1 3 2 1 1 3 4 6 1 2 1 1 3 3 6 1 1 3 5 3 2 3 4 1 4 3 1 6 2 1 2 2 1 2 2 6 1\n [371] 2 4 5 6 3 4 2 1 1 4 2 1 1 1 1 2 1 4 4 1 3 6 3 3 6 2 6 1 2 1 1 4 2 1 4 4 6\n [408] 1 2 6 3 2 2 2 1 4 3 6 1 2 3 1 3 2 2 2 1 1 3 2 1 1 1 3 2 2 6 4 4 4 1 1 6 4\n [445] 3 6 1 3 1 3 2 4 2 2 2 3 2 1 4 3 6 1 4 3 1 3 2 6 3 6 1 3 1 4 1 1 1 2 4 3 1\n [482] 2 2 2 3 2 3 1 1 6 3 2 1 1 2 6 2 2 2 3 3 1 1 2 6 1 2 1 1 3 3 1 3 1 1 1 1 1\n [519] 2 5 1 1 2 2 1 1 6 1 4 1 2 4 1 3 2 6 1 1 6 2 1 1 4 2 3 3 1 5 3 1 1 2 6 1 1\n [556] 3 1 3 2 4 6 2 3 2 1 2 1 1 1 2 2 3 1 5 2 6 2 6 3 2 2 2 1 5 3 2 3 1 6 3 1 2\n [593] 2 2 1 2 2 4 6 6 1 2 6 1 1 2 2 3 6 3 2 3 3 4 2 6 2 6 4 6 1 1 2 2 3 1 1 1 3\n [630] 6 2 5 6 7 1 6 4 3 3 1 6 1 1 1 1 3 2 4 2 2 3 6 6 1 4 3 2 2 2 3 2 4 2 2 4 6\n [667] 6 6 6 3 3 1 4 4 2 1 6 1 6 6 3 3 2 1 1 6 6 1 5 1 6 2 6 2 6 4 1 3 1 2 6 1 1\n [704] 3 1 2 4 2 1 3 2 4 3 2 2 1 1 5 6 4 2 2 2 2 4 6 1 2 2 2 2 4 5 6 6 6 4 3 3 3\n [741] 2 4 2 4 6 6 6 6 2 1 6 2 4 3 2 6 2 3 1 3 4 6 1 2 1 2 6 3 1 2 1 2 1 2 1 2 2\n [778] 2 2 1 1 3 3 1 3 4 3 6 6 4 2 3 2 1 3 2 4 2 2 3 1 2 4 3 3 4 6 1 4 2 1 1 1 3\n [815] 1 5 2 2 4 2 6 1 3 1 2 6 1 2 1 2 1 6 1 3 2 3 2 6 2 1 4 2 6 6 6 2 4 2 6 6 3\n [852] 1 6 5 5 2 2 2 6 2 1 3 1 3 2 4 2 4 6 4 1 2 3 2 3 3 2 3 2 2 2 1 3 2 4 2 6 3\n [889] 3 2 2 6 6 3 2 1 2 4 1 1 1 1 4 3 2 6 3 2 6 1 6 3 2 1 1 1 2 6 2 2 3 3 2 6 6\n [926] 4 5 2 2 2 1 2 3 1 3 3 4 3 6 1 1 1 6 4 3 5 1 1 2 6 2 2 2 2 5 2 2 3 1 2 3 6\n [963] 1 2 6 6 2 6 3 1 1 2 5 3 5 1 1 4 6 2 1 3 1 1 2 4 3 3 3 6 1 1 2 2 1 1 2 2 6\n[1000] 2\n\n\n\nversion2_median &lt;- median(na_example_random)\nversion2_sd &lt;- sd(na_example_random)\n\n# Sonu√ßlarƒ± yazdƒ±r\ncat(\"Versiyon 2 Medyan:\", version2_median, \"\\n\")\n\nVersiyon 2 Medyan: 2 \n\ncat(\"Versiyon 2 Sapma:\", version2_sd)\n\nVersiyon 2 Sapma: 1.725321\n\n\n\nlibrary(knitr)  # kable fonksiyonu i√ßin\n\nWarning: package 'knitr' was built under R version 4.4.3\n\n\n\n# Bu kod bloƒüu tamamen AI tarafƒ±ndan yazƒ±lmƒ±stƒ±r.\n# Sonu√ßlarƒ± birle≈ütirip tabloyu olu≈ütur\n\nstatistics_table &lt;- data.frame(\n  Method = c(\"Original (Mean)\", \"Original (SD)\", \n             \"Imputed (Median, Mean)\", \"Imputed (Median, SD)\", \n             \"Imputed (Random, Mean)\", \"Imputed (Random, SD)\"),\n  Value = c(mean_value, sd_value,\n            mean(na_example_median), sd(na_example_median),\n            mean(na_example_random), sd(na_example_random))\n)\n\n# Tabloyu yazdƒ±r\nkable(statistics_table, caption = \"Comparison of Statistics Before and After Handling NA Values\")\n\n\nComparison of Statistics Before and After Handling NA Values\n\n\nMethod\nValue\n\n\n\n\nOriginal (Mean)\n2.301754\n\n\nOriginal (SD)\n1.223380\n\n\nImputed (Median, Mean)\n2.258000\n\n\nImputed (Median, SD)\n1.136102\n\n\nImputed (Random, Mean)\n2.838000\n\n\nImputed (Random, SD)\n1.725321\n\n\n\n\n\nRegarding the data, imputing with the median seems more appropriate as it preserves the central tendency without being affected by outliers. Imputing with random values could better reflect the distribution of the data, but it may introduce some variability. Looking at the original data, if the number of missing values is minimal, ignoring them could be acceptable. However, if the missing values are not random, it could introduce bias in the data.",
    "crumbs": [
      "Handling Missing Values"
    ]
  },
  {
    "objectID": "assignments.html",
    "href": "assignments.html",
    "title": "My Assignments",
    "section": "",
    "text": "On this page, I showcase the assignment I conducted for the [term and year, e.g.¬†Spring 2024-2025] EMU660 Decision Making with Analytics course. xx\nPlease use left menu to navigate through my assignments.\n\n\n\n Back to top",
    "crumbs": [
      "Assignments"
    ]
  },
  {
    "objectID": "posts.html",
    "href": "posts.html",
    "title": "My Blog",
    "section": "",
    "text": "This page is under construction.\n\n\n\n Back to top"
  }
]