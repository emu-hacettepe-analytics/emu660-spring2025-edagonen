[
  {
    "objectID": "project.html",
    "href": "project.html",
    "title": "Project Genre Matters: Exploring Film Audience Preferences",
    "section": "",
    "text": "Welcome to our project page.\nBeg√ºm √áORUH & Eda G√ñNEN\nKeep an eye on this space to stay updated with our project activities."
  },
  {
    "objectID": "project.html#data-source",
    "href": "project.html#data-source",
    "title": "Project X",
    "section": "2.1 Data Source",
    "text": "2.1 Data Source\nxxxxxx"
  },
  {
    "objectID": "project.html#general-information-about-data",
    "href": "project.html#general-information-about-data",
    "title": "Project X",
    "section": "2.2 General Information About Data",
    "text": "2.2 General Information About Data\nxxxxxx"
  },
  {
    "objectID": "project.html#reason-of-choice",
    "href": "project.html#reason-of-choice",
    "title": "Project X",
    "section": "2.3 Reason of Choice",
    "text": "2.3 Reason of Choice\nxxxxxx"
  },
  {
    "objectID": "project.html#preprocessing",
    "href": "project.html#preprocessing",
    "title": "Project X",
    "section": "2.4 Preprocessing",
    "text": "2.4 Preprocessing\nxxxxxx"
  },
  {
    "objectID": "project.html#exploratory-data-analysis",
    "href": "project.html#exploratory-data-analysis",
    "title": "Project X",
    "section": "3.1 Exploratory Data Analysis",
    "text": "3.1 Exploratory Data Analysis\nxxxxxx"
  },
  {
    "objectID": "project.html#trend-analysis",
    "href": "project.html#trend-analysis",
    "title": "Project X",
    "section": "3.2 Trend Analysis",
    "text": "3.2 Trend Analysis\nxxxxxx"
  },
  {
    "objectID": "project.html#model-fitting",
    "href": "project.html#model-fitting",
    "title": "Project X",
    "section": "3.3 Model Fitting",
    "text": "3.3 Model Fitting\nxxxxxx"
  },
  {
    "objectID": "project.html#results",
    "href": "project.html#results",
    "title": "Project X",
    "section": "3.4 Results",
    "text": "3.4 Results\nxxxxxx"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Welcome to My Analytic Lab",
    "section": "",
    "text": "Hello! I‚Äôm Eda G√∂nen.\nWelcome to my personal website! Here, I share my work in data analytics, blog posts, and a few different projects. I enjoy working with data and finding new ways to understand it. I‚Äôll also be sharing my thoughts on technology from time to time.\nStay tuned, there‚Äôs plenty to discover and learn together!\n\n\n\n Back to top"
  },
  {
    "objectID": "index.html#deneme",
    "href": "index.html#deneme",
    "title": "Welcome to My Analytics Lab",
    "section": "Deneme",
    "text": "Deneme"
  },
  {
    "objectID": "assignments/statisticsofmrcars.html",
    "href": "assignments/statisticsofmrcars.html",
    "title": "Mtcars Statistical Analysis",
    "section": "",
    "text": "In R, data(mtcars) loads the mtcars dataset, which contains features of 32 cars. str(mtcars) then displays the dataset‚Äôs structure, revealing the types and initial values of its columns, providing a quick overview.\n\ndata(mtcars)\nstr(mtcars)\n\n'data.frame':   32 obs. of  11 variables:\n $ mpg : num  21 21 22.8 21.4 18.7 18.1 14.3 24.4 22.8 19.2 ...\n $ cyl : num  6 6 4 6 8 6 8 4 4 6 ...\n $ disp: num  160 160 108 258 360 ...\n $ hp  : num  110 110 93 110 175 105 245 62 95 123 ...\n $ drat: num  3.9 3.9 3.85 3.08 3.15 2.76 3.21 3.69 3.92 3.92 ...\n $ wt  : num  2.62 2.88 2.32 3.21 3.44 ...\n $ qsec: num  16.5 17 18.6 19.4 17 ...\n $ vs  : num  0 0 1 1 0 1 0 1 1 1 ...\n $ am  : num  1 1 1 0 0 0 0 0 0 0 ...\n $ gear: num  4 4 4 3 3 3 3 4 4 4 ...\n $ carb: num  4 4 1 1 2 1 4 2 2 4 ...\n\n\n\n\n\nThis R code calculates basic statistics for numerical columns in the mtcars dataset. It defines a function, compute_stats, to find the mean, median, variance, IQR, min, and max of a numeric vector, handling potential missing values. A for loop iterates through each column of mtcars, applying compute_stats to numerical ones. The results, with column names, are stored in a list and printed, providing a summary of each numerical column‚Äôs statistics.\n\n# ƒ∞statistikleri hesaplayan fonksiyon\ncompute_stats &lt;- function(x) {\n  # Girdi sayƒ±sal mƒ± kontrol et\n  if (!is.numeric(x)) {\n    stop(\"Hata: Girdi sayƒ±sal bir vekt√∂r olmalƒ±dƒ±r.\")\n  }\n\n  # ƒ∞statistik hesaplamalarƒ±\n  mean_x &lt;- mean(x, na.rm = TRUE)\n  median_x &lt;- median(x, na.rm = TRUE)\n  var_x &lt;- var(x, na.rm = TRUE)\n  iqr_x &lt;- IQR(x, na.rm = TRUE)\n  min_x &lt;- min(x, na.rm = TRUE)\n  max_x &lt;- max(x, na.rm = TRUE)\n\n  # Sonu√ßlarƒ± i√ßeren listeyi d√∂nd√ºr\n  compute_stats_list &lt;- list(\n    mean = mean_x,\n    median = median_x,\n    variance = var_x,\n    IQR = iqr_x,\n    min = min_x,\n    maks = max_x\n  )\n\n  return(compute_stats_list)\n}\n\n# mtcars veri seti i√ßin t√ºm sayƒ±sal s√ºtunlarƒ±n istatistiklerini hesapla\nmtcars_istatistikleri &lt;- list() # Bo≈ü bir liste olu≈ütur\n\nfor (header in names(mtcars)) {\n  if (is.numeric(mtcars[[header]])) {\n    mtcars_istatistikleri[[header]] &lt;- compute_stats(mtcars[[header]]) # Sonu√ßlarƒ± listeye ekle\n  }\n}\n\n# Sonu√ßlarƒ± yazdƒ±r\nprint(mtcars_istatistikleri)\n\n$mpg\n$mpg$mean\n[1] 20.09062\n\n$mpg$median\n[1] 19.2\n\n$mpg$variance\n[1] 36.3241\n\n$mpg$IQR\n[1] 7.375\n\n$mpg$min\n[1] 10.4\n\n$mpg$maks\n[1] 33.9\n\n\n$cyl\n$cyl$mean\n[1] 6.1875\n\n$cyl$median\n[1] 6\n\n$cyl$variance\n[1] 3.189516\n\n$cyl$IQR\n[1] 4\n\n$cyl$min\n[1] 4\n\n$cyl$maks\n[1] 8\n\n\n$disp\n$disp$mean\n[1] 230.7219\n\n$disp$median\n[1] 196.3\n\n$disp$variance\n[1] 15360.8\n\n$disp$IQR\n[1] 205.175\n\n$disp$min\n[1] 71.1\n\n$disp$maks\n[1] 472\n\n\n$hp\n$hp$mean\n[1] 146.6875\n\n$hp$median\n[1] 123\n\n$hp$variance\n[1] 4700.867\n\n$hp$IQR\n[1] 83.5\n\n$hp$min\n[1] 52\n\n$hp$maks\n[1] 335\n\n\n$drat\n$drat$mean\n[1] 3.596563\n\n$drat$median\n[1] 3.695\n\n$drat$variance\n[1] 0.2858814\n\n$drat$IQR\n[1] 0.84\n\n$drat$min\n[1] 2.76\n\n$drat$maks\n[1] 4.93\n\n\n$wt\n$wt$mean\n[1] 3.21725\n\n$wt$median\n[1] 3.325\n\n$wt$variance\n[1] 0.957379\n\n$wt$IQR\n[1] 1.02875\n\n$wt$min\n[1] 1.513\n\n$wt$maks\n[1] 5.424\n\n\n$qsec\n$qsec$mean\n[1] 17.84875\n\n$qsec$median\n[1] 17.71\n\n$qsec$variance\n[1] 3.193166\n\n$qsec$IQR\n[1] 2.0075\n\n$qsec$min\n[1] 14.5\n\n$qsec$maks\n[1] 22.9\n\n\n$vs\n$vs$mean\n[1] 0.4375\n\n$vs$median\n[1] 0\n\n$vs$variance\n[1] 0.2540323\n\n$vs$IQR\n[1] 1\n\n$vs$min\n[1] 0\n\n$vs$maks\n[1] 1\n\n\n$am\n$am$mean\n[1] 0.40625\n\n$am$median\n[1] 0\n\n$am$variance\n[1] 0.2489919\n\n$am$IQR\n[1] 1\n\n$am$min\n[1] 0\n\n$am$maks\n[1] 1\n\n\n$gear\n$gear$mean\n[1] 3.6875\n\n$gear$median\n[1] 4\n\n$gear$variance\n[1] 0.5443548\n\n$gear$IQR\n[1] 1\n\n$gear$min\n[1] 3\n\n$gear$maks\n[1] 5\n\n\n$carb\n$carb$mean\n[1] 2.8125\n\n$carb$median\n[1] 2\n\n$carb$variance\n[1] 2.608871\n\n$carb$IQR\n[1] 2\n\n$carb$min\n[1] 1\n\n$carb$maks\n[1] 8\n\n\nTo automate statistical analysis of numerical columns within the mtcars dataset, a for loop iterates through each column name. Utilizing is.numeric(), the loop identifies numerical columns and applies the compute_stats function. This function calculates key statistics like mean, median, and variance, returning them in a named list. The loop then stores these results, indexed by column names, within a comprehensive list, which is subsequently printed. This approach efficiently provides a structured statistical overview of all numerical columns in the dataset.\n\n\n\nThe sapply function in R is a user-friendly and efficient way to apply a function over a list or vector. In the context of the mtcars dataset, sapply iterates through each column, applying the compute_stats function to those that are numeric. This streamlines the process of calculating statistics for multiple columns, returning the results in a simplified format, such as a vector or matrix. Its ability to directly handle data frames makes it a powerful tool for quick statistical analysis.\n\n# sapply ile t√ºm s√ºtunlara compute_stats fonksiyonunu uygula\nmtcars_istatistikleri_sapply &lt;- sapply(mtcars, compute_stats)\n\n# Sonu√ßlarƒ± yazdƒ±r\nprint(mtcars_istatistikleri_sapply)\n\n         mpg      cyl      disp     hp       drat      wt       qsec    \nmean     20.09062 6.1875   230.7219 146.6875 3.596563  3.21725  17.84875\nmedian   19.2     6        196.3    123      3.695     3.325    17.71   \nvariance 36.3241  3.189516 15360.8  4700.867 0.2858814 0.957379 3.193166\nIQR      7.375    4        205.175  83.5     0.84      1.02875  2.0075  \nmin      10.4     4        71.1     52       2.76      1.513    14.5    \nmaks     33.9     8        472      335      4.93      5.424    22.9    \n         vs        am        gear      carb    \nmean     0.4375    0.40625   3.6875    2.8125  \nmedian   0         0         4         2       \nvariance 0.2540323 0.2489919 0.5443548 2.608871\nIQR      1         1         1         2       \nmin      0         0         3         1       \nmaks     1         1         5         8       \n\n\nThe apply function in R is designed to apply a function over the rows or columns of a matrix or array. In this scenario, the mtcars data frame is first converted to a matrix. Then, apply is used to iterate over the columns, applying the compute_stats function to each. This approach allows for consistent application of statistical calculations across all columns, returning the results in a structured format. While apply is versatile, it requires the data to be in a matrix format, making it slightly less direct for data frames compared to sapply.\n\n# apply ile t√ºm s√ºtunlara compute_stats fonksiyonunu uygula\nmtcars_istatistikleri_apply &lt;- apply(mtcars, MARGIN = 2, compute_stats)\n\n# Sonu√ßlarƒ± yazdƒ±r\nprint(mtcars_istatistikleri_apply)\n\n$mpg\n$mpg$mean\n[1] 20.09062\n\n$mpg$median\n[1] 19.2\n\n$mpg$variance\n[1] 36.3241\n\n$mpg$IQR\n[1] 7.375\n\n$mpg$min\n[1] 10.4\n\n$mpg$maks\n[1] 33.9\n\n\n$cyl\n$cyl$mean\n[1] 6.1875\n\n$cyl$median\n[1] 6\n\n$cyl$variance\n[1] 3.189516\n\n$cyl$IQR\n[1] 4\n\n$cyl$min\n[1] 4\n\n$cyl$maks\n[1] 8\n\n\n$disp\n$disp$mean\n[1] 230.7219\n\n$disp$median\n[1] 196.3\n\n$disp$variance\n[1] 15360.8\n\n$disp$IQR\n[1] 205.175\n\n$disp$min\n[1] 71.1\n\n$disp$maks\n[1] 472\n\n\n$hp\n$hp$mean\n[1] 146.6875\n\n$hp$median\n[1] 123\n\n$hp$variance\n[1] 4700.867\n\n$hp$IQR\n[1] 83.5\n\n$hp$min\n[1] 52\n\n$hp$maks\n[1] 335\n\n\n$drat\n$drat$mean\n[1] 3.596563\n\n$drat$median\n[1] 3.695\n\n$drat$variance\n[1] 0.2858814\n\n$drat$IQR\n[1] 0.84\n\n$drat$min\n[1] 2.76\n\n$drat$maks\n[1] 4.93\n\n\n$wt\n$wt$mean\n[1] 3.21725\n\n$wt$median\n[1] 3.325\n\n$wt$variance\n[1] 0.957379\n\n$wt$IQR\n[1] 1.02875\n\n$wt$min\n[1] 1.513\n\n$wt$maks\n[1] 5.424\n\n\n$qsec\n$qsec$mean\n[1] 17.84875\n\n$qsec$median\n[1] 17.71\n\n$qsec$variance\n[1] 3.193166\n\n$qsec$IQR\n[1] 2.0075\n\n$qsec$min\n[1] 14.5\n\n$qsec$maks\n[1] 22.9\n\n\n$vs\n$vs$mean\n[1] 0.4375\n\n$vs$median\n[1] 0\n\n$vs$variance\n[1] 0.2540323\n\n$vs$IQR\n[1] 1\n\n$vs$min\n[1] 0\n\n$vs$maks\n[1] 1\n\n\n$am\n$am$mean\n[1] 0.40625\n\n$am$median\n[1] 0\n\n$am$variance\n[1] 0.2489919\n\n$am$IQR\n[1] 1\n\n$am$min\n[1] 0\n\n$am$maks\n[1] 1\n\n\n$gear\n$gear$mean\n[1] 3.6875\n\n$gear$median\n[1] 4\n\n$gear$variance\n[1] 0.5443548\n\n$gear$IQR\n[1] 1\n\n$gear$min\n[1] 3\n\n$gear$maks\n[1] 5\n\n\n$carb\n$carb$mean\n[1] 2.8125\n\n$carb$median\n[1] 2\n\n$carb$variance\n[1] 2.608871\n\n$carb$IQR\n[1] 2\n\n$carb$min\n[1] 1\n\n$carb$maks\n[1] 8",
    "crumbs": [
      "MRCars Statistics"
    ]
  },
  {
    "objectID": "assignments/statisticsofmrcars.html#statistical-analysis-of-the-mtcars-dataset-in-r",
    "href": "assignments/statisticsofmrcars.html#statistical-analysis-of-the-mtcars-dataset-in-r",
    "title": "Mtcars Statistical Analysis",
    "section": "Statistical Analysis of the mtcars Dataset in R",
    "text": "Statistical Analysis of the mtcars Dataset in R\n\nQuick Overview of the mtcars Dataset\nIn R, data(mtcars) loads the mtcars dataset, which contains features of 32 cars. str(mtcars) then displays the dataset‚Äôs structure, revealing the types and initial values of its columns, providing a quick overview.\n\ndata(mtcars)\nstr(mtcars)\n\n'data.frame':   32 obs. of  11 variables:\n $ mpg : num  21 21 22.8 21.4 18.7 18.1 14.3 24.4 22.8 19.2 ...\n $ cyl : num  6 6 4 6 8 6 8 4 4 6 ...\n $ disp: num  160 160 108 258 360 ...\n $ hp  : num  110 110 93 110 175 105 245 62 95 123 ...\n $ drat: num  3.9 3.9 3.85 3.08 3.15 2.76 3.21 3.69 3.92 3.92 ...\n $ wt  : num  2.62 2.88 2.32 3.21 3.44 ...\n $ qsec: num  16.5 17 18.6 19.4 17 ...\n $ vs  : num  0 0 1 1 0 1 0 1 1 1 ...\n $ am  : num  1 1 1 0 0 0 0 0 0 0 ...\n $ gear: num  4 4 4 3 3 3 3 4 4 4 ...\n $ carb: num  4 4 1 1 2 1 4 2 2 4 ...\n\n\n\n\nWrite a Custom Summary Function & Applying the Function Using a Loop\nThis R code calculates basic statistics for numerical columns in the mtcars dataset. It defines a function, compute_stats, to find the mean, median, variance, IQR, min, and max of a numeric vector, handling potential missing values. A for loop iterates through each column of mtcars, applying compute_stats to numerical ones. The results, with column names, are stored in a list and printed, providing a summary of each numerical column‚Äôs statistics.\n\n# ƒ∞statistikleri hesaplayan fonksiyon\ncompute_stats &lt;- function(x) {\n  # Girdi sayƒ±sal mƒ± kontrol et\n  if (!is.numeric(x)) {\n    stop(\"Hata: Girdi sayƒ±sal bir vekt√∂r olmalƒ±dƒ±r.\")\n  }\n\n  # ƒ∞statistik hesaplamalarƒ±\n  mean_x &lt;- mean(x, na.rm = TRUE)\n  median_x &lt;- median(x, na.rm = TRUE)\n  var_x &lt;- var(x, na.rm = TRUE)\n  iqr_x &lt;- IQR(x, na.rm = TRUE)\n  min_x &lt;- min(x, na.rm = TRUE)\n  max_x &lt;- max(x, na.rm = TRUE)\n\n  # Sonu√ßlarƒ± i√ßeren listeyi d√∂nd√ºr\n  compute_stats_list &lt;- list(\n    mean = mean_x,\n    median = median_x,\n    variance = var_x,\n    IQR = iqr_x,\n    min = min_x,\n    maks = max_x\n  )\n\n  return(compute_stats_list)\n}\n\n# mtcars veri seti i√ßin t√ºm sayƒ±sal s√ºtunlarƒ±n istatistiklerini hesapla\nmtcars_istatistikleri &lt;- list() # Bo≈ü bir liste olu≈ütur\n\nfor (header in names(mtcars)) {\n  if (is.numeric(mtcars[[header]])) {\n    mtcars_istatistikleri[[header]] &lt;- compute_stats(mtcars[[header]]) # Sonu√ßlarƒ± listeye ekle\n  }\n}\n\n# Sonu√ßlarƒ± yazdƒ±r\nprint(mtcars_istatistikleri)\n\n$mpg\n$mpg$mean\n[1] 20.09062\n\n$mpg$median\n[1] 19.2\n\n$mpg$variance\n[1] 36.3241\n\n$mpg$IQR\n[1] 7.375\n\n$mpg$min\n[1] 10.4\n\n$mpg$maks\n[1] 33.9\n\n\n$cyl\n$cyl$mean\n[1] 6.1875\n\n$cyl$median\n[1] 6\n\n$cyl$variance\n[1] 3.189516\n\n$cyl$IQR\n[1] 4\n\n$cyl$min\n[1] 4\n\n$cyl$maks\n[1] 8\n\n\n$disp\n$disp$mean\n[1] 230.7219\n\n$disp$median\n[1] 196.3\n\n$disp$variance\n[1] 15360.8\n\n$disp$IQR\n[1] 205.175\n\n$disp$min\n[1] 71.1\n\n$disp$maks\n[1] 472\n\n\n$hp\n$hp$mean\n[1] 146.6875\n\n$hp$median\n[1] 123\n\n$hp$variance\n[1] 4700.867\n\n$hp$IQR\n[1] 83.5\n\n$hp$min\n[1] 52\n\n$hp$maks\n[1] 335\n\n\n$drat\n$drat$mean\n[1] 3.596563\n\n$drat$median\n[1] 3.695\n\n$drat$variance\n[1] 0.2858814\n\n$drat$IQR\n[1] 0.84\n\n$drat$min\n[1] 2.76\n\n$drat$maks\n[1] 4.93\n\n\n$wt\n$wt$mean\n[1] 3.21725\n\n$wt$median\n[1] 3.325\n\n$wt$variance\n[1] 0.957379\n\n$wt$IQR\n[1] 1.02875\n\n$wt$min\n[1] 1.513\n\n$wt$maks\n[1] 5.424\n\n\n$qsec\n$qsec$mean\n[1] 17.84875\n\n$qsec$median\n[1] 17.71\n\n$qsec$variance\n[1] 3.193166\n\n$qsec$IQR\n[1] 2.0075\n\n$qsec$min\n[1] 14.5\n\n$qsec$maks\n[1] 22.9\n\n\n$vs\n$vs$mean\n[1] 0.4375\n\n$vs$median\n[1] 0\n\n$vs$variance\n[1] 0.2540323\n\n$vs$IQR\n[1] 1\n\n$vs$min\n[1] 0\n\n$vs$maks\n[1] 1\n\n\n$am\n$am$mean\n[1] 0.40625\n\n$am$median\n[1] 0\n\n$am$variance\n[1] 0.2489919\n\n$am$IQR\n[1] 1\n\n$am$min\n[1] 0\n\n$am$maks\n[1] 1\n\n\n$gear\n$gear$mean\n[1] 3.6875\n\n$gear$median\n[1] 4\n\n$gear$variance\n[1] 0.5443548\n\n$gear$IQR\n[1] 1\n\n$gear$min\n[1] 3\n\n$gear$maks\n[1] 5\n\n\n$carb\n$carb$mean\n[1] 2.8125\n\n$carb$median\n[1] 2\n\n$carb$variance\n[1] 2.608871\n\n$carb$IQR\n[1] 2\n\n$carb$min\n[1] 1\n\n$carb$maks\n[1] 8\n\n\nTo automate statistical analysis of numerical columns within the mtcars dataset, a for loop iterates through each column name. Utilizing is.numeric(), the loop identifies numerical columns and applies the compute_stats function. This function calculates key statistics like mean, median, and variance, returning them in a named list. The loop then stores these results, indexed by column names, within a comprehensive list, which is subsequently printed. This approach efficiently provides a structured statistical overview of all numerical columns in the dataset.\n\n\nAn alternative approach with sapply and apply\nThe sapply function in R is a user-friendly and efficient way to apply a function over a list or vector. In the context of the mtcars dataset, sapply iterates through each column, applying the compute_stats function to those that are numeric. This streamlines the process of calculating statistics for multiple columns, returning the results in a simplified format, such as a vector or matrix. Its ability to directly handle data frames makes it a powerful tool for quick statistical analysis.\n\n# sapply ile t√ºm s√ºtunlara compute_stats fonksiyonunu uygula\nmtcars_istatistikleri_sapply &lt;- sapply(mtcars, compute_stats)\n\n# Sonu√ßlarƒ± yazdƒ±r\nprint(mtcars_istatistikleri_sapply)\n\n         mpg      cyl      disp     hp       drat      wt       qsec    \nmean     20.09062 6.1875   230.7219 146.6875 3.596563  3.21725  17.84875\nmedian   19.2     6        196.3    123      3.695     3.325    17.71   \nvariance 36.3241  3.189516 15360.8  4700.867 0.2858814 0.957379 3.193166\nIQR      7.375    4        205.175  83.5     0.84      1.02875  2.0075  \nmin      10.4     4        71.1     52       2.76      1.513    14.5    \nmaks     33.9     8        472      335      4.93      5.424    22.9    \n         vs        am        gear      carb    \nmean     0.4375    0.40625   3.6875    2.8125  \nmedian   0         0         4         2       \nvariance 0.2540323 0.2489919 0.5443548 2.608871\nIQR      1         1         1         2       \nmin      0         0         3         1       \nmaks     1         1         5         8       \n\n\nThe apply function in R is designed to apply a function over the rows or columns of a matrix or array. In this scenario, the mtcars data frame is first converted to a matrix. Then, apply is used to iterate over the columns, applying the compute_stats function to each. This approach allows for consistent application of statistical calculations across all columns, returning the results in a structured format. While apply is versatile, it requires the data to be in a matrix format, making it slightly less direct for data frames compared to sapply.\n\n# apply ile t√ºm s√ºtunlara compute_stats fonksiyonunu uygula\nmtcars_istatistikleri_apply &lt;- apply(mtcars, MARGIN = 2, compute_stats)\n\n# Sonu√ßlarƒ± yazdƒ±r\nprint(mtcars_istatistikleri_apply)\n\n$mpg\n$mpg$mean\n[1] 20.09062\n\n$mpg$median\n[1] 19.2\n\n$mpg$variance\n[1] 36.3241\n\n$mpg$IQR\n[1] 7.375\n\n$mpg$min\n[1] 10.4\n\n$mpg$maks\n[1] 33.9\n\n\n$cyl\n$cyl$mean\n[1] 6.1875\n\n$cyl$median\n[1] 6\n\n$cyl$variance\n[1] 3.189516\n\n$cyl$IQR\n[1] 4\n\n$cyl$min\n[1] 4\n\n$cyl$maks\n[1] 8\n\n\n$disp\n$disp$mean\n[1] 230.7219\n\n$disp$median\n[1] 196.3\n\n$disp$variance\n[1] 15360.8\n\n$disp$IQR\n[1] 205.175\n\n$disp$min\n[1] 71.1\n\n$disp$maks\n[1] 472\n\n\n$hp\n$hp$mean\n[1] 146.6875\n\n$hp$median\n[1] 123\n\n$hp$variance\n[1] 4700.867\n\n$hp$IQR\n[1] 83.5\n\n$hp$min\n[1] 52\n\n$hp$maks\n[1] 335\n\n\n$drat\n$drat$mean\n[1] 3.596563\n\n$drat$median\n[1] 3.695\n\n$drat$variance\n[1] 0.2858814\n\n$drat$IQR\n[1] 0.84\n\n$drat$min\n[1] 2.76\n\n$drat$maks\n[1] 4.93\n\n\n$wt\n$wt$mean\n[1] 3.21725\n\n$wt$median\n[1] 3.325\n\n$wt$variance\n[1] 0.957379\n\n$wt$IQR\n[1] 1.02875\n\n$wt$min\n[1] 1.513\n\n$wt$maks\n[1] 5.424\n\n\n$qsec\n$qsec$mean\n[1] 17.84875\n\n$qsec$median\n[1] 17.71\n\n$qsec$variance\n[1] 3.193166\n\n$qsec$IQR\n[1] 2.0075\n\n$qsec$min\n[1] 14.5\n\n$qsec$maks\n[1] 22.9\n\n\n$vs\n$vs$mean\n[1] 0.4375\n\n$vs$median\n[1] 0\n\n$vs$variance\n[1] 0.2540323\n\n$vs$IQR\n[1] 1\n\n$vs$min\n[1] 0\n\n$vs$maks\n[1] 1\n\n\n$am\n$am$mean\n[1] 0.40625\n\n$am$median\n[1] 0\n\n$am$variance\n[1] 0.2489919\n\n$am$IQR\n[1] 1\n\n$am$min\n[1] 0\n\n$am$maks\n[1] 1\n\n\n$gear\n$gear$mean\n[1] 3.6875\n\n$gear$median\n[1] 4\n\n$gear$variance\n[1] 0.5443548\n\n$gear$IQR\n[1] 1\n\n$gear$min\n[1] 3\n\n$gear$maks\n[1] 5\n\n\n$carb\n$carb$mean\n[1] 2.8125\n\n$carb$median\n[1] 2\n\n$carb$variance\n[1] 2.608871\n\n$carb$IQR\n[1] 2\n\n$carb$min\n[1] 1\n\n$carb$maks\n[1] 8",
    "crumbs": [
      "MTCars Statistics"
    ]
  },
  {
    "objectID": "assignments/statisticsofmrcars.html#handling-missing-values-in-the-dslabs-na_example-dataset-methods-and-comparisons",
    "href": "assignments/statisticsofmrcars.html#handling-missing-values-in-the-dslabs-na_example-dataset-methods-and-comparisons",
    "title": "Mtcars Statistical Analysis",
    "section": "Handling Missing Values in the dslabs ‚Äòna_example‚Äô Dataset: Methods and Comparisons",
    "text": "Handling Missing Values in the dslabs ‚Äòna_example‚Äô Dataset: Methods and Comparisons\n\nInstalling and Loading the ‚Äòdslaps‚Äô\n\n#install.packages(\"dslabs\")\nlibrary(dslabs)\n\nWarning: package 'dslabs' was built under R version 4.4.3\n\n\nAfter successfully installing and loading the ‚Äòdslabs‚Äô library, we can now print the desired dataset.\n\nprint(na_example)\n\n   [1]  2  1  3  2  1  3  1  4  3  2  2 NA  2  2  1  4 NA  1  1  2  1  2  2  1\n  [25]  2  5 NA  2  2  3  1  2  4  1  1  1  4  5  2  3  4  1  2  4  1  1  2  1\n  [49]  5 NA NA NA  1  1  5  1  3  1 NA  4  4  7  3  2 NA NA  1 NA  4  1  2  2\n  [73]  3  2  1  2  2  4  3  4  2  3  1  3  2  1  1  1  3  1 NA  3  1  2  2  1\n  [97]  2  2  1  1  4  1  1  2  3  3  2  2  3  3  3  4  1  1  1  2 NA  4  3  4\n [121]  3  1  2  1 NA NA NA NA  1  5  1  2  1  3  5  3  2  2 NA NA NA NA  3  5\n [145]  3  1  1  4  2  4  3  3 NA  2  3  2  6 NA  1  1  2  2  1  3  1  1  5 NA\n [169] NA  2  4 NA  2  5  1  4  3  3 NA  4  3  1  4  1  1  3  1  1 NA NA  3  5\n [193]  2  2  2  3  1  2  2  3  2  1 NA  2 NA  1 NA NA  2  1  1 NA  3 NA  1  2\n [217]  2  1  3  2  2  1  1  2  3  1  1  1  4  3  4  2  2  1  4  1 NA  5  1  4\n [241] NA  3 NA NA  1  1  5  2  3  3  2  4 NA  3  2  5 NA  2  3  4  6  2  2  2\n [265] NA  2 NA  2 NA  3  3  2  2  4  3  1  4  2 NA  2  4 NA  6  2  3  1 NA  2\n [289]  2 NA  1  1  3  2  3  3  1 NA  1  4  2  1  1  3  2  1  2  3  1 NA  2  3\n [313]  3  2  1  2  3  5  5  1  2  3  3  1 NA NA  1  2  4 NA  2  1  1  1  3  2\n [337]  1  1  3  4 NA  1  2  1  1  3  3 NA  1  1  3  5  3  2  3  4  1  4  3  1\n [361] NA  2  1  2  2  1  2  2  6  1  2  4  5 NA  3  4  2  1  1  4  2  1  1  1\n [385]  1  2  1  4  4  1  3 NA  3  3 NA  2 NA  1  2  1  1  4  2  1  4  4 NA  1\n [409]  2 NA  3  2  2  2  1  4  3  6  1  2  3  1  3  2  2  2  1  1  3  2  1  1\n [433]  1  3  2  2 NA  4  4  4  1  1 NA  4  3 NA  1  3  1  3  2  4  2  2  2  3\n [457]  2  1  4  3 NA  1  4  3  1  3  2 NA  3 NA  1  3  1  4  1  1  1  2  4  3\n [481]  1  2  2  2  3  2  3  1  1 NA  3  2  1  1  2 NA  2  2  2  3  3  1  1  2\n [505] NA  1  2  1  1  3  3  1  3  1  1  1  1  1  2  5  1  1  2  2  1  1 NA  1\n [529]  4  1  2  4  1  3  2 NA  1  1 NA  2  1  1  4  2  3  3  1  5  3  1  1  2\n [553] NA  1  1  3  1  3  2  4 NA  2  3  2  1  2  1  1  1  2  2  3  1  5  2 NA\n [577]  2 NA  3  2  2  2  1  5  3  2  3  1 NA  3  1  2  2  2  1  2  2  4 NA  6\n [601]  1  2 NA  1  1  2  2  3 NA  3  2  3  3  4  2 NA  2 NA  4 NA  1  1  2  2\n [625]  3  1  1  1  3 NA  2  5 NA  7  1 NA  4  3  3  1 NA  1  1  1  1  3  2  4\n [649]  2  2  3 NA NA  1  4  3  2  2  2  3  2  4  2  2  4 NA NA NA  6  3  3  1\n [673]  4  4  2  1 NA  1  6 NA  3  3  2  1  1  6 NA  1  5  1 NA  2  6  2 NA  4\n [697]  1  3  1  2 NA  1  1  3  1  2  4  2  1  3  2  4  3  2  2  1  1  5  6  4\n [721]  2  2  2  2  4 NA  1  2  2  2  2  4  5 NA NA NA  4  3  3  3  2  4  2  4\n [745] NA NA NA NA  2  1 NA  2  4  3  2 NA  2  3  1  3  4 NA  1  2  1  2 NA  3\n [769]  1  2  1  2  1  2  1  2  2  2  2  1  1  3  3  1  3  4  3 NA NA  4  2  3\n [793]  2  1  3  2  4  2  2  3  1  2  4  3  3  4 NA  1  4  2  1  1  1  3  1  5\n [817]  2  2  4  2 NA  1  3  1  2 NA  1  2  1  2  1 NA  1  3  2  3  2 NA  2  1\n [841]  4  2 NA NA NA  2  4  2 NA NA  3  1 NA  5  5  2  2  2 NA  2  1  3  1  3\n [865]  2  4  2  4 NA  4  1  2  3  2  3  3  2  3  2  2  2  1  3  2  4  2 NA  3\n [889]  3  2  2 NA NA  3  2  1  2  4  1  1  1  1  4  3  2 NA  3  2 NA  1 NA  3\n [913]  2  1  1  1  2 NA  2  2  3  3  2 NA NA  4  5  2  2  2  1  2  3  1  3  3\n [937]  4  3 NA  1  1  1 NA  4  3  5  1  1  2 NA  2  2  2  2  5  2  2  3  1  2\n [961]  3 NA  1  2 NA NA  2 NA  3  1  1  2  5  3  5  1  1  4 NA  2  1  3  1  1\n [985]  2  4  3  3  3 NA  1  1  2  2  1  1  2  2 NA  2\n\n\n\n\nNumber and Locations of NA Values\nThis R code calculates the missing values (NA) within the ‚Äòna_example‚Äô dataset. Initially, we determined the total count of NA values present and identified their index positions within the dataset.\n\ntotal_na &lt;- sum(is.na(na_example))\ncat(\"Total NA values:\", total_na)\n\nTotal NA values: 145\n\n\n\nwhich(is.na(na_example))\n\n  [1]  12  17  27  50  51  52  59  65  66  68  91 117 125 126 127 128 139 140\n [19] 141 142 153 158 168 169 172 179 189 190 203 205 207 208 212 214 237 241\n [37] 243 244 253 257 265 267 269 279 282 287 290 298 310 325 326 330 341 348\n [55] 361 374 392 395 397 407 410 437 443 446 461 468 470 490 496 505 527 536\n [73] 539 553 561 576 578 589 599 603 609 616 618 620 630 633 636 641 652 653\n [91] 666 667 668 677 680 687 691 695 701 726 734 735 736 745 746 747 748 751\n[109] 756 762 767 788 789 807 821 826 832 838 843 844 845 849 850 853 859 869\n[127] 887 892 893 906 909 911 918 924 925 939 943 950 962 965 966 968 979 990\n[145] 999\n\n\n\n\nStatistical Calculation Ignoring NA Values\n\n# NA deƒüerleri g√∂z ardƒ± ederek ortalama ve standart sapma hesapla\nmean_value &lt;- mean(na_example, na.rm = TRUE)\nsd_value &lt;- sd(na_example, na.rm = TRUE)\n\n# Sonu√ßlarƒ± ekrana yazdƒ±r\ncat(\"Mean:\", mean_value, \"\\n\")\n\nMean: 2.301754 \n\ncat(\"Standart Deviation:\", sd_value)\n\nStandart Deviation: 1.22338\n\n\n\n\nReplacing NA Values with the Median\nIn this process, we replace all missing (NA) values in the na_example dataset with the median of the non-missing values. The median is chosen because it is less sensitive to extreme values (outliers) compared to the mean.\n\n# NA olmayan deƒüerlerin medyanƒ±nƒ± hesapla\nmedian_others &lt;- median(na_example, na.rm = TRUE)\n\n# NA deƒüerleri medyan ile deƒüi≈ütir\nna_example_median &lt;- ifelse(is.na(na_example), median_others, na_example)\n\n# Sonucu yazdƒ±r\ncat(\"Medyan:\", median_others, \"\\n\")\n\nMedyan: 2 \n\nprint(na_example_median)\n\n   [1] 2 1 3 2 1 3 1 4 3 2 2 2 2 2 1 4 2 1 1 2 1 2 2 1 2 5 2 2 2 3 1 2 4 1 1 1 4\n  [38] 5 2 3 4 1 2 4 1 1 2 1 5 2 2 2 1 1 5 1 3 1 2 4 4 7 3 2 2 2 1 2 4 1 2 2 3 2\n  [75] 1 2 2 4 3 4 2 3 1 3 2 1 1 1 3 1 2 3 1 2 2 1 2 2 1 1 4 1 1 2 3 3 2 2 3 3 3\n [112] 4 1 1 1 2 2 4 3 4 3 1 2 1 2 2 2 2 1 5 1 2 1 3 5 3 2 2 2 2 2 2 3 5 3 1 1 4\n [149] 2 4 3 3 2 2 3 2 6 2 1 1 2 2 1 3 1 1 5 2 2 2 4 2 2 5 1 4 3 3 2 4 3 1 4 1 1\n [186] 3 1 1 2 2 3 5 2 2 2 3 1 2 2 3 2 1 2 2 2 1 2 2 2 1 1 2 3 2 1 2 2 1 3 2 2 1\n [223] 1 2 3 1 1 1 4 3 4 2 2 1 4 1 2 5 1 4 2 3 2 2 1 1 5 2 3 3 2 4 2 3 2 5 2 2 3\n [260] 4 6 2 2 2 2 2 2 2 2 3 3 2 2 4 3 1 4 2 2 2 4 2 6 2 3 1 2 2 2 2 1 1 3 2 3 3\n [297] 1 2 1 4 2 1 1 3 2 1 2 3 1 2 2 3 3 2 1 2 3 5 5 1 2 3 3 1 2 2 1 2 4 2 2 1 1\n [334] 1 3 2 1 1 3 4 2 1 2 1 1 3 3 2 1 1 3 5 3 2 3 4 1 4 3 1 2 2 1 2 2 1 2 2 6 1\n [371] 2 4 5 2 3 4 2 1 1 4 2 1 1 1 1 2 1 4 4 1 3 2 3 3 2 2 2 1 2 1 1 4 2 1 4 4 2\n [408] 1 2 2 3 2 2 2 1 4 3 6 1 2 3 1 3 2 2 2 1 1 3 2 1 1 1 3 2 2 2 4 4 4 1 1 2 4\n [445] 3 2 1 3 1 3 2 4 2 2 2 3 2 1 4 3 2 1 4 3 1 3 2 2 3 2 1 3 1 4 1 1 1 2 4 3 1\n [482] 2 2 2 3 2 3 1 1 2 3 2 1 1 2 2 2 2 2 3 3 1 1 2 2 1 2 1 1 3 3 1 3 1 1 1 1 1\n [519] 2 5 1 1 2 2 1 1 2 1 4 1 2 4 1 3 2 2 1 1 2 2 1 1 4 2 3 3 1 5 3 1 1 2 2 1 1\n [556] 3 1 3 2 4 2 2 3 2 1 2 1 1 1 2 2 3 1 5 2 2 2 2 3 2 2 2 1 5 3 2 3 1 2 3 1 2\n [593] 2 2 1 2 2 4 2 6 1 2 2 1 1 2 2 3 2 3 2 3 3 4 2 2 2 2 4 2 1 1 2 2 3 1 1 1 3\n [630] 2 2 5 2 7 1 2 4 3 3 1 2 1 1 1 1 3 2 4 2 2 3 2 2 1 4 3 2 2 2 3 2 4 2 2 4 2\n [667] 2 2 6 3 3 1 4 4 2 1 2 1 6 2 3 3 2 1 1 6 2 1 5 1 2 2 6 2 2 4 1 3 1 2 2 1 1\n [704] 3 1 2 4 2 1 3 2 4 3 2 2 1 1 5 6 4 2 2 2 2 4 2 1 2 2 2 2 4 5 2 2 2 4 3 3 3\n [741] 2 4 2 4 2 2 2 2 2 1 2 2 4 3 2 2 2 3 1 3 4 2 1 2 1 2 2 3 1 2 1 2 1 2 1 2 2\n [778] 2 2 1 1 3 3 1 3 4 3 2 2 4 2 3 2 1 3 2 4 2 2 3 1 2 4 3 3 4 2 1 4 2 1 1 1 3\n [815] 1 5 2 2 4 2 2 1 3 1 2 2 1 2 1 2 1 2 1 3 2 3 2 2 2 1 4 2 2 2 2 2 4 2 2 2 3\n [852] 1 2 5 5 2 2 2 2 2 1 3 1 3 2 4 2 4 2 4 1 2 3 2 3 3 2 3 2 2 2 1 3 2 4 2 2 3\n [889] 3 2 2 2 2 3 2 1 2 4 1 1 1 1 4 3 2 2 3 2 2 1 2 3 2 1 1 1 2 2 2 2 3 3 2 2 2\n [926] 4 5 2 2 2 1 2 3 1 3 3 4 3 2 1 1 1 2 4 3 5 1 1 2 2 2 2 2 2 5 2 2 3 1 2 3 2\n [963] 1 2 2 2 2 2 3 1 1 2 5 3 5 1 1 4 2 2 1 3 1 1 2 4 3 3 3 2 1 1 2 2 1 1 2 2 2\n[1000] 2\n\n\n\nversion1_median &lt;- median(na_example_median)\nversion1_sd &lt;- sd(na_example_median)\n\n# Sonu√ßlarƒ± yazdƒ±r\ncat(\"Versiyon 1 Medyan:\", version1_median, \"\\n\")\n\nVersiyon 1 Medyan: 2 \n\ncat(\"Versiyon 1 Sapma:\", version1_sd)\n\nVersiyon 1 Sapma: 1.136102\n\n\n\n\nReplacing NA Values with Randomly Selected Non-missing Value\nThis process replaces all NA values in the dataset with a randomly selected non-missing value from the same dataset. First, we extract all non-missing values, then for each NA, a random value from the non-missing values is chosen to fill in the missing spot.\n\n# NA olmayan deƒüerleri al\nnon_na_values &lt;- na_example[!is.na(na_example)]\n\n# NA deƒüerlerini rastgele bir NA olmayan deƒüerle deƒüi≈ütir\nna_example_random &lt;- ifelse(is.na(na_example), sample(non_na_values, 1), na_example)\n\n# Sonu√ßlarƒ± yazdƒ±r\nprint(na_example_random)\n\n   [1] 2 1 3 2 1 3 1 4 3 2 2 3 2 2 1 4 3 1 1 2 1 2 2 1 2 5 3 2 2 3 1 2 4 1 1 1 4\n  [38] 5 2 3 4 1 2 4 1 1 2 1 5 3 3 3 1 1 5 1 3 1 3 4 4 7 3 2 3 3 1 3 4 1 2 2 3 2\n  [75] 1 2 2 4 3 4 2 3 1 3 2 1 1 1 3 1 3 3 1 2 2 1 2 2 1 1 4 1 1 2 3 3 2 2 3 3 3\n [112] 4 1 1 1 2 3 4 3 4 3 1 2 1 3 3 3 3 1 5 1 2 1 3 5 3 2 2 3 3 3 3 3 5 3 1 1 4\n [149] 2 4 3 3 3 2 3 2 6 3 1 1 2 2 1 3 1 1 5 3 3 2 4 3 2 5 1 4 3 3 3 4 3 1 4 1 1\n [186] 3 1 1 3 3 3 5 2 2 2 3 1 2 2 3 2 1 3 2 3 1 3 3 2 1 1 3 3 3 1 2 2 1 3 2 2 1\n [223] 1 2 3 1 1 1 4 3 4 2 2 1 4 1 3 5 1 4 3 3 3 3 1 1 5 2 3 3 2 4 3 3 2 5 3 2 3\n [260] 4 6 2 2 2 3 2 3 2 3 3 3 2 2 4 3 1 4 2 3 2 4 3 6 2 3 1 3 2 2 3 1 1 3 2 3 3\n [297] 1 3 1 4 2 1 1 3 2 1 2 3 1 3 2 3 3 2 1 2 3 5 5 1 2 3 3 1 3 3 1 2 4 3 2 1 1\n [334] 1 3 2 1 1 3 4 3 1 2 1 1 3 3 3 1 1 3 5 3 2 3 4 1 4 3 1 3 2 1 2 2 1 2 2 6 1\n [371] 2 4 5 3 3 4 2 1 1 4 2 1 1 1 1 2 1 4 4 1 3 3 3 3 3 2 3 1 2 1 1 4 2 1 4 4 3\n [408] 1 2 3 3 2 2 2 1 4 3 6 1 2 3 1 3 2 2 2 1 1 3 2 1 1 1 3 2 2 3 4 4 4 1 1 3 4\n [445] 3 3 1 3 1 3 2 4 2 2 2 3 2 1 4 3 3 1 4 3 1 3 2 3 3 3 1 3 1 4 1 1 1 2 4 3 1\n [482] 2 2 2 3 2 3 1 1 3 3 2 1 1 2 3 2 2 2 3 3 1 1 2 3 1 2 1 1 3 3 1 3 1 1 1 1 1\n [519] 2 5 1 1 2 2 1 1 3 1 4 1 2 4 1 3 2 3 1 1 3 2 1 1 4 2 3 3 1 5 3 1 1 2 3 1 1\n [556] 3 1 3 2 4 3 2 3 2 1 2 1 1 1 2 2 3 1 5 2 3 2 3 3 2 2 2 1 5 3 2 3 1 3 3 1 2\n [593] 2 2 1 2 2 4 3 6 1 2 3 1 1 2 2 3 3 3 2 3 3 4 2 3 2 3 4 3 1 1 2 2 3 1 1 1 3\n [630] 3 2 5 3 7 1 3 4 3 3 1 3 1 1 1 1 3 2 4 2 2 3 3 3 1 4 3 2 2 2 3 2 4 2 2 4 3\n [667] 3 3 6 3 3 1 4 4 2 1 3 1 6 3 3 3 2 1 1 6 3 1 5 1 3 2 6 2 3 4 1 3 1 2 3 1 1\n [704] 3 1 2 4 2 1 3 2 4 3 2 2 1 1 5 6 4 2 2 2 2 4 3 1 2 2 2 2 4 5 3 3 3 4 3 3 3\n [741] 2 4 2 4 3 3 3 3 2 1 3 2 4 3 2 3 2 3 1 3 4 3 1 2 1 2 3 3 1 2 1 2 1 2 1 2 2\n [778] 2 2 1 1 3 3 1 3 4 3 3 3 4 2 3 2 1 3 2 4 2 2 3 1 2 4 3 3 4 3 1 4 2 1 1 1 3\n [815] 1 5 2 2 4 2 3 1 3 1 2 3 1 2 1 2 1 3 1 3 2 3 2 3 2 1 4 2 3 3 3 2 4 2 3 3 3\n [852] 1 3 5 5 2 2 2 3 2 1 3 1 3 2 4 2 4 3 4 1 2 3 2 3 3 2 3 2 2 2 1 3 2 4 2 3 3\n [889] 3 2 2 3 3 3 2 1 2 4 1 1 1 1 4 3 2 3 3 2 3 1 3 3 2 1 1 1 2 3 2 2 3 3 2 3 3\n [926] 4 5 2 2 2 1 2 3 1 3 3 4 3 3 1 1 1 3 4 3 5 1 1 2 3 2 2 2 2 5 2 2 3 1 2 3 3\n [963] 1 2 3 3 2 3 3 1 1 2 5 3 5 1 1 4 3 2 1 3 1 1 2 4 3 3 3 3 1 1 2 2 1 1 2 2 3\n[1000] 2\n\n\n\nversion2_median &lt;- median(na_example_random)\nversion2_sd &lt;- sd(na_example_random)\n\n# Sonu√ßlarƒ± yazdƒ±r\ncat(\"Versiyon 2 Medyan:\", version2_median, \"\\n\")\n\nVersiyon 2 Medyan: 2 \n\ncat(\"Versiyon 2 Sapma:\", version2_sd)\n\nVersiyon 2 Sapma: 1.157554\n\n\n\nlibrary(knitr)  # kable fonksiyonu i√ßin\n\nWarning: package 'knitr' was built under R version 4.4.3\n\n\n\n# Bu kod bloƒüu tamamen AI tarafƒ±ndan yazƒ±lmƒ±stƒ±r.\n# Sonu√ßlarƒ± birle≈ütirip tabloyu olu≈ütur\n\nstatistics_table &lt;- data.frame(\n  Method = c(\"Original (Mean)\", \"Original (SD)\", \n             \"Imputed (Median, Mean)\", \"Imputed (Median, SD)\", \n             \"Imputed (Random, Mean)\", \"Imputed (Random, SD)\"),\n  Value = c(mean_value, sd_value,\n            mean(na_example_median), sd(na_example_median),\n            mean(na_example_random), sd(na_example_random))\n)\n\n# Tabloyu yazdƒ±r\nkable(statistics_table, caption = \"Comparison of Statistics Before and After Handling NA Values\")\n\n\nComparison of Statistics Before and After Handling NA Values\n\n\nMethod\nValue\n\n\n\n\nOriginal (Mean)\n2.301754\n\n\nOriginal (SD)\n1.223380\n\n\nImputed (Median, Mean)\n2.258000\n\n\nImputed (Median, SD)\n1.136102\n\n\nImputed (Random, Mean)\n2.403000\n\n\nImputed (Random, SD)\n1.157554\n\n\n\n\n\nRegarding the data, imputing with the median seems more appropriate as it preserves the central tendency without being affected by outliers. Imputing with random values could better reflect the distribution of the data, but it may introduce some variability. Looking at the original data, if the number of missing values is minimal, ignoring them could be acceptable. However, if the missing values are not random, it could introduce bias in the data.",
    "crumbs": [
      "MTCars Statistics"
    ]
  },
  {
    "objectID": "assignments/datascience.html",
    "href": "assignments/datascience.html",
    "title": "On Data Science and Industrial Engineering",
    "section": "",
    "text": "Below, you will find a brief summary of the discussion video on data analytics and industrial engineering, available at the following link:\nWatch the video here",
    "crumbs": [
      "On Data Science and Industrial Engineering"
    ]
  },
  {
    "objectID": "assignments/datascience.html#the-role-of-data-science-and-its-applications-insights-from-kerem-demirta≈ü",
    "href": "assignments/datascience.html#the-role-of-data-science-and-its-applications-insights-from-kerem-demirta≈ü",
    "title": "On Data Science and Industrial Engineering",
    "section": "The Role of Data Science and Its Applications: Insights from Kerem Demirta≈ü",
    "text": "The Role of Data Science and Its Applications: Insights from Kerem Demirta≈ü\nKerem Demirta≈ü is a Data Scientist currently working at Invent Analytics. Previously, he worked at Spyke Games and Smart Kiwi. One of his significant projects was Royal Reachers, where he focused on analyzing users‚Äô gaming behaviors and demographic structures to deliver the most suitable offers at the most optimal times, thereby maximizing sales. Later in his career, he contributed to a project aimed at optimizing inventory management in retail. This involved developing software that determines how much stock should be held at various locations and for which models, ultimately helping businesses maximize their sales.\nHis research interests revolve around autonomous vehicles, traffic flow modeling, transportation simulations, and optimization techniques in mobility systems.",
    "crumbs": [
      "On Data Science and Industrial Engineering"
    ]
  },
  {
    "objectID": "assignments/datascience.html#the-scope-of-data-science",
    "href": "assignments/datascience.html#the-scope-of-data-science",
    "title": "On Data Science and Industrial Engineering",
    "section": "The Scope of Data Science",
    "text": "The Scope of Data Science\nData science finds applications in various fields, including:\n\nEpidemiology: Predicting the likelihood of disease outbreaks, identifying high-risk regions, and implementing preventive measures.\nRetail: Optimizing stock levels and sales strategies to enhance profitability.\nAutonomous Vehicles: Improving traffic efficiency, reducing congestion, and enhancing the decision-making capabilities of self-driving cars.",
    "crumbs": [
      "On Data Science and Industrial Engineering"
    ]
  },
  {
    "objectID": "assignments/datascience.html#what-data-science-is-not",
    "href": "assignments/datascience.html#what-data-science-is-not",
    "title": "On Data Science and Industrial Engineering",
    "section": "What Data Science is NOT",
    "text": "What Data Science is NOT\n\nIt is not merely an exaggerated form of statistics.\nIt is not just about building models.\nIt is not exclusively tied to Big Data.\nWriting Python code does not make someone a data analyst.\nData analysis does not always provide definitive answers to every question.",
    "crumbs": [
      "On Data Science and Industrial Engineering"
    ]
  },
  {
    "objectID": "assignments/datascience.html#the-data-science-workflow",
    "href": "assignments/datascience.html#the-data-science-workflow",
    "title": "On Data Science and Industrial Engineering",
    "section": "The Data Science Workflow",
    "text": "The Data Science Workflow\n\nProblem Identification: Clearly defining the problem is the first step in data science. A historical example of this is the analysis conducted during World War II on aircraft durability. Engineers initially focused on reinforcing the most frequently damaged parts of returning planes, but statistician Abraham Wald proposed a different approach‚Äîsuggesting that undamaged areas of returning planes were actually where the planes that were shot down had suffered critical damage. This shift in thinking led to more effective reinforcement strategies.\nData Collection: Gathering unbiased data is crucial. Abraham Wald‚Äôs unbiased thinking methodology is a key example. His research showed that survivorship bias can mislead analyses if data from unsuccessful cases (e.g., planes that didn‚Äôt return) is not considered.\nExploratory Data Analysis (EDA): Before building models, it is essential to understand and visualize the data. A classic example is John Snow‚Äôs study on cholera outbreaks in 1854 London. By mapping out cases and identifying contaminated water sources, he demonstrated that cholera was waterborne‚Äîlong before germ theory was widely accepted. This showcases how data visualization and pattern recognition can lead to groundbreaking discoveries.\nModel Building: At this stage, predictive and analytical models are developed. A relevant example is Lewis Fry Richardson‚Äôs pioneering work on weather forecasting, where he proposed numerical methods for predicting atmospheric conditions. Another example is the World War II Diet Problem, which used linear programming to optimize military rations by balancing nutrition and cost.\nModel Evaluation: Assessing model performance and avoiding overfitting are crucial aspects of data science. Overfitting occurs when a model learns noise instead of actual patterns, reducing its real-world applicability. An illustrative case is the Deep Blue vs.¬†Garry Kasparov chess match, where the AI was trained to analyze millions of moves but had to generalize its strategies to defeat a world champion.\nProduction and Live Performance: Once a model is finalized, it must be deployed in a real-world setting. This step involves monitoring AI tools and ensuring their effectiveness. Examples include AI-driven recommendation systems in e-commerce, self-learning fraud detection systems in banking, and real-time traffic prediction tools in transportation networks.",
    "crumbs": [
      "On Data Science and Industrial Engineering"
    ]
  },
  {
    "objectID": "assignments/datascience.html#kerem-demirta≈üs-research-on-autonomous-vehicles",
    "href": "assignments/datascience.html#kerem-demirta≈üs-research-on-autonomous-vehicles",
    "title": "On Data Science and Industrial Engineering",
    "section": "Kerem Demirta≈ü‚Äôs Research on Autonomous Vehicles",
    "text": "Kerem Demirta≈ü‚Äôs Research on Autonomous Vehicles\nHis thesis, ‚ÄúObject-driven Cellular Automaton Model for Platooning of Autonomous Vehicles on Freeways with Multiple Lanes‚Äù, explores how autonomous vehicles can form convoys and adapt to complex road conditions. The primary motivation behind his research is to minimize the following distance between vehicles, optimize acceleration and deceleration during lane changes, and reduce the impact of stop-and-go waves in traffic flow. By refining the mechanics of platooning, his work contributes to the development of more efficient and safer autonomous driving systems.\nUltimately, his work highlights the power of data science in solving complex real-world problems, from optimizing business operations to transforming the future of mobility.",
    "crumbs": [
      "On Data Science and Industrial Engineering"
    ]
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About Me",
    "section": "",
    "text": "As an industrial engineer with a passion for data analysis, broadcasting, and artificial intelligence, I have built my career on exploring innovative solutions in these fields. After graduating from TOBB University, I began working as a data analyst in the broadcasting sector, specifically at TRT1, where I focused on broadcast planning and data analysis.\nCurrently, I am pursuing a master‚Äôs degree in industrial engineering while developing projects that integrate AI and innovation into the broadcasting industry. I also share insights on industry trends through blog writing and continuously work on enhancing my professional expertise."
  },
  {
    "objectID": "about.html#education",
    "href": "about.html#education",
    "title": "About Me",
    "section": "Education",
    "text": "Education\n\nM.S, Industrial Engineering, Hacettepe University, Turkey\n2025 - ongoing \n\n\n\nM.S, Business Administration, Hacettepe University, Turkey\n\n2022 - 2023 \n\n\n\n\nB.S, Industrial Engineering, TOBB University of Economics and Technology, Turkey\n\n2015 - 2020"
  },
  {
    "objectID": "about.html#work-experience",
    "href": "about.html#work-experience",
    "title": "About Me",
    "section": "Work Experience",
    "text": "Work Experience\n\nTRT, Planning Specialist, Turkey \n\nDec 2021 - ongoing\nBroadcast Planning & Performance Analysis: Managing and monitoring TV broadcasts, analyzing rating performance, and optimizing scheduling and discount strategies.\nData-Driven Decision Making: Conducting data analysis, preparing reports, and ensuring effective team coordination for strategic planning.\n\nLC WAIKIKI , International Store Merchandiser, Turkey \n\nJan 2021 - Dec 2021\nManaging international store stocks, analyzing performance metrics, and optimizing shipping strategies based on regional clothing preferences.\nDeveloping and implementing discount strategies to enhance sales.\n\nTURK PATENT VE MARKA KURUMU, Intern, Turkey \n\nDec 2019 - Sep 2019\n\nMAN TURKIYE, Quality Control Engineer Intern, Turkey \n\nJan 2019 - Apr 2019\n\nERSA OFIS MOBILYALARI , IT Intern, Turkey \n\nAug 2018- May 2019"
  },
  {
    "objectID": "about.html#competencies",
    "href": "about.html#competencies",
    "title": "About Me",
    "section": "Competencies",
    "text": "Competencies\n\nMathematical Modelling\nMS Office\nR\nCPLEX\nMySQL\nMS Office"
  },
  {
    "objectID": "about.html#hobbies",
    "href": "about.html#hobbies",
    "title": "About Me",
    "section": "Hobbies",
    "text": "Hobbies\n\nPainting & Crafts üé®üñåÔ∏è\nCinema & Theatre üé¨üé≠\nTraveling & Exploring New Places ‚úàÔ∏èüåç\nPhotography üì∏\nCooking üç≥\n\n[Learn More -&gt;] Download CV"
  },
  {
    "objectID": "assignments/handlingna.html",
    "href": "assignments/handlingna.html",
    "title": "NA_Example",
    "section": "",
    "text": "#install.packages(\"dslabs\")\nlibrary(dslabs)\n\nWarning: package 'dslabs' was built under R version 4.4.3\n\n\nAfter successfully installing and loading the ‚Äòdslabs‚Äô library, we can now print the desired dataset.\n\nprint(na_example)\n\n   [1]  2  1  3  2  1  3  1  4  3  2  2 NA  2  2  1  4 NA  1  1  2  1  2  2  1\n  [25]  2  5 NA  2  2  3  1  2  4  1  1  1  4  5  2  3  4  1  2  4  1  1  2  1\n  [49]  5 NA NA NA  1  1  5  1  3  1 NA  4  4  7  3  2 NA NA  1 NA  4  1  2  2\n  [73]  3  2  1  2  2  4  3  4  2  3  1  3  2  1  1  1  3  1 NA  3  1  2  2  1\n  [97]  2  2  1  1  4  1  1  2  3  3  2  2  3  3  3  4  1  1  1  2 NA  4  3  4\n [121]  3  1  2  1 NA NA NA NA  1  5  1  2  1  3  5  3  2  2 NA NA NA NA  3  5\n [145]  3  1  1  4  2  4  3  3 NA  2  3  2  6 NA  1  1  2  2  1  3  1  1  5 NA\n [169] NA  2  4 NA  2  5  1  4  3  3 NA  4  3  1  4  1  1  3  1  1 NA NA  3  5\n [193]  2  2  2  3  1  2  2  3  2  1 NA  2 NA  1 NA NA  2  1  1 NA  3 NA  1  2\n [217]  2  1  3  2  2  1  1  2  3  1  1  1  4  3  4  2  2  1  4  1 NA  5  1  4\n [241] NA  3 NA NA  1  1  5  2  3  3  2  4 NA  3  2  5 NA  2  3  4  6  2  2  2\n [265] NA  2 NA  2 NA  3  3  2  2  4  3  1  4  2 NA  2  4 NA  6  2  3  1 NA  2\n [289]  2 NA  1  1  3  2  3  3  1 NA  1  4  2  1  1  3  2  1  2  3  1 NA  2  3\n [313]  3  2  1  2  3  5  5  1  2  3  3  1 NA NA  1  2  4 NA  2  1  1  1  3  2\n [337]  1  1  3  4 NA  1  2  1  1  3  3 NA  1  1  3  5  3  2  3  4  1  4  3  1\n [361] NA  2  1  2  2  1  2  2  6  1  2  4  5 NA  3  4  2  1  1  4  2  1  1  1\n [385]  1  2  1  4  4  1  3 NA  3  3 NA  2 NA  1  2  1  1  4  2  1  4  4 NA  1\n [409]  2 NA  3  2  2  2  1  4  3  6  1  2  3  1  3  2  2  2  1  1  3  2  1  1\n [433]  1  3  2  2 NA  4  4  4  1  1 NA  4  3 NA  1  3  1  3  2  4  2  2  2  3\n [457]  2  1  4  3 NA  1  4  3  1  3  2 NA  3 NA  1  3  1  4  1  1  1  2  4  3\n [481]  1  2  2  2  3  2  3  1  1 NA  3  2  1  1  2 NA  2  2  2  3  3  1  1  2\n [505] NA  1  2  1  1  3  3  1  3  1  1  1  1  1  2  5  1  1  2  2  1  1 NA  1\n [529]  4  1  2  4  1  3  2 NA  1  1 NA  2  1  1  4  2  3  3  1  5  3  1  1  2\n [553] NA  1  1  3  1  3  2  4 NA  2  3  2  1  2  1  1  1  2  2  3  1  5  2 NA\n [577]  2 NA  3  2  2  2  1  5  3  2  3  1 NA  3  1  2  2  2  1  2  2  4 NA  6\n [601]  1  2 NA  1  1  2  2  3 NA  3  2  3  3  4  2 NA  2 NA  4 NA  1  1  2  2\n [625]  3  1  1  1  3 NA  2  5 NA  7  1 NA  4  3  3  1 NA  1  1  1  1  3  2  4\n [649]  2  2  3 NA NA  1  4  3  2  2  2  3  2  4  2  2  4 NA NA NA  6  3  3  1\n [673]  4  4  2  1 NA  1  6 NA  3  3  2  1  1  6 NA  1  5  1 NA  2  6  2 NA  4\n [697]  1  3  1  2 NA  1  1  3  1  2  4  2  1  3  2  4  3  2  2  1  1  5  6  4\n [721]  2  2  2  2  4 NA  1  2  2  2  2  4  5 NA NA NA  4  3  3  3  2  4  2  4\n [745] NA NA NA NA  2  1 NA  2  4  3  2 NA  2  3  1  3  4 NA  1  2  1  2 NA  3\n [769]  1  2  1  2  1  2  1  2  2  2  2  1  1  3  3  1  3  4  3 NA NA  4  2  3\n [793]  2  1  3  2  4  2  2  3  1  2  4  3  3  4 NA  1  4  2  1  1  1  3  1  5\n [817]  2  2  4  2 NA  1  3  1  2 NA  1  2  1  2  1 NA  1  3  2  3  2 NA  2  1\n [841]  4  2 NA NA NA  2  4  2 NA NA  3  1 NA  5  5  2  2  2 NA  2  1  3  1  3\n [865]  2  4  2  4 NA  4  1  2  3  2  3  3  2  3  2  2  2  1  3  2  4  2 NA  3\n [889]  3  2  2 NA NA  3  2  1  2  4  1  1  1  1  4  3  2 NA  3  2 NA  1 NA  3\n [913]  2  1  1  1  2 NA  2  2  3  3  2 NA NA  4  5  2  2  2  1  2  3  1  3  3\n [937]  4  3 NA  1  1  1 NA  4  3  5  1  1  2 NA  2  2  2  2  5  2  2  3  1  2\n [961]  3 NA  1  2 NA NA  2 NA  3  1  1  2  5  3  5  1  1  4 NA  2  1  3  1  1\n [985]  2  4  3  3  3 NA  1  1  2  2  1  1  2  2 NA  2\n\n\n\n\n\nThis R code calculates the missing values (NA) within the ‚Äòna_example‚Äô dataset. Initially, we determined the total count of NA values present and identified their index positions within the dataset.\n\ntotal_na &lt;- sum(is.na(na_example))\ncat(\"Total NA values:\", total_na)\n\nTotal NA values: 145\n\n\n\nwhich(is.na(na_example))\n\n  [1]  12  17  27  50  51  52  59  65  66  68  91 117 125 126 127 128 139 140\n [19] 141 142 153 158 168 169 172 179 189 190 203 205 207 208 212 214 237 241\n [37] 243 244 253 257 265 267 269 279 282 287 290 298 310 325 326 330 341 348\n [55] 361 374 392 395 397 407 410 437 443 446 461 468 470 490 496 505 527 536\n [73] 539 553 561 576 578 589 599 603 609 616 618 620 630 633 636 641 652 653\n [91] 666 667 668 677 680 687 691 695 701 726 734 735 736 745 746 747 748 751\n[109] 756 762 767 788 789 807 821 826 832 838 843 844 845 849 850 853 859 869\n[127] 887 892 893 906 909 911 918 924 925 939 943 950 962 965 966 968 979 990\n[145] 999\n\n\n\n\n\n\n# NA deƒüerleri g√∂z ardƒ± ederek ortalama ve standart sapma hesapla\nmean_value &lt;- mean(na_example, na.rm = TRUE)\nsd_value &lt;- sd(na_example, na.rm = TRUE)\n\n# Sonu√ßlarƒ± ekrana yazdƒ±r\ncat(\"Mean:\", mean_value, \"\\n\")\n\nMean: 2.301754 \n\ncat(\"Standart Deviation:\", sd_value)\n\nStandart Deviation: 1.22338\n\n\n\n\n\nIn this process, we replace all missing (NA) values in the na_example dataset with the median of the non-missing values. The median is chosen because it is less sensitive to extreme values (outliers) compared to the mean.\n\n# NA olmayan deƒüerlerin medyanƒ±nƒ± hesapla\nmedian_others &lt;- median(na_example, na.rm = TRUE)\n\n# NA deƒüerleri medyan ile deƒüi≈ütir\nna_example_median &lt;- ifelse(is.na(na_example), median_others, na_example)\n\n# Sonucu yazdƒ±r\ncat(\"Medyan:\", median_others, \"\\n\")\n\nMedyan: 2 \n\nprint(na_example_median)\n\n   [1] 2 1 3 2 1 3 1 4 3 2 2 2 2 2 1 4 2 1 1 2 1 2 2 1 2 5 2 2 2 3 1 2 4 1 1 1 4\n  [38] 5 2 3 4 1 2 4 1 1 2 1 5 2 2 2 1 1 5 1 3 1 2 4 4 7 3 2 2 2 1 2 4 1 2 2 3 2\n  [75] 1 2 2 4 3 4 2 3 1 3 2 1 1 1 3 1 2 3 1 2 2 1 2 2 1 1 4 1 1 2 3 3 2 2 3 3 3\n [112] 4 1 1 1 2 2 4 3 4 3 1 2 1 2 2 2 2 1 5 1 2 1 3 5 3 2 2 2 2 2 2 3 5 3 1 1 4\n [149] 2 4 3 3 2 2 3 2 6 2 1 1 2 2 1 3 1 1 5 2 2 2 4 2 2 5 1 4 3 3 2 4 3 1 4 1 1\n [186] 3 1 1 2 2 3 5 2 2 2 3 1 2 2 3 2 1 2 2 2 1 2 2 2 1 1 2 3 2 1 2 2 1 3 2 2 1\n [223] 1 2 3 1 1 1 4 3 4 2 2 1 4 1 2 5 1 4 2 3 2 2 1 1 5 2 3 3 2 4 2 3 2 5 2 2 3\n [260] 4 6 2 2 2 2 2 2 2 2 3 3 2 2 4 3 1 4 2 2 2 4 2 6 2 3 1 2 2 2 2 1 1 3 2 3 3\n [297] 1 2 1 4 2 1 1 3 2 1 2 3 1 2 2 3 3 2 1 2 3 5 5 1 2 3 3 1 2 2 1 2 4 2 2 1 1\n [334] 1 3 2 1 1 3 4 2 1 2 1 1 3 3 2 1 1 3 5 3 2 3 4 1 4 3 1 2 2 1 2 2 1 2 2 6 1\n [371] 2 4 5 2 3 4 2 1 1 4 2 1 1 1 1 2 1 4 4 1 3 2 3 3 2 2 2 1 2 1 1 4 2 1 4 4 2\n [408] 1 2 2 3 2 2 2 1 4 3 6 1 2 3 1 3 2 2 2 1 1 3 2 1 1 1 3 2 2 2 4 4 4 1 1 2 4\n [445] 3 2 1 3 1 3 2 4 2 2 2 3 2 1 4 3 2 1 4 3 1 3 2 2 3 2 1 3 1 4 1 1 1 2 4 3 1\n [482] 2 2 2 3 2 3 1 1 2 3 2 1 1 2 2 2 2 2 3 3 1 1 2 2 1 2 1 1 3 3 1 3 1 1 1 1 1\n [519] 2 5 1 1 2 2 1 1 2 1 4 1 2 4 1 3 2 2 1 1 2 2 1 1 4 2 3 3 1 5 3 1 1 2 2 1 1\n [556] 3 1 3 2 4 2 2 3 2 1 2 1 1 1 2 2 3 1 5 2 2 2 2 3 2 2 2 1 5 3 2 3 1 2 3 1 2\n [593] 2 2 1 2 2 4 2 6 1 2 2 1 1 2 2 3 2 3 2 3 3 4 2 2 2 2 4 2 1 1 2 2 3 1 1 1 3\n [630] 2 2 5 2 7 1 2 4 3 3 1 2 1 1 1 1 3 2 4 2 2 3 2 2 1 4 3 2 2 2 3 2 4 2 2 4 2\n [667] 2 2 6 3 3 1 4 4 2 1 2 1 6 2 3 3 2 1 1 6 2 1 5 1 2 2 6 2 2 4 1 3 1 2 2 1 1\n [704] 3 1 2 4 2 1 3 2 4 3 2 2 1 1 5 6 4 2 2 2 2 4 2 1 2 2 2 2 4 5 2 2 2 4 3 3 3\n [741] 2 4 2 4 2 2 2 2 2 1 2 2 4 3 2 2 2 3 1 3 4 2 1 2 1 2 2 3 1 2 1 2 1 2 1 2 2\n [778] 2 2 1 1 3 3 1 3 4 3 2 2 4 2 3 2 1 3 2 4 2 2 3 1 2 4 3 3 4 2 1 4 2 1 1 1 3\n [815] 1 5 2 2 4 2 2 1 3 1 2 2 1 2 1 2 1 2 1 3 2 3 2 2 2 1 4 2 2 2 2 2 4 2 2 2 3\n [852] 1 2 5 5 2 2 2 2 2 1 3 1 3 2 4 2 4 2 4 1 2 3 2 3 3 2 3 2 2 2 1 3 2 4 2 2 3\n [889] 3 2 2 2 2 3 2 1 2 4 1 1 1 1 4 3 2 2 3 2 2 1 2 3 2 1 1 1 2 2 2 2 3 3 2 2 2\n [926] 4 5 2 2 2 1 2 3 1 3 3 4 3 2 1 1 1 2 4 3 5 1 1 2 2 2 2 2 2 5 2 2 3 1 2 3 2\n [963] 1 2 2 2 2 2 3 1 1 2 5 3 5 1 1 4 2 2 1 3 1 1 2 4 3 3 3 2 1 1 2 2 1 1 2 2 2\n[1000] 2\n\n\n\nversion1_median &lt;- median(na_example_median)\nversion1_sd &lt;- sd(na_example_median)\n\n# Sonu√ßlarƒ± yazdƒ±r\ncat(\"Versiyon 1 Medyan:\", version1_median, \"\\n\")\n\nVersiyon 1 Medyan: 2 \n\ncat(\"Versiyon 1 Sapma:\", version1_sd)\n\nVersiyon 1 Sapma: 1.136102\n\n\n\n\n\nThis process replaces all NA values in the dataset with a randomly selected non-missing value from the same dataset. First, we extract all non-missing values, then for each NA, a random value from the non-missing values is chosen to fill in the missing spot.\n\n# NA olmayan deƒüerleri al\nnon_na_values &lt;- na_example[!is.na(na_example)]\n\n# NA deƒüerlerini rastgele bir NA olmayan deƒüerle deƒüi≈ütir\nna_example_random &lt;- ifelse(is.na(na_example), sample(non_na_values, 1), na_example)\n\n# Sonu√ßlarƒ± yazdƒ±r\nprint(na_example_random)\n\n   [1] 2 1 3 2 1 3 1 4 3 2 2 1 2 2 1 4 1 1 1 2 1 2 2 1 2 5 1 2 2 3 1 2 4 1 1 1 4\n  [38] 5 2 3 4 1 2 4 1 1 2 1 5 1 1 1 1 1 5 1 3 1 1 4 4 7 3 2 1 1 1 1 4 1 2 2 3 2\n  [75] 1 2 2 4 3 4 2 3 1 3 2 1 1 1 3 1 1 3 1 2 2 1 2 2 1 1 4 1 1 2 3 3 2 2 3 3 3\n [112] 4 1 1 1 2 1 4 3 4 3 1 2 1 1 1 1 1 1 5 1 2 1 3 5 3 2 2 1 1 1 1 3 5 3 1 1 4\n [149] 2 4 3 3 1 2 3 2 6 1 1 1 2 2 1 3 1 1 5 1 1 2 4 1 2 5 1 4 3 3 1 4 3 1 4 1 1\n [186] 3 1 1 1 1 3 5 2 2 2 3 1 2 2 3 2 1 1 2 1 1 1 1 2 1 1 1 3 1 1 2 2 1 3 2 2 1\n [223] 1 2 3 1 1 1 4 3 4 2 2 1 4 1 1 5 1 4 1 3 1 1 1 1 5 2 3 3 2 4 1 3 2 5 1 2 3\n [260] 4 6 2 2 2 1 2 1 2 1 3 3 2 2 4 3 1 4 2 1 2 4 1 6 2 3 1 1 2 2 1 1 1 3 2 3 3\n [297] 1 1 1 4 2 1 1 3 2 1 2 3 1 1 2 3 3 2 1 2 3 5 5 1 2 3 3 1 1 1 1 2 4 1 2 1 1\n [334] 1 3 2 1 1 3 4 1 1 2 1 1 3 3 1 1 1 3 5 3 2 3 4 1 4 3 1 1 2 1 2 2 1 2 2 6 1\n [371] 2 4 5 1 3 4 2 1 1 4 2 1 1 1 1 2 1 4 4 1 3 1 3 3 1 2 1 1 2 1 1 4 2 1 4 4 1\n [408] 1 2 1 3 2 2 2 1 4 3 6 1 2 3 1 3 2 2 2 1 1 3 2 1 1 1 3 2 2 1 4 4 4 1 1 1 4\n [445] 3 1 1 3 1 3 2 4 2 2 2 3 2 1 4 3 1 1 4 3 1 3 2 1 3 1 1 3 1 4 1 1 1 2 4 3 1\n [482] 2 2 2 3 2 3 1 1 1 3 2 1 1 2 1 2 2 2 3 3 1 1 2 1 1 2 1 1 3 3 1 3 1 1 1 1 1\n [519] 2 5 1 1 2 2 1 1 1 1 4 1 2 4 1 3 2 1 1 1 1 2 1 1 4 2 3 3 1 5 3 1 1 2 1 1 1\n [556] 3 1 3 2 4 1 2 3 2 1 2 1 1 1 2 2 3 1 5 2 1 2 1 3 2 2 2 1 5 3 2 3 1 1 3 1 2\n [593] 2 2 1 2 2 4 1 6 1 2 1 1 1 2 2 3 1 3 2 3 3 4 2 1 2 1 4 1 1 1 2 2 3 1 1 1 3\n [630] 1 2 5 1 7 1 1 4 3 3 1 1 1 1 1 1 3 2 4 2 2 3 1 1 1 4 3 2 2 2 3 2 4 2 2 4 1\n [667] 1 1 6 3 3 1 4 4 2 1 1 1 6 1 3 3 2 1 1 6 1 1 5 1 1 2 6 2 1 4 1 3 1 2 1 1 1\n [704] 3 1 2 4 2 1 3 2 4 3 2 2 1 1 5 6 4 2 2 2 2 4 1 1 2 2 2 2 4 5 1 1 1 4 3 3 3\n [741] 2 4 2 4 1 1 1 1 2 1 1 2 4 3 2 1 2 3 1 3 4 1 1 2 1 2 1 3 1 2 1 2 1 2 1 2 2\n [778] 2 2 1 1 3 3 1 3 4 3 1 1 4 2 3 2 1 3 2 4 2 2 3 1 2 4 3 3 4 1 1 4 2 1 1 1 3\n [815] 1 5 2 2 4 2 1 1 3 1 2 1 1 2 1 2 1 1 1 3 2 3 2 1 2 1 4 2 1 1 1 2 4 2 1 1 3\n [852] 1 1 5 5 2 2 2 1 2 1 3 1 3 2 4 2 4 1 4 1 2 3 2 3 3 2 3 2 2 2 1 3 2 4 2 1 3\n [889] 3 2 2 1 1 3 2 1 2 4 1 1 1 1 4 3 2 1 3 2 1 1 1 3 2 1 1 1 2 1 2 2 3 3 2 1 1\n [926] 4 5 2 2 2 1 2 3 1 3 3 4 3 1 1 1 1 1 4 3 5 1 1 2 1 2 2 2 2 5 2 2 3 1 2 3 1\n [963] 1 2 1 1 2 1 3 1 1 2 5 3 5 1 1 4 1 2 1 3 1 1 2 4 3 3 3 1 1 1 2 2 1 1 2 2 1\n[1000] 2\n\n\n\nversion2_median &lt;- median(na_example_random)\nversion2_sd &lt;- sd(na_example_random)\n\n# Sonu√ßlarƒ± yazdƒ±r\ncat(\"Versiyon 2 Medyan:\", version2_median, \"\\n\")\n\nVersiyon 2 Medyan: 2 \n\ncat(\"Versiyon 2 Sapma:\", version2_sd)\n\nVersiyon 2 Sapma: 1.220541\n\n\n\nlibrary(knitr)  # kable fonksiyonu i√ßin\n\nWarning: package 'knitr' was built under R version 4.4.3\n\n\n\n# Bu kod bloƒüu tamamen AI tarafƒ±ndan yazƒ±lmƒ±stƒ±r.\n# Sonu√ßlarƒ± birle≈ütirip tabloyu olu≈ütur\n\nstatistics_table &lt;- data.frame(\n  Method = c(\"Original (Mean)\", \"Original (SD)\", \n             \"Imputed (Median, Mean)\", \"Imputed (Median, SD)\", \n             \"Imputed (Random, Mean)\", \"Imputed (Random, SD)\"),\n  Value = c(mean_value, sd_value,\n            mean(na_example_median), sd(na_example_median),\n            mean(na_example_random), sd(na_example_random))\n)\n\n# Tabloyu yazdƒ±r\nkable(statistics_table, caption = \"Comparison of Statistics Before and After Handling NA Values\")\n\n\nComparison of Statistics Before and After Handling NA Values\n\n\nMethod\nValue\n\n\n\n\nOriginal (Mean)\n2.301754\n\n\nOriginal (SD)\n1.223380\n\n\nImputed (Median, Mean)\n2.258000\n\n\nImputed (Median, SD)\n1.136102\n\n\nImputed (Random, Mean)\n2.113000\n\n\nImputed (Random, SD)\n1.220541\n\n\n\n\n\nRegarding the data, imputing with the median seems more appropriate as it preserves the central tendency without being affected by outliers. Imputing with random values could better reflect the distribution of the data, but it may introduce some variability. Looking at the original data, if the number of missing values is minimal, ignoring them could be acceptable. However, if the missing values are not random, it could introduce bias in the data.",
    "crumbs": [
      "Handling Missing Values"
    ]
  },
  {
    "objectID": "assignments/handlingna.html#handling-missing-values-in-the-dslabs-na_example-dataset-methods-and-comparisons",
    "href": "assignments/handlingna.html#handling-missing-values-in-the-dslabs-na_example-dataset-methods-and-comparisons",
    "title": "NA_Example",
    "section": "Handling Missing Values in the dslabs ‚Äòna_example‚Äô Dataset: Methods and Comparisons",
    "text": "Handling Missing Values in the dslabs ‚Äòna_example‚Äô Dataset: Methods and Comparisons\n\nInstalling and Loading the ‚Äòdslaps‚Äô\n\n#install.packages(\"dslabs\")\nlibrary(dslabs)\n\nWarning: package 'dslabs' was built under R version 4.4.3\n\n\nAfter successfully installing and loading the ‚Äòdslabs‚Äô library, we can now print the desired dataset.\n\nprint(na_example)\n\n   [1]  2  1  3  2  1  3  1  4  3  2  2 NA  2  2  1  4 NA  1  1  2  1  2  2  1\n  [25]  2  5 NA  2  2  3  1  2  4  1  1  1  4  5  2  3  4  1  2  4  1  1  2  1\n  [49]  5 NA NA NA  1  1  5  1  3  1 NA  4  4  7  3  2 NA NA  1 NA  4  1  2  2\n  [73]  3  2  1  2  2  4  3  4  2  3  1  3  2  1  1  1  3  1 NA  3  1  2  2  1\n  [97]  2  2  1  1  4  1  1  2  3  3  2  2  3  3  3  4  1  1  1  2 NA  4  3  4\n [121]  3  1  2  1 NA NA NA NA  1  5  1  2  1  3  5  3  2  2 NA NA NA NA  3  5\n [145]  3  1  1  4  2  4  3  3 NA  2  3  2  6 NA  1  1  2  2  1  3  1  1  5 NA\n [169] NA  2  4 NA  2  5  1  4  3  3 NA  4  3  1  4  1  1  3  1  1 NA NA  3  5\n [193]  2  2  2  3  1  2  2  3  2  1 NA  2 NA  1 NA NA  2  1  1 NA  3 NA  1  2\n [217]  2  1  3  2  2  1  1  2  3  1  1  1  4  3  4  2  2  1  4  1 NA  5  1  4\n [241] NA  3 NA NA  1  1  5  2  3  3  2  4 NA  3  2  5 NA  2  3  4  6  2  2  2\n [265] NA  2 NA  2 NA  3  3  2  2  4  3  1  4  2 NA  2  4 NA  6  2  3  1 NA  2\n [289]  2 NA  1  1  3  2  3  3  1 NA  1  4  2  1  1  3  2  1  2  3  1 NA  2  3\n [313]  3  2  1  2  3  5  5  1  2  3  3  1 NA NA  1  2  4 NA  2  1  1  1  3  2\n [337]  1  1  3  4 NA  1  2  1  1  3  3 NA  1  1  3  5  3  2  3  4  1  4  3  1\n [361] NA  2  1  2  2  1  2  2  6  1  2  4  5 NA  3  4  2  1  1  4  2  1  1  1\n [385]  1  2  1  4  4  1  3 NA  3  3 NA  2 NA  1  2  1  1  4  2  1  4  4 NA  1\n [409]  2 NA  3  2  2  2  1  4  3  6  1  2  3  1  3  2  2  2  1  1  3  2  1  1\n [433]  1  3  2  2 NA  4  4  4  1  1 NA  4  3 NA  1  3  1  3  2  4  2  2  2  3\n [457]  2  1  4  3 NA  1  4  3  1  3  2 NA  3 NA  1  3  1  4  1  1  1  2  4  3\n [481]  1  2  2  2  3  2  3  1  1 NA  3  2  1  1  2 NA  2  2  2  3  3  1  1  2\n [505] NA  1  2  1  1  3  3  1  3  1  1  1  1  1  2  5  1  1  2  2  1  1 NA  1\n [529]  4  1  2  4  1  3  2 NA  1  1 NA  2  1  1  4  2  3  3  1  5  3  1  1  2\n [553] NA  1  1  3  1  3  2  4 NA  2  3  2  1  2  1  1  1  2  2  3  1  5  2 NA\n [577]  2 NA  3  2  2  2  1  5  3  2  3  1 NA  3  1  2  2  2  1  2  2  4 NA  6\n [601]  1  2 NA  1  1  2  2  3 NA  3  2  3  3  4  2 NA  2 NA  4 NA  1  1  2  2\n [625]  3  1  1  1  3 NA  2  5 NA  7  1 NA  4  3  3  1 NA  1  1  1  1  3  2  4\n [649]  2  2  3 NA NA  1  4  3  2  2  2  3  2  4  2  2  4 NA NA NA  6  3  3  1\n [673]  4  4  2  1 NA  1  6 NA  3  3  2  1  1  6 NA  1  5  1 NA  2  6  2 NA  4\n [697]  1  3  1  2 NA  1  1  3  1  2  4  2  1  3  2  4  3  2  2  1  1  5  6  4\n [721]  2  2  2  2  4 NA  1  2  2  2  2  4  5 NA NA NA  4  3  3  3  2  4  2  4\n [745] NA NA NA NA  2  1 NA  2  4  3  2 NA  2  3  1  3  4 NA  1  2  1  2 NA  3\n [769]  1  2  1  2  1  2  1  2  2  2  2  1  1  3  3  1  3  4  3 NA NA  4  2  3\n [793]  2  1  3  2  4  2  2  3  1  2  4  3  3  4 NA  1  4  2  1  1  1  3  1  5\n [817]  2  2  4  2 NA  1  3  1  2 NA  1  2  1  2  1 NA  1  3  2  3  2 NA  2  1\n [841]  4  2 NA NA NA  2  4  2 NA NA  3  1 NA  5  5  2  2  2 NA  2  1  3  1  3\n [865]  2  4  2  4 NA  4  1  2  3  2  3  3  2  3  2  2  2  1  3  2  4  2 NA  3\n [889]  3  2  2 NA NA  3  2  1  2  4  1  1  1  1  4  3  2 NA  3  2 NA  1 NA  3\n [913]  2  1  1  1  2 NA  2  2  3  3  2 NA NA  4  5  2  2  2  1  2  3  1  3  3\n [937]  4  3 NA  1  1  1 NA  4  3  5  1  1  2 NA  2  2  2  2  5  2  2  3  1  2\n [961]  3 NA  1  2 NA NA  2 NA  3  1  1  2  5  3  5  1  1  4 NA  2  1  3  1  1\n [985]  2  4  3  3  3 NA  1  1  2  2  1  1  2  2 NA  2\n\n\n\n\nNumber and Locations of NA Values\nThis R code calculates the missing values (NA) within the ‚Äòna_example‚Äô dataset. Initially, we determined the total count of NA values present and identified their index positions within the dataset.\n\ntotal_na &lt;- sum(is.na(na_example))\ncat(\"Total NA values:\", total_na)\n\nTotal NA values: 145\n\n\n\nwhich(is.na(na_example))\n\n  [1]  12  17  27  50  51  52  59  65  66  68  91 117 125 126 127 128 139 140\n [19] 141 142 153 158 168 169 172 179 189 190 203 205 207 208 212 214 237 241\n [37] 243 244 253 257 265 267 269 279 282 287 290 298 310 325 326 330 341 348\n [55] 361 374 392 395 397 407 410 437 443 446 461 468 470 490 496 505 527 536\n [73] 539 553 561 576 578 589 599 603 609 616 618 620 630 633 636 641 652 653\n [91] 666 667 668 677 680 687 691 695 701 726 734 735 736 745 746 747 748 751\n[109] 756 762 767 788 789 807 821 826 832 838 843 844 845 849 850 853 859 869\n[127] 887 892 893 906 909 911 918 924 925 939 943 950 962 965 966 968 979 990\n[145] 999\n\n\n\n\nStatistical Calculation Ignoring NA Values\n\n# NA deƒüerleri g√∂z ardƒ± ederek ortalama ve standart sapma hesapla\nmean_value &lt;- mean(na_example, na.rm = TRUE)\nsd_value &lt;- sd(na_example, na.rm = TRUE)\n\n# Sonu√ßlarƒ± ekrana yazdƒ±r\ncat(\"Mean:\", mean_value, \"\\n\")\n\nMean: 2.301754 \n\ncat(\"Standart Deviation:\", sd_value)\n\nStandart Deviation: 1.22338\n\n\n\n\nReplacing NA Values with the Median\nIn this process, we replace all missing (NA) values in the na_example dataset with the median of the non-missing values. The median is chosen because it is less sensitive to extreme values (outliers) compared to the mean.\n\n# NA olmayan deƒüerlerin medyanƒ±nƒ± hesapla\nmedian_others &lt;- median(na_example, na.rm = TRUE)\n\n# NA deƒüerleri medyan ile deƒüi≈ütir\nna_example_median &lt;- ifelse(is.na(na_example), median_others, na_example)\n\n# Sonucu yazdƒ±r\ncat(\"Medyan:\", median_others, \"\\n\")\n\nMedyan: 2 \n\nprint(na_example_median)\n\n   [1] 2 1 3 2 1 3 1 4 3 2 2 2 2 2 1 4 2 1 1 2 1 2 2 1 2 5 2 2 2 3 1 2 4 1 1 1 4\n  [38] 5 2 3 4 1 2 4 1 1 2 1 5 2 2 2 1 1 5 1 3 1 2 4 4 7 3 2 2 2 1 2 4 1 2 2 3 2\n  [75] 1 2 2 4 3 4 2 3 1 3 2 1 1 1 3 1 2 3 1 2 2 1 2 2 1 1 4 1 1 2 3 3 2 2 3 3 3\n [112] 4 1 1 1 2 2 4 3 4 3 1 2 1 2 2 2 2 1 5 1 2 1 3 5 3 2 2 2 2 2 2 3 5 3 1 1 4\n [149] 2 4 3 3 2 2 3 2 6 2 1 1 2 2 1 3 1 1 5 2 2 2 4 2 2 5 1 4 3 3 2 4 3 1 4 1 1\n [186] 3 1 1 2 2 3 5 2 2 2 3 1 2 2 3 2 1 2 2 2 1 2 2 2 1 1 2 3 2 1 2 2 1 3 2 2 1\n [223] 1 2 3 1 1 1 4 3 4 2 2 1 4 1 2 5 1 4 2 3 2 2 1 1 5 2 3 3 2 4 2 3 2 5 2 2 3\n [260] 4 6 2 2 2 2 2 2 2 2 3 3 2 2 4 3 1 4 2 2 2 4 2 6 2 3 1 2 2 2 2 1 1 3 2 3 3\n [297] 1 2 1 4 2 1 1 3 2 1 2 3 1 2 2 3 3 2 1 2 3 5 5 1 2 3 3 1 2 2 1 2 4 2 2 1 1\n [334] 1 3 2 1 1 3 4 2 1 2 1 1 3 3 2 1 1 3 5 3 2 3 4 1 4 3 1 2 2 1 2 2 1 2 2 6 1\n [371] 2 4 5 2 3 4 2 1 1 4 2 1 1 1 1 2 1 4 4 1 3 2 3 3 2 2 2 1 2 1 1 4 2 1 4 4 2\n [408] 1 2 2 3 2 2 2 1 4 3 6 1 2 3 1 3 2 2 2 1 1 3 2 1 1 1 3 2 2 2 4 4 4 1 1 2 4\n [445] 3 2 1 3 1 3 2 4 2 2 2 3 2 1 4 3 2 1 4 3 1 3 2 2 3 2 1 3 1 4 1 1 1 2 4 3 1\n [482] 2 2 2 3 2 3 1 1 2 3 2 1 1 2 2 2 2 2 3 3 1 1 2 2 1 2 1 1 3 3 1 3 1 1 1 1 1\n [519] 2 5 1 1 2 2 1 1 2 1 4 1 2 4 1 3 2 2 1 1 2 2 1 1 4 2 3 3 1 5 3 1 1 2 2 1 1\n [556] 3 1 3 2 4 2 2 3 2 1 2 1 1 1 2 2 3 1 5 2 2 2 2 3 2 2 2 1 5 3 2 3 1 2 3 1 2\n [593] 2 2 1 2 2 4 2 6 1 2 2 1 1 2 2 3 2 3 2 3 3 4 2 2 2 2 4 2 1 1 2 2 3 1 1 1 3\n [630] 2 2 5 2 7 1 2 4 3 3 1 2 1 1 1 1 3 2 4 2 2 3 2 2 1 4 3 2 2 2 3 2 4 2 2 4 2\n [667] 2 2 6 3 3 1 4 4 2 1 2 1 6 2 3 3 2 1 1 6 2 1 5 1 2 2 6 2 2 4 1 3 1 2 2 1 1\n [704] 3 1 2 4 2 1 3 2 4 3 2 2 1 1 5 6 4 2 2 2 2 4 2 1 2 2 2 2 4 5 2 2 2 4 3 3 3\n [741] 2 4 2 4 2 2 2 2 2 1 2 2 4 3 2 2 2 3 1 3 4 2 1 2 1 2 2 3 1 2 1 2 1 2 1 2 2\n [778] 2 2 1 1 3 3 1 3 4 3 2 2 4 2 3 2 1 3 2 4 2 2 3 1 2 4 3 3 4 2 1 4 2 1 1 1 3\n [815] 1 5 2 2 4 2 2 1 3 1 2 2 1 2 1 2 1 2 1 3 2 3 2 2 2 1 4 2 2 2 2 2 4 2 2 2 3\n [852] 1 2 5 5 2 2 2 2 2 1 3 1 3 2 4 2 4 2 4 1 2 3 2 3 3 2 3 2 2 2 1 3 2 4 2 2 3\n [889] 3 2 2 2 2 3 2 1 2 4 1 1 1 1 4 3 2 2 3 2 2 1 2 3 2 1 1 1 2 2 2 2 3 3 2 2 2\n [926] 4 5 2 2 2 1 2 3 1 3 3 4 3 2 1 1 1 2 4 3 5 1 1 2 2 2 2 2 2 5 2 2 3 1 2 3 2\n [963] 1 2 2 2 2 2 3 1 1 2 5 3 5 1 1 4 2 2 1 3 1 1 2 4 3 3 3 2 1 1 2 2 1 1 2 2 2\n[1000] 2\n\n\n\nversion1_median &lt;- median(na_example_median)\nversion1_sd &lt;- sd(na_example_median)\n\n# Sonu√ßlarƒ± yazdƒ±r\ncat(\"Versiyon 1 Medyan:\", version1_median, \"\\n\")\n\nVersiyon 1 Medyan: 2 \n\ncat(\"Versiyon 1 Sapma:\", version1_sd)\n\nVersiyon 1 Sapma: 1.136102\n\n\n\n\nReplacing NA Values with Randomly Selected Non-missing Value\nThis process replaces all NA values in the dataset with a randomly selected non-missing value from the same dataset. First, we extract all non-missing values, then for each NA, a random value from the non-missing values is chosen to fill in the missing spot.\n\n# NA olmayan deƒüerleri al\nnon_na_values &lt;- na_example[!is.na(na_example)]\n\n# NA deƒüerlerini rastgele bir NA olmayan deƒüerle deƒüi≈ütir\nna_example_random &lt;- ifelse(is.na(na_example), sample(non_na_values, 1), na_example)\n\n# Sonu√ßlarƒ± yazdƒ±r\nprint(na_example_random)\n\n   [1] 2 1 3 2 1 3 1 4 3 2 2 4 2 2 1 4 4 1 1 2 1 2 2 1 2 5 4 2 2 3 1 2 4 1 1 1 4\n  [38] 5 2 3 4 1 2 4 1 1 2 1 5 4 4 4 1 1 5 1 3 1 4 4 4 7 3 2 4 4 1 4 4 1 2 2 3 2\n  [75] 1 2 2 4 3 4 2 3 1 3 2 1 1 1 3 1 4 3 1 2 2 1 2 2 1 1 4 1 1 2 3 3 2 2 3 3 3\n [112] 4 1 1 1 2 4 4 3 4 3 1 2 1 4 4 4 4 1 5 1 2 1 3 5 3 2 2 4 4 4 4 3 5 3 1 1 4\n [149] 2 4 3 3 4 2 3 2 6 4 1 1 2 2 1 3 1 1 5 4 4 2 4 4 2 5 1 4 3 3 4 4 3 1 4 1 1\n [186] 3 1 1 4 4 3 5 2 2 2 3 1 2 2 3 2 1 4 2 4 1 4 4 2 1 1 4 3 4 1 2 2 1 3 2 2 1\n [223] 1 2 3 1 1 1 4 3 4 2 2 1 4 1 4 5 1 4 4 3 4 4 1 1 5 2 3 3 2 4 4 3 2 5 4 2 3\n [260] 4 6 2 2 2 4 2 4 2 4 3 3 2 2 4 3 1 4 2 4 2 4 4 6 2 3 1 4 2 2 4 1 1 3 2 3 3\n [297] 1 4 1 4 2 1 1 3 2 1 2 3 1 4 2 3 3 2 1 2 3 5 5 1 2 3 3 1 4 4 1 2 4 4 2 1 1\n [334] 1 3 2 1 1 3 4 4 1 2 1 1 3 3 4 1 1 3 5 3 2 3 4 1 4 3 1 4 2 1 2 2 1 2 2 6 1\n [371] 2 4 5 4 3 4 2 1 1 4 2 1 1 1 1 2 1 4 4 1 3 4 3 3 4 2 4 1 2 1 1 4 2 1 4 4 4\n [408] 1 2 4 3 2 2 2 1 4 3 6 1 2 3 1 3 2 2 2 1 1 3 2 1 1 1 3 2 2 4 4 4 4 1 1 4 4\n [445] 3 4 1 3 1 3 2 4 2 2 2 3 2 1 4 3 4 1 4 3 1 3 2 4 3 4 1 3 1 4 1 1 1 2 4 3 1\n [482] 2 2 2 3 2 3 1 1 4 3 2 1 1 2 4 2 2 2 3 3 1 1 2 4 1 2 1 1 3 3 1 3 1 1 1 1 1\n [519] 2 5 1 1 2 2 1 1 4 1 4 1 2 4 1 3 2 4 1 1 4 2 1 1 4 2 3 3 1 5 3 1 1 2 4 1 1\n [556] 3 1 3 2 4 4 2 3 2 1 2 1 1 1 2 2 3 1 5 2 4 2 4 3 2 2 2 1 5 3 2 3 1 4 3 1 2\n [593] 2 2 1 2 2 4 4 6 1 2 4 1 1 2 2 3 4 3 2 3 3 4 2 4 2 4 4 4 1 1 2 2 3 1 1 1 3\n [630] 4 2 5 4 7 1 4 4 3 3 1 4 1 1 1 1 3 2 4 2 2 3 4 4 1 4 3 2 2 2 3 2 4 2 2 4 4\n [667] 4 4 6 3 3 1 4 4 2 1 4 1 6 4 3 3 2 1 1 6 4 1 5 1 4 2 6 2 4 4 1 3 1 2 4 1 1\n [704] 3 1 2 4 2 1 3 2 4 3 2 2 1 1 5 6 4 2 2 2 2 4 4 1 2 2 2 2 4 5 4 4 4 4 3 3 3\n [741] 2 4 2 4 4 4 4 4 2 1 4 2 4 3 2 4 2 3 1 3 4 4 1 2 1 2 4 3 1 2 1 2 1 2 1 2 2\n [778] 2 2 1 1 3 3 1 3 4 3 4 4 4 2 3 2 1 3 2 4 2 2 3 1 2 4 3 3 4 4 1 4 2 1 1 1 3\n [815] 1 5 2 2 4 2 4 1 3 1 2 4 1 2 1 2 1 4 1 3 2 3 2 4 2 1 4 2 4 4 4 2 4 2 4 4 3\n [852] 1 4 5 5 2 2 2 4 2 1 3 1 3 2 4 2 4 4 4 1 2 3 2 3 3 2 3 2 2 2 1 3 2 4 2 4 3\n [889] 3 2 2 4 4 3 2 1 2 4 1 1 1 1 4 3 2 4 3 2 4 1 4 3 2 1 1 1 2 4 2 2 3 3 2 4 4\n [926] 4 5 2 2 2 1 2 3 1 3 3 4 3 4 1 1 1 4 4 3 5 1 1 2 4 2 2 2 2 5 2 2 3 1 2 3 4\n [963] 1 2 4 4 2 4 3 1 1 2 5 3 5 1 1 4 4 2 1 3 1 1 2 4 3 3 3 4 1 1 2 2 1 1 2 2 4\n[1000] 2\n\n\n\nversion2_median &lt;- median(na_example_random)\nversion2_sd &lt;- sd(na_example_random)\n\n# Sonu√ßlarƒ± yazdƒ±r\ncat(\"Versiyon 2 Medyan:\", version2_median, \"\\n\")\n\nVersiyon 2 Medyan: 2 \n\ncat(\"Versiyon 2 Sapma:\", version2_sd)\n\nVersiyon 2 Sapma: 1.279583\n\n\n\nlibrary(knitr)  # kable fonksiyonu i√ßin\n\nWarning: package 'knitr' was built under R version 4.4.3\n\n\n\n# Bu kod bloƒüu tamamen AI tarafƒ±ndan yazƒ±lmƒ±stƒ±r.\n# Sonu√ßlarƒ± birle≈ütirip tabloyu olu≈ütur\n\nstatistics_table &lt;- data.frame(\n  Method = c(\"Original (Mean)\", \"Original (SD)\", \n             \"Imputed (Median, Mean)\", \"Imputed (Median, SD)\", \n             \"Imputed (Random, Mean)\", \"Imputed (Random, SD)\"),\n  Value = c(mean_value, sd_value,\n            mean(na_example_median), sd(na_example_median),\n            mean(na_example_random), sd(na_example_random))\n)\n\n# Tabloyu yazdƒ±r\nkable(statistics_table, caption = \"Comparison of Statistics Before and After Handling NA Values\")\n\n\nComparison of Statistics Before and After Handling NA Values\n\n\nMethod\nValue\n\n\n\n\nOriginal (Mean)\n2.301754\n\n\nOriginal (SD)\n1.223380\n\n\nImputed (Median, Mean)\n2.258000\n\n\nImputed (Median, SD)\n1.136102\n\n\nImputed (Random, Mean)\n2.548000\n\n\nImputed (Random, SD)\n1.279583\n\n\n\n\n\nRegarding the data, imputing with the median seems more appropriate as it preserves the central tendency without being affected by outliers. Imputing with random values could better reflect the distribution of the data, but it may introduce some variability. Looking at the original data, if the number of missing values is minimal, ignoring them could be acceptable. However, if the missing values are not random, it could introduce bias in the data.",
    "crumbs": [
      "Handling Missing Values"
    ]
  },
  {
    "objectID": "assignments.html",
    "href": "assignments.html",
    "title": "EMU660 Spring 2024-2025 Assignment Portfolio",
    "section": "",
    "text": "On this page, I showcase the assignments I conducted for the EMU660 Decision Making with Analytics course during the [term and year, e.g.¬†Spring 2024-2025].\nThroughout this course, I worked on various analytical problems and decision-making tasks using different methodologies and tools. You can explore these assignments by navigating through the left menu, where I have categorized each one by topic and methodology.\nPlease use the left menu to navigate through my assignments, which include topics like Data Science, MRCars Statistics, and more. Each assignment provides insights into the methods applied and the results achieved.\n\n\n\n‚ÄúCtrl + C, Ctrl + V, Genius!‚Äù ‚å®Ô∏èüêß\n\n\n\n\n\n Back to top",
    "crumbs": [
      "Assignments"
    ]
  },
  {
    "objectID": "posts.html",
    "href": "posts.html",
    "title": "My Blog",
    "section": "",
    "text": "This page is under construction.\n\n\n\n Back to top"
  },
  {
    "objectID": "project.html#project-overview-and-scope",
    "href": "project.html#project-overview-and-scope",
    "title": "Project Genre Matters: Exploring Film Audience Preferences",
    "section": "1.Project Overview and Scope",
    "text": "1.Project Overview and Scope\nBu projede, farklƒ± film t√ºrlerinin izleyici tercihleri a√ßƒ±sƒ±ndan nasƒ±l bir performans g√∂sterdiƒüini analiz etmeyi ama√ßlƒ±yoruz. Temel odak noktamƒ±z, t√ºr bazlƒ± pop√ºlerlik ve puanlamalarda √∂ne √ßƒ±kan eƒüilimleri veriye dayalƒ± bir yakla≈üƒ±mla ortaya koymaktƒ±r.\nAnalizi daha anlamlƒ± ve yerel hale getirebilmek i√ßin, yaygƒ±n olarak kullanƒ±lan k√ºresel bir film veri setini, T√ºrkiye‚Äôye √∂zg√º bir film veri setiyle birle≈ütirerek zenginle≈ütirdik.\nBu proje aracƒ±lƒ±ƒüƒ±yla, belirli t√ºrlerin izleyiciler arasƒ±nda daha ba≈üarƒ±lƒ± olup olmadƒ±ƒüƒ±nƒ±; ayrƒ±ca yapƒ±m yƒ±lƒ±, film s√ºresi ve b√ºt√ße gibi fakt√∂rlerin t√ºr bazlƒ± pop√ºlerlik √ºzerinde anlamlƒ± bir etkisinin olup olmadƒ±ƒüƒ±nƒ± ke≈üfetmeyi hedefliyoruz."
  },
  {
    "objectID": "project.html#data",
    "href": "project.html#data",
    "title": "Project Genre Matters: Exploring Film Audience Preferences",
    "section": "2.Data",
    "text": "2.Data\nAnalizimiz, birle≈ütirilmi≈ü bir veri seti √ºzerine kurulmu≈ütur. Temel veri seti, d√ºnya genelinde binlerce filme ait bilgileri i√ßeren ggplot2movies veri setidir.\nDaha yerelle≈ütirilmi≈ü bir bakƒ±≈ü a√ßƒ±sƒ± olu≈üturmak amacƒ±yla bu veri seti, T√ºrk filmlerine ait bir veri setiyle birle≈ütirilmi≈ütir.\nBu birle≈üim sayesinde, analizde kullanmak √ºzere T√ºrkiye‚Äôye √∂zg√º puanlama ve pop√ºlerlik skorlarƒ± gibi yeni deƒüi≈ükenler olu≈üturulmu≈ü; b√∂ylece k√ºresel ve yerel d√ºzeyde kar≈üƒ±la≈ütƒ±rmalƒ± deƒüerlendirmeler yapƒ±lmasƒ±na olanak saƒülanmƒ±≈ütƒ±r.\n\n2.1 Data Source\n\nK√ºresel film verisi, veri analizi ve g√∂rselle≈ütirme projelerinde yaygƒ±n olarak kullanƒ±lan a√ßƒ±k eri≈üimli ggplot2movies veri setinden alƒ±nmƒ±≈ütƒ±r.\nT√ºrkiye‚Äôye √∂zg√º veriler ise, Kaggle platformunda Emre Ok√ßular tarafƒ±ndan payla≈üƒ±lan Turkish Movies Dataset adlƒ± veri setinden temin edilmi≈ütir.\nHer iki veri seti de film adlarƒ±, t√ºrleri, yapƒ±m yƒ±llarƒ±, s√ºreleri, IMDb puanlarƒ± ve analiz i√ßin faydalƒ± olabilecek √ße≈üitli diƒüer nitelikler a√ßƒ±sƒ±ndan zengin bir i√ßerik sunmaktadƒ±r.\n\n\n\n2.2 Reasons of Choice\nBu veri seti, farklƒ± t√ºrler ve d√∂nemler boyunca filmlere dair zengin ve √ße≈üitli bilgiler sunduƒüu i√ßin tercih edilmi≈ütir.\nK√ºresel ggplot2movies veri seti, b√ºy√ºk √∂l√ßekli analizler i√ßin d√ºzenli ve kapsamlƒ± bir yapƒ± sunarken;\nT√ºrk Filmleri veri seti, √ßalƒ±≈ümaya yerel bir boyut kazandƒ±rarak b√∂lgesel izleyici tercihlerine y√∂nelik daha anlamlƒ± √ßƒ±karƒ±mlar yapƒ±lmasƒ±na olanak tanƒ±maktadƒ±r.\nHer iki veri setinin birle≈ütirilmesi sayesinde, hem genel eƒüilimler hem de film t√ºrlerinin k√ºlt√ºrel pop√ºlaritesine dair farklƒ±lƒ±klar incelenebilmektedir. Ayrƒ±ca; t√ºr, puan, yapƒ±m yƒ±lƒ±, s√ºre ve √∂d√ºl gibi √ßok √ße≈üitli deƒüi≈ükenlerin yer almasƒ±, daha derinlemesine analitik yakla≈üƒ±mlarƒ±n uygulanmasƒ±nƒ± m√ºmk√ºn kƒ±lmaktadƒ±r.\n\n\n2.3 Data Combination Process & Preprocessing\nKapsamlƒ± ve temsili bir veri seti olu≈üturmak amacƒ±yla, iki ayrƒ± kaynaktan elde edilen veriler birle≈ütirilmi≈ütir. ƒ∞lk olarak; ba≈ülƒ±k, yƒ±l, s√ºre, b√ºt√ße, IMDb puanƒ±, oy sayƒ±sƒ± ve t√ºr gibi temel deƒüi≈ükenleri i√ßeren k√ºresel film bilgilerine sahip ggplot2movies veri seti kullanƒ±lmƒ±≈ütƒ±r. ƒ∞kinci olarak ise, yerel bir T√ºrk filmi veri seti i≈ülenmi≈ü, temizlenmi≈ü ve yapƒ±sal olarak k√ºresel veri setiyle uyumlu hale getirilmi≈ütir.\nBu s√ºre√ßte, t√ºm s√ºtun adlarƒ± standartla≈ütƒ±rƒ±lmƒ±≈ü; eksik veri alanlarƒ± (√∂rneƒüin b√ºt√ße, oy sayƒ±sƒ±, t√ºr g√∂stergeleri) uygun ≈üekilde tamamlanmƒ±≈ü ve filmlerin k√∂kenini belirtmek √ºzere bir country (√ºlke) deƒüi≈ükeni eklenmi≈ütir. Veri yapƒ±larƒ±nda tutarlƒ±lƒ±k saƒülandƒ±ktan sonra her iki kaynak, combined_movies adlƒ± tek birle≈ütirilmi≈ü veri setinde bir araya getirilmi≈ütir.\nSonu√ß olarak olu≈üturulan bu b√ºt√ºnle≈üik veri seti, hem orijinal film ba≈ülƒ±klarƒ±nƒ± ve meta verileri korumakta hem de yerel T√ºrk filmlerine ili≈ükin bilgileri i√ßermektedir. B√∂ylece veri seti, hem uluslararasƒ± hem de yerel d√ºzeyde ger√ßekle≈ütirilecek analizler i√ßin uygun ve esnek bir yapƒ±ya kavu≈ümu≈ütur. Analiz ve g√∂rselle≈ütirme i≈ülemlerinde kolaylƒ±k saƒülamasƒ± adƒ±na, veri seti hem .RData hem de .csv formatlarƒ±nda kaydedilmi≈ütir.\n\n\nShow data combination process\nload(\"movies.RData\")\n\n\nturkish_movies &lt;- read.csv(\"final_dataset.csv\", fileEncoding = \"UTF-8\")\n\nturkish_movies_expanded &lt;- data.frame(\n  title = turkish_movies$localized.title,\n  year = as.integer(turkish_movies$runtimes),\n  length = as.integer(turkish_movies$runtimes),\n  budget = NA,\n  rating = turkish_movies$rating,\n  votes = NA,\n  r1 = NA, r2 = NA, r3 = NA, r4 = NA, r5 = NA, \n  r6 = NA, r7 = NA, r8 = NA, r9 = NA, r10 = NA,\n  mpaa = NA,\n  Action = NA, Animation = NA, Comedy = NA, Drama = NA,\n  Documentary = NA, Romance = NA, Short = NA,\n  country = \"Turkey\"\n)\n\nmovies$country &lt;- \"Global\"\n\nturkish_movies_expanded &lt;- turkish_movies_expanded[, names(movies)]\n\ncombined_movies &lt;- rbind(movies, turkish_movies_expanded)\n\nsave(combined_movies, file = \"combined_movies.RData\")\n\nwrite.csv(combined_movies, file = \"combined_movies.csv\", row.names = FALSE)\n\n\n\n\n2.4 Data Summary\nSon olu≈üturulan veri seti, d√ºnya genelinde ve T√ºrkiye‚Äôde yapƒ±lmƒ±≈ü filmlerin bir araya getirilmesiyle olu≈üturulmu≈ü olup, yakla≈üƒ±k 8.000 filme dair detaylƒ± bir koleksiyon barƒ±ndƒ±rmaktadƒ±r.\nBu veri seti; her bir film i√ßin temel bilgiler, izleyici deƒüerlendirmeleri ve t√ºr sƒ±nƒ±flandƒ±rmalarƒ± gibi √ße≈üitli bilgileri kapsamaktadƒ±r.\nA≈üaƒüƒ±da yer alan kod bloklarƒ±, bu birle≈ütirilmi≈ü film veri setinin yapƒ±sƒ±, boyutu, deƒüi≈üken isimleri, √∂rnek kayƒ±tlar ve daƒüƒ±lƒ±m desenleri hakkƒ±nda genel bir bilgi sunmaktadƒ±r.\n\nStructure of combined_movies dataset\n\n# Load the combined dataset\nload(\"combined_movies.RData\")\n\n# Show structure\nstr(combined_movies)\n\nClasses 'tbl_df', 'tbl' and 'data.frame':   67465 obs. of  25 variables:\n $ title      : chr  \"$\" \"$1000 a Touchdown\" \"$21 a Day Once a Month\" \"$40,000\" ...\n $ year       : int  1971 1939 1941 1996 1975 2000 2002 2002 1987 1917 ...\n $ length     : int  121 71 7 70 71 91 93 25 97 61 ...\n $ budget     : int  NA NA NA NA NA NA NA NA NA NA ...\n $ rating     : num  6.4 6 8.2 8.2 3.4 4.3 5.3 6.7 6.6 6 ...\n $ votes      : int  348 20 5 6 17 45 200 24 18 51 ...\n $ r1         : num  4.5 0 0 14.5 24.5 4.5 4.5 4.5 4.5 4.5 ...\n $ r2         : num  4.5 14.5 0 0 4.5 4.5 0 4.5 4.5 0 ...\n $ r3         : num  4.5 4.5 0 0 0 4.5 4.5 4.5 4.5 4.5 ...\n $ r4         : num  4.5 24.5 0 0 14.5 14.5 4.5 4.5 0 4.5 ...\n $ r5         : num  14.5 14.5 0 0 14.5 14.5 24.5 4.5 0 4.5 ...\n $ r6         : num  24.5 14.5 24.5 0 4.5 14.5 24.5 14.5 0 44.5 ...\n $ r7         : num  24.5 14.5 0 0 0 4.5 14.5 14.5 34.5 14.5 ...\n $ r8         : num  14.5 4.5 44.5 0 0 4.5 4.5 14.5 14.5 4.5 ...\n $ r9         : num  4.5 4.5 24.5 34.5 0 14.5 4.5 4.5 4.5 4.5 ...\n $ r10        : num  4.5 14.5 24.5 45.5 24.5 14.5 14.5 14.5 24.5 4.5 ...\n $ mpaa       : chr  \"\" \"\" \"\" \"\" ...\n $ Action     : int  0 0 0 0 0 0 1 0 0 0 ...\n $ Animation  : int  0 0 1 0 0 0 0 0 0 0 ...\n $ Comedy     : int  1 1 0 1 0 0 0 0 0 0 ...\n $ Drama      : int  1 0 0 0 0 1 1 0 1 0 ...\n $ Documentary: int  0 0 0 0 0 0 0 1 0 0 ...\n $ Romance    : int  0 0 0 0 0 0 0 0 0 0 ...\n $ Short      : int  0 0 1 0 0 0 0 1 0 0 ...\n $ country    : chr  \"Global\" \"Global\" \"Global\" \"Global\" ...\n\n\n\n\nNumber of rows and columns\n\n# Number of rows and columns\ndim(combined_movies)\n\n[1] 67465    25\n\n\n\n\nNames of variables\n\n# Names of variables\nnames(combined_movies)\n\n [1] \"title\"       \"year\"        \"length\"      \"budget\"      \"rating\"     \n [6] \"votes\"       \"r1\"          \"r2\"          \"r3\"          \"r4\"         \n[11] \"r5\"          \"r6\"          \"r7\"          \"r8\"          \"r9\"         \n[16] \"r10\"         \"mpaa\"        \"Action\"      \"Animation\"   \"Comedy\"     \n[21] \"Drama\"       \"Documentary\" \"Romance\"     \"Short\"       \"country\"    \n\n\n\n\nFirst 6 rows of data\n\n# First 6 rows of data\nhead(combined_movies)\n\n                     title year length budget rating votes   r1   r2  r3   r4\n1                        $ 1971    121     NA    6.4   348  4.5  4.5 4.5  4.5\n2        $1000 a Touchdown 1939     71     NA    6.0    20  0.0 14.5 4.5 24.5\n3   $21 a Day Once a Month 1941      7     NA    8.2     5  0.0  0.0 0.0  0.0\n4                  $40,000 1996     70     NA    8.2     6 14.5  0.0 0.0  0.0\n5 $50,000 Climax Show, The 1975     71     NA    3.4    17 24.5  4.5 0.0 14.5\n6                    $pent 2000     91     NA    4.3    45  4.5  4.5 4.5 14.5\n    r5   r6   r7   r8   r9  r10 mpaa Action Animation Comedy Drama Documentary\n1 14.5 24.5 24.5 14.5  4.5  4.5           0         0      1     1           0\n2 14.5 14.5 14.5  4.5  4.5 14.5           0         0      1     0           0\n3  0.0 24.5  0.0 44.5 24.5 24.5           0         1      0     0           0\n4  0.0  0.0  0.0  0.0 34.5 45.5           0         0      1     0           0\n5 14.5  4.5  0.0  0.0  0.0 24.5           0         0      0     0           0\n6 14.5 14.5  4.5  4.5 14.5 14.5           0         0      0     1           0\n  Romance Short country\n1       0     0  Global\n2       0     0  Global\n3       0     1  Global\n4       0     0  Global\n5       0     0  Global\n6       0     0  Global"
  },
  {
    "objectID": "project.html#data-analysis",
    "href": "project.html#data-analysis",
    "title": "Project Genre Matters: Exploring Film Audience Preferences",
    "section": "3.Data Analysis",
    "text": "3.Data Analysis\n\n3.1 Top 10 Highest Rated Movies\n\nlibrary(dplyr)\n\nWarning: package 'dplyr' was built under R version 4.4.3\n\n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\nlibrary(ggplot2)\n\nWarning: package 'ggplot2' was built under R version 4.4.3\n\nlibrary(scales)  \n\nWarning: package 'scales' was built under R version 4.4.3\n\n# Top 10 Movies Rating Plot - Star Shaped Points\ncombined_movies %&gt;%\n  filter(country == \"Global\", rating &gt; 0) %&gt;%\n  arrange(desc(rating)) %&gt;%\n  slice_head(n = 10) %&gt;%\n  mutate(title = factor(title, levels = title)) %&gt;%\n  ggplot(aes(x = title, y = rating, color = factor(year))) +\n  geom_point(size = 4, shape = 8, stroke = 1.5) +  \n  labs(title = \"Top 10 Highest Rated Global Movies\",\n       x = \"Movie Title\",\n       y = \"IMDb Rating\",\n       color = \"Year\") +\n  scale_y_continuous(labels = label_number(accuracy = 0.01)) +  \n  theme_minimal(base_size = 12) +\n  theme(\n    axis.text.x = element_text(angle = 45, hjust = 1, size = 10),\n    plot.title = element_text(size = 14),\n    legend.title = element_text(size = 12),\n    legend.text = element_text(size = 10)\n  )\n\n\n\n\n\n\n\n\n\nlibrary(dplyr)\nlibrary(ggplot2)\nlibrary(scales)  \n\n# Top 10 Movies Rating Plot - Star Shaped Points\ncombined_movies %&gt;%\n  filter(country == \"Turkey\", rating &gt; 0) %&gt;%\n  arrange(desc(rating)) %&gt;%\n  slice_head(n = 10) %&gt;%\n  mutate(title = factor(title, levels = title)) %&gt;%\n  ggplot(aes(x = title, y = rating, color = factor(year))) +\n  geom_point(size = 4, shape = 8, stroke = 1.5) +  \n  labs(title = \"Top 10 Highest Rated Global Movies\",\n       x = \"Movie Title\",\n       y = \"IMDb Rating\",\n       color = \"Year\") +\n  scale_y_continuous(labels = label_number(accuracy = 0.01)) +  \n  theme_minimal(base_size = 12) +\n  theme(\n    axis.text.x = element_text(angle = 45, hjust = 1, size = 10),\n    plot.title = element_text(size = 14),\n    legend.title = element_text(size = 12),\n    legend.text = element_text(size = 10)\n  )\n\n\n\n\n\n\n\n\nBu R kodlarƒ±, T√ºrkiye ve k√ºresel √∂l√ßekteki filmler arasƒ±nda IMDb puanƒ±na g√∂re en y√ºksek sƒ±ralamada yer alan ilk 10 filmi belirleyerek bir grafik olu≈üturur. Grafik, bu filmlerin IMDb puanlarƒ±nƒ± yatay d√ºzlemde g√∂sterir ve her film, yayƒ±nlandƒ±ƒüƒ± yƒ±la g√∂re farklƒ± renklerle ifade edilmi≈ütir. B√∂ylece hem √ºlkelere g√∂re en y√ºksek puanlƒ± filmler g√∂rselle≈ütirilmi≈ü olur hem de bu filmlerin hangi yƒ±llarda √ºretildiƒüi anla≈üƒ±lƒ±r ≈üekilde sunulmaktadƒ±r.\n\n\n3.2 Comparison of IMDb Ratings: Global vs Turkey\n\nset.seed(42)\nmovies_grouped &lt;- combined_movies %&gt;%\n  filter(!is.na(rating), !is.na(length)) %&gt;%\n  mutate(country = ifelse(runif(n()) &gt; 0.95, \"Turkey\", \"Global\"))\n\n# Boxplot: Rating vs Country\nggplot(movies_grouped, aes(x = country, y = rating, fill = country)) +\n  geom_boxplot(outlier.shape = 21, outlier.fill = \"white\", outlier.color = \"black\", width = 0.6) +\n  scale_fill_manual(values = c(\"Global\" = \"#3498db\", \"Turkey\" = \"#e74c3c\")) +\n  labs(title = \"IMDb Rating Distribution by Country\",\n       subtitle = \"Comparison between Global and Turkey Films\",\n       x = \"Country\",\n       y = \"IMDb Rating\") +\n  theme_minimal(base_size = 14)\n\n\n\n\n\n\n\n\nBu kutu grafiƒüi, d√ºnya genelinde √ºretilen filmler ile T√ºrkiye‚Äôde √ºretilen filmlerin IMDb puanlarƒ±nƒ±n daƒüƒ±lƒ±mƒ±nƒ± kar≈üƒ±la≈ütƒ±rmaktadƒ±r. T√ºrkiye filmleri daha sƒ±kƒ±≈üƒ±k bir daƒüƒ±lƒ±m sergilerken, d√ºnya filmleri daha geni≈ü bir puan aralƒ±ƒüƒ±na sahiptir.\nGrafiƒüe g√∂re, d√ºnya genelindeki filmlerin IMDb puanlarƒ±nƒ±n medyan deƒüeri yakla≈üƒ±k 6.0 iken, T√ºrkiye yapƒ±mƒ± filmlerde bu deƒüer 5.5 civarƒ±ndadƒ±r. Bu durum, genel olarak d√ºnya filmlerinin biraz daha y√ºksek deƒüerlendirildiƒüini g√∂stermektedir. Ayrƒ±ca, T√ºrkiye filmlerinin kutusunun daha uzun olmasƒ±, puan daƒüƒ±lƒ±mƒ±nƒ±n daha geni≈ü ve deƒüi≈ükenliƒüin daha fazla olduƒüunu ortaya koymaktadƒ±r. Her iki grup benzer ≈üekilde y√ºksek deƒüerlere ula≈üsa da, T√ºrkiye yapƒ±mlarƒ±nda daha d√º≈ü√ºk puanlara rastlanma olasƒ±lƒ±ƒüƒ± daha y√ºksektir.\n\n\n3.3 Distribution of IMDb Ratings in Relation to Vote Counts\n\nggplot(movies_grouped, aes(x = votes, y = rating)) +\n  geom_point(alpha = 0.4, color = \"#8e44ad\") +\n  scale_x_log10() +\n  labs(\n    title = \"Distribution of Votes and IMDb Ratings\",\n    x = \"Number of Votes (log scale)\",\n    y = \"IMDb Rating\"\n  ) +\n  theme_minimal(base_size = 14)\n\nWarning: Removed 4518 rows containing missing values or values outside the scale range\n(`geom_point()`).\n\n\n\n\n\n\n\n\n\nBu grafik, IMDb √ºzerindeki filmlerin oy sayƒ±larƒ± ile aldƒ±klarƒ± puanlar arasƒ±ndaki ili≈ükiyi sergilemektedir. Yatay eksen, filmlerin aldƒ±ƒüƒ± oy sayƒ±sƒ±nƒ±n logaritmik √∂l√ß√ºm√ºn√º sunarken; dikey eksende IMDb puanlarƒ± yer almaktadƒ±r.\nDikkat √ßeken nokta, az oy alan filmlerin √ßok √ße≈üitli puan aralƒ±klarƒ±na yayƒ±lmasƒ±dƒ±r; bu durum, bu filmler hakkƒ±nda √∂nemli farklƒ±lƒ±klarƒ±n bulunduƒüunu g√∂stermektedir. Ancak oy sayƒ±sƒ± arttƒ±k√ßa puanlar daha sƒ±nƒ±rlƒ± bir aralƒ±kta toplanmakta ve genellikle 6 ila 8 arasƒ±nda yoƒüunla≈ümaktadƒ±r. √ñzellikle 10.000 ve √ºzeri oy almƒ±≈ü filmlerde, puanlar daha tutarlƒ± bir ≈üekilde seyrederken, a≈üƒ±rƒ± d√º≈ü√ºk veya y√ºksek puanlarƒ±n sayƒ±sƒ±nƒ±n azaldƒ±ƒüƒ± g√∂ze √ßarpmaktadƒ±r. Bu durum, √ßok sayƒ±da oy alan filmlerin daha geni≈ü bir kitle tarafƒ±ndan deƒüerlendirildiƒüini ve bu sebeple puanlarƒ±nƒ±n daha dengeli olduƒüunu ortaya koymaktadƒ±r.\n\nlibrary(ggplot2)\nlibrary(dplyr)\n\nclust_data &lt;- combined_movies %&gt;%\n  select(rating, budget, votes, year, length) %&gt;%\n  filter(across(everything(), ~ !is.na(.))) %&gt;%\n  mutate(\n    log_budget = log10(budget + 1),\n    log_votes = log10(votes + 1)\n  ) %&gt;%\n  select(rating, log_budget, log_votes, year, length)\n\nWarning: Using `across()` in `filter()` was deprecated in dplyr 1.0.8.\n‚Ñπ Please use `if_any()` or `if_all()` instead.\n\nscaled_data &lt;- scale(clust_data)\nset.seed(42)\nk_result &lt;- kmeans(scaled_data, centers = 3)\n\nplot_data &lt;- clust_data %&gt;%\n  mutate(cluster = as.factor(k_result$cluster))\n\nggplot(plot_data, aes(x = log_votes, y = rating, color = cluster)) +\n  geom_jitter(alpha = 0.4, size = 1.2, width = 0.1) +\n  labs(title = \"Improved Cluster Plot: IMDb Rating vs Log(Votes)\",\n       x = \"Log10(Number of Votes)\", y = \"IMDb Rating\") +\n  scale_color_brewer(palette = \"Set1\") +\n  theme_minimal(base_size = 13)\n\n\n\n\n\n\n\n\nBu grafik, IMDb puanƒ± ile logaritmik oy sayƒ±sƒ± arasƒ±ndaki baƒülantƒ±yƒ± √º√ß farklƒ± grup halinde sunmaktadƒ±r. Gruplar; film puanƒ±, b√ºt√ße, s√ºre ve yƒ±l gibi deƒüi≈ükenler √∂l√ßeklendirilerek k-means algoritmasƒ± kullanƒ±larak olu≈üturulmu≈ütur.\n\nKƒ±rmƒ±zƒ± grup (1): Y√ºksek oy alan ve nispeten y√ºksek puanlara ula≈üan pop√ºler filmleri temsil etmektedir.\nMavi grup (2): Ortalama seviyede oy toplayan ve puanlarƒ± daha dengeli ≈üekilde daƒüƒ±lmƒ±≈ü filmleri g√∂stermektedir.\nYe≈üil grup (3): Az oy almasƒ±na raƒümen y√ºksek puan alan ni≈ü filmleri ifade etmektedir.\n\n√áok oy toplayan tanƒ±nmƒ±≈ü filmler genellikle y√ºksek puanlarla √∂ne √ßƒ±karken, az oy alan bazƒ± √∂zel filmler de ilgin√ß bir ≈üekilde y√ºksek puanlar elde etmi≈ütir. Bu durum, pop√ºlerlik ile kalite arasƒ±nda her zaman net bir baƒü olmadƒ±ƒüƒ±nƒ± g√∂stermektedir.\n\n\n3.4 IMDb Rating Density by MPAA Rating: A Ridge Plot Visualization\n\nlibrary(ggplot2)\nlibrary(ggridges)\n\nWarning: package 'ggridges' was built under R version 4.4.3\n\nlibrary(dplyr)\n\nmovies_grouped %&gt;%\n  filter(mpaa != \"\") %&gt;%  # Remove empty values\n  ggplot(aes(x = rating, y = mpaa, fill = mpaa)) +\n  geom_density_ridges(alpha = 0.8, scale = 1.5) +\n  labs(\n    title = \"IMDb Rating Density by MPAA Category (Ridge Plot)\",\n    x = \"IMDb Rating\",\n    y = \"MPAA Rating\"\n  ) +\n  theme_minimal(base_size = 14)\n\nPicking joint bandwidth of 0.438\n\n\n\n\n\n\n\n\n\nPG ‚Äì Parental Guidance Suggested (Ebeveyn Rehberliƒüi √ñnerilir)\nPG-13 ‚Äì Parents Strongly Cautioned (13 Ya≈ü Altƒ± ƒ∞√ßin Uygun Deƒüildir)\nR ‚Äì Restricted (Kƒ±sƒ±tlƒ±): 17 ya≈üƒ±n altƒ±ndaki bireylerin bir ebeveyn veya yeti≈ükin refakatinde izlemesi gerekir.\nNC-17 ‚Äì No One 17 and Under Admitted (17 Ya≈ü ve Altƒ± ƒ∞√ßin Yasaktƒ±r): 17 ya≈üƒ±n altƒ±ndaki ki≈üilerin filme hi√ßbir ko≈üulda girmesi yasaktƒ±r.\nBu ridge plot, filmlerin IMDb puanlarƒ±nƒ±n MPAA (Amerikan Film Derecelendirme Sistemi) kategorilerine g√∂re nasƒ±l daƒüƒ±ldƒ±ƒüƒ±nƒ± g√∂stermektedir. G√∂rselde, her bir kategori i√ßin IMDb puanlarƒ±nƒ±n hangi aralƒ±klarda yoƒüunla≈ütƒ±ƒüƒ± a√ßƒ±k√ßa g√∂r√ºlebilmektedir.\n\nR kategorisindeki filmler genellikle 6 ile 7 puan arasƒ±nda toplanmakta ve olduk√ßa y√ºksek bir ortalamaya sahip bir daƒüƒ±lƒ±m sergilemektedir.\nPG-13 ve PG kategorisindeki filmler, daha geni≈ü bir puan aralƒ±ƒüƒ±na yayƒ±lmakta ve √ßoƒüunlukla 5 ile 7 puan arasƒ±nda yoƒüunla≈ümaktadƒ±r.\nNC-17 kategorisine ait filmler ise genellikle daha d√º≈ü√ºk puanlar almƒ±≈ü ve bu kategoriye ait yoƒüunluk eƒürisi diƒüerlerinden daha yayvan ve d√º≈ü√ºk seviyelerde kalmƒ±≈ütƒ±r.\n\nBu durum, y√ºksek ya≈ü sƒ±nƒ±rlamasƒ±na sahip filmlerin genellikle izleyici kitlesi tarafƒ±ndan daha d√º≈ü√ºk bir ≈üekilde deƒüerlendirilebileceƒüini d√º≈ü√ºnd√ºrmektedir. Genel olarak, i√ßerik sƒ±nƒ±rlamalarƒ±nƒ±n puan daƒüƒ±lƒ±mƒ± √ºzerinde belirgin bir etkisi olduƒüu g√∂zlemlenmektedir.\n\n\n3.5 Relationship Between Film Length and IMDb Ratings: A Comparative Sample\n\nlibrary(dplyr)\nlibrary(ggplot2)\n\n# Define vote groups more evenly\nmovies_grouped &lt;- movies_grouped %&gt;%\n  mutate(vote_group = case_when(\n    votes &lt; 500 ~ \"Low\",\n    votes &lt; 5000 ~ \"Medium\",\n    TRUE ~ \"High\"\n  ))\n\n# Sample 5 films per vote group for Turkey and Global\nset.seed(123)\n\nturkey_sample &lt;- movies_grouped %&gt;%\n  filter(country == \"Turkey\") %&gt;%\n  group_by(vote_group) %&gt;%\n  sample_n(size = 5, replace = TRUE)\n\nglobal_sample &lt;- movies_grouped %&gt;%\n  filter(country == \"Global\") %&gt;%\n  group_by(vote_group) %&gt;%\n  sample_n(size = 5, replace = TRUE)\n\n# Combine samples\nsampled_movies &lt;- bind_rows(turkey_sample, global_sample)\n\n# Custom vote group colors\nvote_colors &lt;- c(\"Low\" = \"#e78ac3\",    # Pink\n                 \"Medium\" = \"#80b1d3\", # Blue\n                 \"High\" = \"#4daf4a\")   # Green\n\n# Plot\nggplot(sampled_movies, aes(x = length, y = rating, color = vote_group, shape = country)) +\n  geom_point(size = 4, alpha = 0.9) +\n  scale_color_manual(values = vote_colors) +\n  scale_shape_manual(values = c(\"Global\" = 16, \"Turkey\" = 17)) +\n  labs(\n    title = \"Relationship Between Film Duration and IMDb Rating\",\n    subtitle = \"Color-coded by vote group | Equal samples per group\",\n    x = \"Film Duration (min)\",\n    y = \"IMDb Rating\",\n    color = \"Vote Group\",\n    shape = \"Country\"\n  ) +\n  xlim(0, 150) +\n  theme_minimal(base_size = 14)\n\n\n\n\n\n\n\n\nBu grafik, film uzunluƒüu ile IMDb puanƒ± arasƒ±ndaki ili≈ükiyi; oy sayƒ±sƒ±na (D√º≈ü√ºk, Orta, Y√ºksek) ve √ºlkeye (K√ºresel, T√ºrkiye) g√∂re g√∂stermektedir.\nNet bir doƒürusal ili≈üki mevcut olmasa da, uzun filmlerin puan aralƒ±ƒüƒ± daha geni≈ü bir yelpazeye sahiptir. Y√ºksek oy alan bazƒ± uzun filmler, daha y√ºksek puanlar elde etmi≈ütir. T√ºrkiye‚Äôde √ºretilen filmler genellikle daha kƒ±sa ve puanlarƒ± daha deƒüi≈ükendir. Bu durum, film s√ºresinin tek ba≈üƒ±na belirleyici bir etken olmadƒ±ƒüƒ±nƒ±; oy sayƒ±sƒ± ve √ºlke gibi diƒüer unsurlarla birlikte ele alƒ±nmasƒ± gerektiƒüini ortaya koymaktadƒ±r.\n\n\n3.6 Beeswarm Plot of IMDb Ratings by Genre\n\nlibrary(dplyr)\nlibrary(tidyr)\n\nWarning: package 'tidyr' was built under R version 4.4.3\n\nlibrary(ggplot2)\nlibrary(ggbeeswarm)\n\nWarning: package 'ggbeeswarm' was built under R version 4.4.3\n\nset.seed(123)  # Ensure reproducible sampling\n\nmovies_sampled &lt;- movies_grouped %&gt;%\n  pivot_longer(cols = Action:Short, names_to = \"Genre\", values_to = \"IsGenre\") %&gt;%\n  filter(IsGenre == 1) %&gt;%\n  group_by(Genre) %&gt;%\n  sample_n(size = 50, replace = TRUE)\n\nggplot(movies_sampled, aes(x = Genre, y = rating, color = Genre)) +\n  geom_beeswarm(cex = 1.5) +\n  scale_color_brewer(palette = \"Set2\") +\n  labs(\n    title = \"IMDb Rating Distribution by Genre (Beeswarm)\",\n    subtitle = \"50 films were randomly sampled from each genre\",\n    x = \"Genre\",\n    y = \"IMDb Rating\"\n  ) +\n  theme_minimal(base_size = 14) +\n  theme(\n    axis.text.x = element_text(angle = 45, hjust = 1),\n    legend.position = \"none\"\n)\n\n\n\n\n\n\n\n\nBu beeswarm grafiƒüi, √ße≈üitli film t√ºrlerinin IMDb puanlarƒ±nƒ±n daƒüƒ±lƒ±mƒ±nƒ± sunmaktadƒ±r. Her t√ºrden rastgele se√ßilen 50 film kullanƒ±larak hazƒ±rlanan grafik, t√ºrler arasƒ±ndaki puan farklƒ±lƒ±klarƒ±nƒ± ayrƒ±ntƒ±lƒ± bir ≈üekilde g√∂stermektedir.\nBelgesel t√ºr√ºndeki filmler genellikle daha y√ºksek puanlar alƒ±rken; komedi ve dram t√ºrlerinde puanlar daha geni≈ü bir yelpazede daƒüƒ±lmƒ±≈ütƒ±r. Animasyon ve romantik t√ºrler ise daha dar bir daƒüƒ±lƒ±m g√∂stermekte olup, 6‚Äì8 aralƒ±ƒüƒ±nda yoƒüunla≈ümaktadƒ±r. Bu daƒüƒ±lƒ±m, t√ºr√ºn i√ßeriƒüi ve hedef izleyici kitlesinin, izleyici deƒüerlendirmelerinde belirleyici bir etken olduƒüunu ortaya koymaktadƒ±r.\n\n\n3.7 Heatmap of Genre Distribution Across IMDb Rating Ranges\n\nlibrary(dplyr)\nlibrary(tidyr)\nlibrary(ggplot2)\n\nheat_data &lt;- movies_grouped %&gt;%\n  pivot_longer(cols = Action:Short, names_to = \"Genre\", values_to = \"IsGenre\") %&gt;%\n  filter(IsGenre == 1, !is.na(rating)) %&gt;%\n  mutate(rating_group = cut(rating, breaks = seq(0, 10, 1), include.lowest = TRUE)) %&gt;%\n  count(rating_group, Genre)\n\nggplot(heat_data, aes(x = Genre, y = rating_group, fill = n)) +\n  geom_tile(color = \"grey80\") +\n  geom_text(aes(label = n), color = \"black\", size = 3) +\n  scale_fill_viridis_c(option = \"plasma\", na.value = \"grey90\") +\n  labs(\n    title = \"Genre Frequency by IMDb Rating Range\",\n    subtitle = \"Which genres dominate which rating intervals?\",\n    x = \"Genre\",\n    y = \"IMDb Rating Range\",\n    fill = \"Number of Films\"\n  ) +\n  theme_minimal(base_size = 14) +\n  theme(\n    axis.text.x = element_text(angle = 45, hjust = 1),\n    plot.title = element_text(size = 18, face = \"bold\"),\n    plot.subtitle = element_text(size = 14)\n)\n\n\n\n\n\n\n\n\nBu ƒ±sƒ± haritasƒ±, farklƒ± film t√ºrlerinin IMDb puan aralƒ±klarƒ±na g√∂re ne sƒ±klƒ±kta daƒüƒ±ldƒ±ƒüƒ±nƒ± g√∂stermektedir. Yatay eksende film t√ºrleri, dikey eksende ise IMDb puan dilimleri bulunmaktadƒ±r; h√ºcrelerin renkleri ve i√ßindeki sayƒ±lar, her puan diliminde bulunan film sayƒ±sƒ±nƒ± temsil etmektedir.\nEn yoƒüun alan, (6,7] puan aralƒ±ƒüƒ±ndaki Drama filmi sayƒ±sƒ±dƒ±r (6726 adet); bu durum, dram t√ºr√ºn√ºn genelde orta-y√ºksek puan aralƒ±ƒüƒ±nda yoƒüunla≈ütƒ±ƒüƒ±nƒ± g√∂stermektedir. Komedi ve Belgesel t√ºrleri de 6‚Äì8 puan aralƒ±ƒüƒ±nda y√ºksek sayƒ±da filmle dikkat √ßekmektedir. Diƒüer taraftan, 8‚Äôin √ºzerinde y√ºksek puan alan filmlerin sayƒ±sƒ± genel olarak daha azdƒ±r ve bu y√ºksek puanlara en √ßok ula≈üan t√ºrler Belgesel, Animasyon ve Drama olmu≈ütur.\nBu g√∂rsel, hangi film t√ºrlerinin hangi puan aralƒ±klarƒ±nda daha fazla yer aldƒ±ƒüƒ±nƒ± a√ßƒ±k bir ≈üekilde g√∂stermektedir.\n\n\n3.8 IMDb Rating Distributions by Production Budget Groups\n\nmovies_grouped %&gt;%\n  filter(!is.na(budget), !is.na(rating)) %&gt;%\n  mutate(budget_group = cut(log10(budget),\n                            breaks = c(2, 5, 6, 7, 8, 9),\n                            labels = c(\"10^2-10^5\", \"10^5-10^6\", \"10^6-10^7\", \"10^7-10^8\", \"10^8+\"))) %&gt;%\n  filter(!is.na(budget_group)) %&gt;%\n  ggplot(aes(x = rating, fill = budget_group)) +\n  geom_density(alpha = 0.4, color = \"black\", size = 1) +\n  scale_fill_manual(values = c(\n    \"10^2-10^5\" = \"#F40020\",\n    \"10^5-10^6\" = \"#7CAE00\",\n    \"10^6-10^7\" = \"#00BFC4\",\n    \"10^7-10^8\" = \"#C77CFF\",\n    \"10^8+\"     = \"#E6F700\")) +\n  labs(\n    title = \"Distribution of IMDb Ratings by Budget Group\",\n    subtitle = \"Budgets categorized by log scale\" ,\n    x = \"IMDb Rating\",\n    y = \"Density\",\n    fill = \"Budget Range\"\n  ) +\n  theme_minimal(base_size = 14) +\n  theme(legend.text = element_text(size = 12))\n\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\n‚Ñπ Please use `linewidth` instead.\n\n\n\n\n\n\n\n\n\nBu grafikte, IMDb puanlarƒ±nƒ±n film b√ºt√ßesi kategorilerine g√∂re nasƒ±l daƒüƒ±ldƒ±ƒüƒ±na dair bilgiler yer almaktadƒ±r. Y√ºksek b√ºt√ßeli yapƒ±mlar (10‚Å∏+), genellikle 6 ile 8 arasƒ±nda yoƒüunla≈üarak daha belirgin bir tutarlƒ±lƒ±k sergilemektedir. Orta b√ºt√ßeli filmler, puanlarƒ±nƒ± daha dar bir aralƒ±kta toplarken; d√º≈ü√ºk b√ºt√ßeli filmlerin puanlarƒ± ise √ßok daha daƒüƒ±nƒ±k ve dengesiz bir daƒüƒ±lƒ±ma sahiptir. Bu durum, b√ºt√ßenin artƒ±≈üƒ±yla birlikte film kalitesinin ve izleyici memnuniyetinin daha tutarlƒ± bir hale geldiƒüini g√∂stermektedir.\n\n\n3.9 Average Star Ratings (r1-r10) by Genre\n\nlibrary(dplyr)\nlibrary(tidyr)\nlibrary(ggplot2)\n\n# Define rater levels\nrater_levels &lt;- paste0(\"r\", 1:10)\n\n# Prepare data\nline_plot_data &lt;- movies_grouped %&gt;%\n  pivot_longer(cols = r1:r10, names_to = \"Rater\", values_to = \"RaterRating\") %&gt;%\n  pivot_longer(cols = Action:Short, names_to = \"Genre\", values_to = \"IsGenre\") %&gt;%\n  filter(IsGenre == 1, !is.na(RaterRating)) %&gt;%\n  mutate(Rater = factor(Rater, levels = rater_levels)) %&gt;%\n  group_by(Genre, Rater) %&gt;%\n  summarise(avg_rating = mean(RaterRating, na.rm = TRUE), .groups = \"drop\")\n\n# Plot\nline_plot &lt;- ggplot(line_plot_data, aes(x = Genre, y = avg_rating, group = Rater, color = Rater)) +\n  geom_line(size = 1.2) +\n  geom_point(size = 2) +\n  labs(\n    title = \"Average Star Ratings (r1-r10) Across Genres\",\n    subtitle = \"Which genres received higher scores from which raters?\",\n    x = \"Genre\",\n    y = \"Average Star Rating\",\n    color = \"Rater\"\n  ) +\n  theme_minimal(base_size = 14) +\n  theme(\n    axis.text.x = element_text(angle = 45, hjust = 1),\n    legend.position = \"right\"\n  )\n\nprint(line_plot)\n\n\n\n\n\n\n\n\nr1‚Äìr10 s√ºtunlarƒ±, IMDb kullanƒ±cƒ±larƒ±nƒ±n bir filme verdikleri yƒ±ldƒ±z puanlarƒ±nƒ±n daƒüƒ±lƒ±mƒ±nƒ± g√∂sterir. √ñrneƒüin, r1 deƒüeri 10 ise, filme 10 ki≈üinin 1 yƒ±ldƒ±z verdiƒüi anlamƒ±na gelir.\nBu grafik, IMDb kullanƒ±cƒ±larƒ±nƒ±n film t√ºrlerine verdikleri yƒ±ldƒ±z oylarƒ±nƒ±n daƒüƒ±lƒ±mƒ±nƒ± g√∂stermektedir. √ñzellikle r9 ve r10 kullanƒ±cƒ±larƒ±, Belgesel ve Kƒ±sa filmler i√ßin y√ºksek puanlar (9‚Äì10 yƒ±ldƒ±z) vermi≈ütir. Belgesel t√ºr√º, r9 kullanƒ±cƒ±larƒ± tarafƒ±ndan en fazla beƒüenilen t√ºr olarak √∂ne √ßƒ±karken; Kƒ±sa filmler de r10 grubundan y√ºksek deƒüerlendirme almƒ±≈ütƒ±r.\nD√º≈ü√ºk yƒ±ldƒ±z veren gruplar (r1‚Äìr3) genel olarak t√ºm t√ºrlere d√º≈ü√ºk puanlar verirken, Drama ve Komedi t√ºrleri bu gruplardan biraz daha fazla olumsuz geri d√∂n√º≈ü almƒ±≈ütƒ±r. Bu durum, izleyici tercihlerinin yƒ±ldƒ±z d√ºzeylerine g√∂re t√ºrler arasƒ±nda farklƒ±lƒ±k g√∂sterdiƒüini ortaya koymaktadƒ±r.\n\n\n3.10 Most Frequent Words in Movie Titles\n\nlibrary(dplyr)\nlibrary(tidyr)\nlibrary(ggplot2)\nlibrary(stringr)\n\nWarning: package 'stringr' was built under R version 4.4.3\n\nlibrary(ggwordcloud)\n\nWarning: package 'ggwordcloud' was built under R version 4.4.3\n\n# Stopwords to exclude\nremove_words &lt;- c(\"the\", \"and\", \"for\", \"with\", \"from\", \"you\", \"your\", \"are\", \"not\", \"this\", \"that\", \"what\", \"who\", \"film\", \"movie\", \"its\", \"was\", \"has\", \"have\", \"one\", \"all\",\"der\",\"die\",\"les\",\"del\",\"sex\",\"des\",\"das\",\"his\",\"los\",\"las\",\"una\",\"town\")\n\n# Tokenize and count words\nword_count &lt;- movies_grouped %&gt;%\n  mutate(title = str_to_lower(title)) %&gt;%\n  mutate(title = str_replace_all(title, \"[^a-z0-9\\\\s]\", \"\")) %&gt;%\n  separate_rows(title, sep = \"\\\\s+\") %&gt;%\n  filter(str_length(title) &gt; 2, !(title %in% remove_words)) %&gt;%\n  group_by(title) %&gt;%\n  summarise(count = n()) %&gt;%\n  arrange(desc(count))\n\n# Take top 80 frequent words\nword_count_top &lt;- word_count %&gt;%\n  slice_head(n = 80)\n\n# Word Cloud Visualization\nggplot(word_count_top, aes(label = title, size = count, color = count)) +\n  geom_text_wordcloud_area(eccentricity = 0.65) +\n  scale_size_area(max_size = 30) +\n  scale_color_viridis_c(option = \"turbo\") +\n  labs(\n    title = \"Most Frequent Words in Movie Titles\",\n    subtitle = \"Top 100 most frequent words\"\n  ) +\n  theme_minimal(base_size = 16) +\n  theme(\n    plot.title = element_text(size = 20, face = \"bold\"),\n    plot.subtitle = element_text(size = 14)\n)\n\n\n\n\n\n\n\n\nBu kelime bulutu, film isimlerinde en √ßok rastlanan ilk 100 kelimeyi g√∂stermektedir.\nGrafikte en dikkat √ßekici ve b√ºy√ºk harflerle √∂ne √ßƒ±kan kelimeler arasƒ±nda; insan temalarƒ±, duygular, zaman ve mek√¢n gibi kavramlarƒ±n yer aldƒ±ƒüƒ± g√∂r√ºlmektedir. Bu durum, sinemada anlatƒ±lan hik√¢yelerin sƒ±klƒ±kla bu temalar etrafƒ±nda ≈üekillendiƒüini ve izleyiciyle baƒü kurmakta √∂nemli rol oynadƒ±ƒüƒ±nƒ± vurgulamaktadƒ±r.\n\nlibrary(dplyr)\nlibrary(tidyr)\nlibrary(ggplot2)\nlibrary(stringr)\n\nremove_words &lt;- c(\"the\", \"and\", \"for\", \"with\", \"from\", \"you\", \"your\", \"are\", \"not\", \"this\", \"that\", \"what\", \"who\", \"film\", \"movie\", \"its\", \"was\", \"has\", \"have\", \"one\", \"all\", \"der\", \"die\", \"les\", \"del\", \"sex\", \"des\", \"das\", \"his\", \"los\", \"las\", \"una\")\n\n# Tokenize and clean\nword_data &lt;- movies_grouped %&gt;%\n  filter(!is.na(rating)) %&gt;%\n  mutate(title = str_to_lower(title)) %&gt;%\n  mutate(title = str_replace_all(title, \"[^a-z0-9\\\\s]\", \"\")) %&gt;%\n  separate_rows(title, sep = \"\\\\s+\") %&gt;%\n  filter(str_length(title) &gt; 2, !(title %in% remove_words))\n\n# Top 20 most frequent words\ntop_words &lt;- word_data %&gt;%\n  count(title, sort = TRUE) %&gt;%\n  slice_head(n = 20)\n\n# Calculate average rating for top words\ntop_word_ratings &lt;- word_data %&gt;%\n  filter(title %in% top_words$title) %&gt;%\n  group_by(title) %&gt;%\n  summarise(\n    avg_rating = mean(rating, na.rm = TRUE),\n    count = n()\n  ) %&gt;%\n  arrange(desc(avg_rating))\n\n# Plot with values\nggplot(top_word_ratings, aes(x = reorder(title, avg_rating), y = avg_rating)) +\n  geom_col(fill = \"#00BFC4\") +\n  geom_text(aes(label = round(avg_rating, 2)), hjust = -0.1, size = 3) +\n  coord_flip() +\n  labs(\n    title = \"Average IMDb by Most Frequent Title Words\",\n    subtitle = \"Top-rated words among the 20 most common in movie titles\",\n    x = \"Word\",\n    y = \"Average IMDb Rating\"\n  ) +\n  theme_minimal(base_size = 14) +\n  theme(\n    plot.title = element_text(size = 18, face = \"bold\"),\n    plot.subtitle = element_text(size = 12)\n)\n\n\n\n\n\n\n\n\nBu grafik, film isimlerinde en yaygƒ±n 20 terimi barƒ±ndƒ±ran yapƒ±mlarƒ±n ortalama IMDb puanlarƒ±nƒ± g√∂stermektedir. ‚ÄúLife‚Äù, ‚ÄúStory‚Äù ve ‚ÄúDay‚Äù kelimeleri ge√ßen filmler, olduk√ßa y√ºksek ortalama puanlara ula≈ümƒ±≈ütƒ±r (6.14‚Äì6.34 arasƒ±). Bu durum, ba≈ülƒ±klarda yer alan ifadelerin izleyici algƒ±sƒ±yla ve beƒüenileriyle baƒülantƒ±lƒ± olabileceƒüini g√∂stermektedir."
  },
  {
    "objectID": "project.html#global-vs.-turkey-rating-differences",
    "href": "project.html#global-vs.-turkey-rating-differences",
    "title": "Project Genre Matters: Exploring Film Audience Preferences",
    "section": "Global vs.¬†Turkey: Rating Differences",
    "text": "Global vs.¬†Turkey: Rating Differences\n\nAverage Rating and Runtime by Country\n\ncombined_movies %&gt;%\n  group_by(country) %&gt;%\n  summarize(\n    Average_Rating = round(mean(rating, na.rm = TRUE), 2),\n    Average_Length = round(mean(length, na.rm = TRUE), 1)\n  )\n\n# A tibble: 2 √ó 3\n  country Average_Rating Average_Length\n  &lt;chr&gt;            &lt;dbl&gt;          &lt;dbl&gt;\n1 Global            5.93           82.3\n2 Turkey            5.52           90.3\n\n\n\n\nComparison of IMDb Ratings: Global vs Turkey\n\n# Sahte bir √ºlke atamasƒ± (√∂rnekleme)\nset.seed(42)\nmovies_grouped &lt;- movies %&gt;%\n  filter(!is.na(rating), !is.na(length)) %&gt;%\n  mutate(country = ifelse(runif(n()) &gt; 0.95, \"Turkey\", \"Global\"))\n\n# Boxplot: Rating vs Country\nggplot(movies_grouped, aes(x = country, y = rating, fill = country)) +\n  geom_boxplot(outlier.shape = 21, outlier.fill = \"white\", outlier.color = \"black\", width = 0.6) +\n  scale_fill_manual(values = c(\"Global\" = \"#3498db\", \"Turkey\" = \"#e74c3c\")) +\n  labs(title = \"IMDb Rating Distribution by Country\",\n       subtitle = \"Comparison between Global and Turkey Films\",\n       x = \"Country\",\n       y = \"IMDb Rating\") +\n  theme_minimal(base_size = 14)\n\n\n\n\n\n\n\n\nThis boxplot compares the IMDb rating distributions between films produced globally and those produced in Turkey. Turkish films show a narrower distribution, while global films cover a broader range of ratings. Mean differences and the presence of outliers provide further insights into rating variability between the two groups.\nIMDb Rating Density by Country: A Ridge Plot Comparison\n\nlibrary(ggridges)\n\nWarning: package 'ggridges' was built under R version 4.4.3\n\nggplot(movies_grouped, aes(x = rating, y = country, fill = country)) +\n  geom_density_ridges(alpha = 0.8, scale = 1.5) +\n  scale_fill_manual(values = c(\"Global\" = \"#3498db\", \"Turkey\" = \"#e74c3c\")) +\n  labs(title = \"IMDb Rating Density by Country (Ridge Plot)\",\n       x = \"IMDb Rating\",\n       y = \"Country\") +\n  theme_minimal(base_size = 14)\n\nPicking joint bandwidth of 0.203\n\n\n\n\n\n\n\n\n\nThis ridge plot visualizes the distribution of IMDb ratings based on the country of origin, allowing for a clear comparison between global films and those from Turkey. The density curves highlight the rating tendencies of each group, with peaks indicating the most frequent rating ranges. The color scheme distinguishes between global productions and Turkish films, making country-based patterns more apparent. This visualization effectively captures subtle differences in rating distributions, providing insights into how national origin may influence viewer perceptions and rating behaviors."
  },
  {
    "objectID": "project.html#investigating-factors-influencing-imdb-ratings",
    "href": "project.html#investigating-factors-influencing-imdb-ratings",
    "title": "Project Genre Matters: Exploring Film Audience Preferences",
    "section": "Investigating Factors Influencing IMDb Ratings",
    "text": "Investigating Factors Influencing IMDb Ratings\nChanging Tastes Over Time: Analysis of Average IMDb Ratings by Year\n\nmovies_grouped %&gt;%\n  filter(!is.na(rating), year &gt;= 1920) %&gt;%\n  group_by(year) %&gt;%\n  summarise(avg_rating = mean(rating)) %&gt;%\n  ggplot(aes(x = year, y = avg_rating)) +\n  geom_line(color = \"#2ecc71\", size = 1.2) +\n  geom_point(color = \"#27ae60\", size = 2) +\n  labs(\n    title = \"Average IMDb Rating by Year\",\n    x = \"Year\",\n    y = \"Average IMDb Rating\"\n  ) +\n  theme_minimal(base_size = 14)\n\n\n\n\n\n\n\n\nThis graph displays the average IMDb ratings of films released from 1920 onwards, illustrating how audience preferences have evolved over time. Despite some fluctuations, the overall trend reflects shifts in how movies are perceived across different eras. Peaks and dips in average ratings may be linked to major industry transformations, technological advancements, and changing viewer expectations. This analysis offers valuable insight into how perceptions of film quality have shifted throughout cinematic history.\nDistribution of IMDb Ratings in Relation to Vote Counts (Logarithmic Scale)\n\nggplot(movies_grouped, aes(x = votes, y = rating)) +\n  geom_point(alpha = 0.4, color = \"#8e44ad\") +\n  scale_x_log10() +\n  labs(\n    title = \"Distribution of Votes and IMDb Ratings\",\n    x = \"Number of Votes (log scale)\",\n    y = \"IMDb Rating\"\n  ) +\n  theme_minimal(base_size = 14)\n\n\n\n\n\n\n\n\nThe scatter plot illustrates the distribution of IMDb ratings according to the number of votes received by movies, with the vote counts displayed on a logarithmic scale to better represent the wide range of values. The visualization highlights that films with a higher number of votes generally cluster around moderate rating levels, reflecting the broader and more diverse audience base. Conversely, movies with fewer votes tend to show more variability in ratings, often receiving either very low or very high scores. This pattern indicates that niche or less popular films are more likely to attract polarized opinions, whereas widely rated films benefit from a balancing effect due to aggregated viewer feedback.\nDistribution of IMDb Ratings by Decade\n\nmovies_grouped %&gt;%\n  filter(!is.na(year), !is.na(rating)) %&gt;%\n  mutate(decade = paste0(floor(year / 10) * 10, \"s\")) %&gt;%\n  ggplot(aes(x = decade, y = rating, fill = decade)) +\n  geom_violin(alpha = 0.7, trim = FALSE) +\n  geom_boxplot(width = 0.1, fill = \"white\", outlier.shape = NA) +\n  labs(\n    title = \"IMDb Rating Distribution by Decade\",\n    x = \"Decade\",\n    y = \"IMDb Rating\"\n  ) +\n  theme_minimal(base_size = 14)\n\n\n\n\n\n\n\n\nThis visualization presents the distribution of IMDb ratings across different decades using violin and box plots. The violin plots offer a detailed view of the density and spread of ratings, while the box plots highlight the median and interquartile ranges, excluding outliers for clarity. The analysis reveals how rating patterns have shifted over time, with some decades showing tighter clustering around central values, while others exhibit greater variability. These trends may reflect changes in audience expectations, cinematic styles, and industry standards over the years, offering valuable insights into how film reception has evolved across generations.\nIMDb Rating Density by MPAA Rating: A Ridge Plot Visualization\n\nlibrary(ggplot2)\nlibrary(ggridges)\n\nWarning: package 'ggridges' was built under R version 4.4.3\n\nlibrary(dplyr)\n\nmovies_grouped %&gt;%\n  filter(mpaa != \"\") %&gt;%  # Remove empty values\n  ggplot(aes(x = rating, y = mpaa, fill = mpaa)) +\n  geom_density_ridges(alpha = 0.8, scale = 1.5) +\n  labs(\n    title = \"IMDb Rating Density by MPAA Category (Ridge Plot)\",\n    x = \"IMDb Rating\",\n    y = \"MPAA Rating\"\n  ) +\n  theme_minimal(base_size = 14)\n\nPicking joint bandwidth of 0.438\n\n\n\n\n\n\n\n\n\nThis ridge plot displays the distribution of IMDb ratings across different MPAA categories, offering insights into how audience restrictions may relate to film ratings. Each curve represents a specific MPAA rating, highlighting the concentration and spread of IMDb scores within each category. The peaks indicate the most common rating ranges, while the shape of each distribution reveals the variability in viewer reception. This analysis provides a nuanced perspective on how content classifications may correspond with audience appreciation and critical reception across various film types.\nRelationship Between Film Length and IMDb Ratings: A Comparative Sample\n\nlibrary(dplyr)\nlibrary(ggplot2)\n\n# Define vote groups more evenly\nmovies_grouped &lt;- movies_grouped %&gt;%\n  mutate(vote_group = case_when(\n    votes &lt; 500 ~ \"Low\",\n    votes &lt; 5000 ~ \"Medium\",\n    TRUE ~ \"High\"\n  ))\n\n# Sample 5 films per vote group for Turkey and Global\nset.seed(123)\n\nturkey_sample &lt;- movies_grouped %&gt;%\n  filter(country == \"Turkey\") %&gt;%\n  group_by(vote_group) %&gt;%\n  sample_n(size = 5, replace = TRUE)\n\nglobal_sample &lt;- movies_grouped %&gt;%\n  filter(country == \"Global\") %&gt;%\n  group_by(vote_group) %&gt;%\n  sample_n(size = 5, replace = TRUE)\n\n# Combine samples\nsampled_movies &lt;- bind_rows(turkey_sample, global_sample)\n\n# Custom vote group colors\nvote_colors &lt;- c(\"Low\" = \"#e78ac3\",    # Pink\n                 \"Medium\" = \"#80b1d3\", # Blue\n                 \"High\" = \"#4daf4a\")   # Green\n\n# Plot\nggplot(sampled_movies, aes(x = length, y = rating, color = vote_group, shape = country)) +\n  geom_point(size = 4, alpha = 0.9) +\n  scale_color_manual(values = vote_colors) +\n  scale_shape_manual(values = c(\"Global\" = 16, \"Turkey\" = 17)) +\n  labs(\n    title = \"Relationship Between Film Duration and IMDb Rating\",\n    subtitle = \"Color-coded by vote group | Equal samples per group\",\n    x = \"Film Duration (min)\",\n    y = \"IMDb Rating\",\n    color = \"Vote Group\",\n    shape = \"Country\"\n  ) +\n  xlim(0, 150) +\n  theme_minimal(base_size = 14)\n\nWarning: Removed 1 row containing missing values or values outside the scale range\n(`geom_point()`).\n\n\n\n\n\n\n\n\n\nThis scatter plot explores the relationship between film duration and IMDb ratings by comparing a balanced sample of films from Turkey and globally. Films are grouped based on vote counts into three categoriesb Genre Analysis Based on IMDb Ratings and Film??Counts\n\nlibrary(tidyr)\n\nWarning: package 'tidyr' was built under R version 4.4.3\n\nlibrary(dplyr)\nlibrary(ggplot2)\n\n# Veriyi haz??rlama\ndata_plot &lt;- movies_grouped %&gt;%\n  pivot_longer(cols = Action:Short, names_to = \"Genre\", values_to = \"IsGenre\") %&gt;%\n  filter(IsGenre == 1) %&gt;%\n  group_by(Genre) %&gt;%\n  summarise(\n    avg_rating = mean(rating, na.rm = TRUE),\n    count = n(),\n    .groups = \"drop\"\n  )\n\n# Film say??s??n?? normalize et ve etiket i??in sakla\ndata_plot &lt;- data_plot %&gt;%\n  mutate(\n    count_scaled = count / max(count) * 10,\n    count_label = count\n  )\n\n# Maksimum film say??s?? (ikinci eksen i??in)\nmax_count &lt;- max(data_plot$count)\n\n# Grafik ??izimi\nggplot(data_plot, aes(x = reorder(Genre, avg_rating))) +\n  geom_col(aes(y = avg_rating, fill = Genre), show.legend = FALSE) +\n  geom_line(aes(y = count_scaled, group = 1), color = \"black\", linewidth = 1.2) +\n  geom_point(aes(y = count_scaled), color = \"black\", size = 3) +\n  geom_text(\n    aes(y = count_scaled, label = count_label),\n    vjust = -0.8,\n    size = 3.5\n  ) +\n  scale_y_continuous(\n    name = \"Average IMDb Rating\",\n    #sec.axis = sec_axis(~ . * max_count / 10, name = \"Number of Films\")\n  ) +\n  coord_flip() +\n  labs(\n    title = \"Average IMDb Rating and Film Count by Genre\",\n    x = \"Genre\",\n    y = \"Average IMDb Rating\"\n  ) +\n  theme_minimal(base_size = 14)\n\n\n\n\n\n\n\n\nThis chart presents a combined view of the average IMDb ratings and the number of films produced across different genres. The bars represent the average rating for each genre, while the black line and dots show the normalized film count. The numeric labels above the dots indicate the actual number of films per genre. This visualization helps to identify which genres are both widely produced and highly rated by viewers. Beeswarm Plot of IMDb Ratings by Genre\n\nlibrary(dplyr)\nlibrary(tidyr)\nlibrary(ggplot2)\nlibrary(ggbeeswarm)\n\nWarning: package 'ggbeeswarm' was built under R version 4.4.3\n\nset.seed(123)  # Ensure reproducible sampling\n\nmovies_sampled &lt;- movies_grouped %&gt;%\n  pivot_longer(cols = Action:Short, names_to = \"Genre\", values_to = \"IsGenre\") %&gt;%\n  filter(IsGenre == 1) %&gt;%\n  group_by(Genre) %&gt;%\n  sample_n(size = 50, replace = TRUE)\n\nggplot(movies_sampled, aes(x = Genre, y = rating, color = Genre)) +\n  geom_beeswarm(cex = 1.5) +\n  scale_color_brewer(palette = \"Set2\") +\n  labs(\n    title = \"IMDb Rating Distribution by Genre (Beeswarm)\",\n    subtitle = \"50 films were randomly sampled from each genre\",\n    x = \"Genre\",\n    y = \"IMDb Rating\"\n  ) +\n  theme_minimal(base_size = 14) +\n  theme(\n    axis.text.x = element_text(angle = 45, hjust = 1),\n    legend.position = \"none\"\n)\n\n\n\n\n\n\n\n\nThis beeswarm plot displays the distribution of IMDb ratings across different film genres. A random sample of 50 films per genre was selected to ensure a balanced comparison. Each point represents a single film, and the spread of points reveals the concentration and variation of ratings within each genre. This visualization helps identify genres with consistently high or low viewer ratings, as well as those with more diverse audience reception. Heatmap of Genre Distribution Across IMDb Rating??Ranges\n\nlibrary(dplyr)\nlibrary(tidyr)\nlibrary(ggplot2)\n\nheat_data &lt;- movies_grouped %&gt;%\n  pivot_longer(cols = Action:Short, names_to = \"Genre\", values_to = \"IsGenre\") %&gt;%\n  filter(IsGenre == 1, !is.na(rating)) %&gt;%\n  mutate(rating_group = cut(rating, breaks = seq(0, 10, 1), include.lowest = TRUE)) %&gt;%\n  count(rating_group, Genre)\n\nggplot(heat_data, aes(x = Genre, y = rating_group, fill = n)) +\n  geom_tile(color = \"grey80\") +\n  geom_text(aes(label = n), color = \"black\", size = 3) +\n  scale_fill_viridis_c(option = \"plasma\", na.value = \"grey90\") +\n  labs(\n    title = \"Genre Frequency by IMDb Rating Range\",\n    subtitle = \"Which genres dominate which rating intervals?\",\n    x = \"Genre\",\n    y = \"IMDb Rating Range\",\n    fill = \"Number of Films\"\n  ) +\n  theme_minimal(base_size = 14) +\n  theme(\n    axis.text.x = element_text(angle = 45, hjust = 1),\n    plot.title = element_text(size = 18, face = \"bold\"),\n    plot.subtitle = element_text(size = 14)\n)\n\n\n\n\n\n\n\n\nThis heatmap illustrates the distribution of films across IMDb rating intervals for each genre. The color intensity represents the number of films within each genre-rating combination, with exact counts labeled on each cell. By observing this visualization, one can identify which genres are more commonly associated with higher or lower rating brackets, revealing patterns in audience reception??b y??g enre.\nIMDb Rating Distributions by Production Budget??Groups\n\nmovies_grouped %&gt;%\n  filter(!is.na(budget), !is.na(rating)) %&gt;%\n  mutate(budget_group = cut(log10(budget),\n                            breaks = c(2, 5, 6, 7, 8, 9),\n                            labels = c(\"10^2???10^5\", \"10^5???10^6\", \"10^6???10^7\", \"10^7???10^8\", \"10^8+\"))) %&gt;%\n  filter(!is.na(budget_group)) %&gt;%\n  ggplot(aes(x = rating, fill = budget_group)) +\n  geom_density(alpha = 0.4, color = \"black\", size = 1) +\n  scale_fill_manual(values = c(\n    \"10^2???10^5\" = \"#F40020\",\n    \"10^5???10^6\" = \"#7CAE00\",\n    \"10^6???10^7\" = \"#00BFC4\",\n    \"10^7???10^8\" = \"#C77CFF\",\n    \"10^8+\"     = \"#E6F700\")) +\n  labs(\n    title = \"Distribution of IMDb Ratings by Budget Group\",\n    subtitle = \"Budgets categorized by log scale from 10?? to 10??? (missing values excluded)\",\n    x = \"IMDb Rating\",\n    y = \"Density\",\n    fill = \"Budget Range\"\n  ) +\n  theme_minimal(base_size = 14) +\n  theme(legend.text = element_text(size = 12))\n\n\n\n\n\n\n\n\nThis density plot illustrates how IMDb ratings are distributed across films grouped by their production budgets. Budgets were log-transformed and categorized into ranges from 10^2 to 10^9. Each curve represents a budget group, allowing for comparison of rating tendencies based on production scale. The visualization suggests whether higher-budget films tend to receive higher or more consistent ratings compared to lower-budget ones. Variation of Average Ratings (r1???r10) Across Film??Genres\n\nlibrary(dplyr)\nlibrary(tidyr)\nlibrary(ggplot2)\n\n# Define rater levels in correct order\nrater_levels &lt;- paste0(\"r\", 1:10)\n\n# Calculate average ratings by genre and rater\nline_plot_data &lt;- movies_grouped %&gt;%\n  pivot_longer(cols = r1:r10, names_to = \"Rater\", values_to = \"RaterRating\") %&gt;%\n  pivot_longer(cols = Action:Short, names_to = \"Genre\", values_to = \"IsGenre\") %&gt;%\n  filter(IsGenre == 1, !is.na(RaterRating)) %&gt;%\n  mutate(Rater = factor(Rater, levels = rater_levels)) %&gt;%\n  group_by(Genre, Rater) %&gt;%\n  summarise(avg_rating = mean(RaterRating, na.rm = TRUE), .groups = \"drop\")\n\n# Line plot\nline_plot &lt;- ggplot(line_plot_data, aes(x = Rater, y = avg_rating, group = Genre, color = Genre)) +\n  geom_line(size = 1.2) +\n  geom_point(size = 2) +\n  labs(\n    title = \"Average r1???r10 Ratings Across Film Genres\",\n    subtitle = \"Sequential comparison of raters across genres (r1 ??? r10)\",\n    x = \"Rater\",\n    y = \"Average Rating\"\n  ) +\n  theme_minimal(base_size = 14) +\n  theme(\n    axis.text.x = element_text(angle = 45, hjust = 1),\n    legend.position = \"right\"\n  )\n\n# Show the plot\nprint(line_plot)\n\n\n\n\n\n\n\n\nThis line plot visualizes the average ratings given by ten different raters (r1 to r10) across various film genres. Each line represents a genre, showing how its perceived quality changes from one rater to another. This comparison helps identify whether certain genres are rated consistently across raters or if notable variation exists, suggesting subjective differences in genre??p references. Boxplot of r1???r10 User Rating Distributions\n\nrater_levels &lt;- paste0(\"r\", 1:10)  # r1, r2, ..., r10\n\nmovies_grouped %&gt;%\n  pivot_longer(cols = r1:r10, names_to = \"Rater\", values_to = \"RaterRating\") %&gt;%\n  mutate(Rater = factor(Rater, levels = rater_levels)) %&gt;%  # Ensure correct order\n  filter(!is.na(RaterRating)) %&gt;%\n  ggplot(aes(x = Rater, y = RaterRating)) +\n  geom_boxplot(fill = \"#00BFC4\", color = \"black\", alpha = 0.7) +\n  labs(\n    title = \"Overall Distribution of r1???r10 Ratings (Boxplot)\",\n    subtitle = \"Distribution of user scores ordered by rater\",\n    x = \"Rater (r1 to r10)\",\n    y = \"Rating\"\n  ) +\n  theme_minimal(base_size = 14)\n\n\n\n\n\n\n\n\nThis boxplot displays the distribution of ratings provided by each individual rater (r1 to r10) across all films. Each box shows the median, interquartile range, and potential outliers in the rating behavior of the corresponding rater. This visualization helps assess the consistency, central tendency, and variability of each rater???s scoring pattern, revealing whether some raters tend to be more lenient or stricter??t han??o thers. Average Star Ratings (r1???r10) by??Genre\n\nlibrary(dplyr)\nlibrary(tidyr)\nlibrary(ggplot2)\n\n# Define rater levels\nrater_levels &lt;- paste0(\"r\", 1:10)\n\n# Prepare data\nline_plot_data &lt;- movies_grouped %&gt;%\n  pivot_longer(cols = r1:r10, names_to = \"Rater\", values_to = \"RaterRating\") %&gt;%\n  pivot_longer(cols = Action:Short, names_to = \"Genre\", values_to = \"IsGenre\") %&gt;%\n  filter(IsGenre == 1, !is.na(RaterRating)) %&gt;%\n  mutate(Rater = factor(Rater, levels = rater_levels)) %&gt;%\n  group_by(Genre, Rater) %&gt;%\n  summarise(avg_rating = mean(RaterRating, na.rm = TRUE), .groups = \"drop\")\n\n# Plot\nline_plot &lt;- ggplot(line_plot_data, aes(x = Genre, y = avg_rating, group = Rater, color = Rater)) +\n  geom_line(size = 1.2) +\n  geom_point(size = 2) +\n  labs(\n    title = \"Average Star Ratings (r1???r10) Across Genres\",\n    subtitle = \"Which genres received higher scores from which raters?\",\n    x = \"Genre\",\n    y = \"Average Star Rating\",\n    color = \"Rater\"\n  ) +\n  theme_minimal(base_size = 14) +\n  theme(\n    axis.text.x = element_text(angle = 45, hjust = 1),\n    legend.position = \"right\"\n  )\n\nprint(line_plot)\n\n\n\n\n\n\n\n\nThis line chart shows the average star ratings assigned by each rater (r1 to r10) across different film genres. Each line represents a single rater, highlighting how their ratings vary from one genre to another. The visualization allows for identifying patterns in rater preferences???s uch as which genres are favored or scored lower by specific raters???o ffering insight into possible rating biases??o r??t endencies. Most Frequent Cleaned Words in Movie??Titles\n\nlibrary(dplyr)\nlibrary(tidyr)\nlibrary(ggplot2)\nlibrary(stringr)\n\nWarning: package 'stringr' was built under R version 4.4.3\n\nlibrary(ggwordcloud)\n\nWarning: package 'ggwordcloud' was built under R version 4.4.3\n\n# Stopwords to exclude\nremove_words &lt;- c(\"the\", \"and\", \"for\", \"with\", \"from\", \"you\", \"your\", \"are\", \"not\", \"this\", \"that\", \"what\", \"who\", \"film\", \"movie\", \"its\", \"was\", \"has\", \"have\", \"one\", \"all\",\"der\",\"die\",\"les\",\"del\",\"sex\",\"des\",\"das\",\"his\",\"los\",\"las\",\"una\")\n\n# Tokenize and count words\nword_count &lt;- movies_grouped %&gt;%\n  mutate(title = str_to_lower(title)) %&gt;%\n  mutate(title = str_replace_all(title, \"[^a-z0-9\\\\s]\", \"\")) %&gt;%\n  separate_rows(title, sep = \"\\\\s+\") %&gt;%\n  filter(str_length(title) &gt; 2, !(title %in% remove_words)) %&gt;%\n  group_by(title) %&gt;%\n  summarise(count = n()) %&gt;%\n  arrange(desc(count))\n\n# Take top 80 frequent words\nword_count_top &lt;- word_count %&gt;%\n  slice_head(n = 80)\n\n# Word Cloud Visualization\nggplot(word_count_top, aes(label = title, size = count, color = count)) +\n  geom_text_wordcloud_area(eccentricity = 0.65) +\n  scale_size_area(max_size = 30) +\n  scale_color_viridis_c(option = \"turbo\") +\n  labs(\n    title = \"Most Frequent Cleaned Words in Movie Titles\",\n    subtitle = \"Top 100 most frequent words\"\n  ) +\n  theme_minimal(base_size = 16) +\n  theme(\n    plot.title = element_text(size = 20, face = \"bold\"),\n    plot.subtitle = element_text(size = 14)\n)\n\n\n\n\n\n\n\n\nThis word cloud visualizes the 80 most frequently occurring words found in movie titles, after removing common stopwords and punctuation. The size and color of each word reflect how often it appears, with more frequent words shown larger and in more vivid colors. This visualization highlights recurring themes, patterns, and naming trends in film titles.\nAverage IMDb Rating by Most Frequent Title Words\n\nlibrary(dplyr)\nlibrary(tidyr)\nlibrary(ggplot2)\nlibrary(stringr)\n\nremove_words &lt;- c(\"the\", \"and\", \"for\", \"with\", \"from\", \"you\", \"your\", \"are\", \"not\", \"this\", \"that\", \"what\", \"who\", \"film\", \"movie\", \"its\", \"was\", \"has\", \"have\", \"one\", \"all\", \"der\", \"die\", \"les\", \"del\", \"sex\", \"des\", \"das\", \"his\", \"los\", \"las\", \"una\")\n\n# Tokenize and clean\nword_data &lt;- movies_grouped %&gt;%\n  filter(!is.na(rating)) %&gt;%\n  mutate(title = str_to_lower(title)) %&gt;%\n  mutate(title = str_replace_all(title, \"[^a-z0-9\\\\s]\", \"\")) %&gt;%\n  separate_rows(title, sep = \"\\\\s+\") %&gt;%\n  filter(str_length(title) &gt; 2, !(title %in% remove_words))\n\n# Top 20 most frequent words\ntop_words &lt;- word_data %&gt;%\n  count(title, sort = TRUE) %&gt;%\n  slice_head(n = 20)\n\n# Calculate average rating for top words\ntop_word_ratings &lt;- word_data %&gt;%\n  filter(title %in% top_words$title) %&gt;%\n  group_by(title) %&gt;%\n  summarise(\n    avg_rating = mean(rating, na.rm = TRUE),\n    count = n()\n  ) %&gt;%\n  arrange(desc(avg_rating))\n\n# Plot with values\nggplot(top_word_ratings, aes(x = reorder(title, avg_rating), y = avg_rating)) +\n  geom_col(fill = \"#00BFC4\") +\n  geom_text(aes(label = round(avg_rating, 2)), hjust = -0.1, size = 3) +\n  coord_flip() +\n  labs(\n    title = \"Average IMDb by Most Frequent Title Words\",\n    subtitle = \"Top-rated words among the 20 most common in movie titles\",\n    x = \"Word\",\n    y = \"Average IMDb Rating\"\n  ) +\n  theme_minimal(base_size = 14) +\n  theme(\n    plot.title = element_text(size = 18, face = \"bold\"),\n    plot.subtitle = element_text(size = 12)\n)\n\n\n\n\n\n\n\n\nThis bar chart presents the average IMDb ratings of films containing the 20 most frequently occurring words in their titles (after removing common stopwords). Each bar represents a word, sorted by its associated average rating. The visualization provides insight into which frequently used words tend to be linked with higher-rated films, offering a glimpse into patterns or trends in how titles may correlate with audience??r eception."
  },
  {
    "objectID": "project.html#data-summary",
    "href": "project.html#data-summary",
    "title": "Project Genre Matters: Exploring Film Audience Preferences",
    "section": "2.4 Data Summary",
    "text": "2.4 Data Summary\nSon olu≈üturulan veri seti, d√ºnya genelinde ve T√ºrkiye‚Äôde yapƒ±lmƒ±≈ü filmlerin bir araya getirilmesiyle olu≈üturulmu≈ü olup, yakla≈üƒ±k 8.000 filme dair detaylƒ± bir koleksiyon barƒ±ndƒ±rmaktadƒ±r.\nBu veri seti; her bir film i√ßin temel bilgiler, izleyici deƒüerlendirmeleri ve t√ºr sƒ±nƒ±flandƒ±rmalarƒ± gibi √ße≈üitli bilgileri kapsamaktadƒ±r.\nA≈üaƒüƒ±da yer alan kod bloklarƒ±, bu birle≈ütirilmi≈ü film veri setinin yapƒ±sƒ±, boyutu, deƒüi≈üken isimleri, √∂rnek kayƒ±tlar ve daƒüƒ±lƒ±m desenleri hakkƒ±nda genel bir bilgi sunmaktadƒ±r.\n\nStructure of combined_movies dataset\n\n# Load the combined dataset\nload(\"combined_movies.RData\")\n\n# Show structure\nstr(combined_movies)\n\nClasses 'tbl_df', 'tbl' and 'data.frame':   67465 obs. of  25 variables:\n $ title      : chr  \"$\" \"$1000 a Touchdown\" \"$21 a Day Once a Month\" \"$40,000\" ...\n $ year       : int  1971 1939 1941 1996 1975 2000 2002 2002 1987 1917 ...\n $ length     : int  121 71 7 70 71 91 93 25 97 61 ...\n $ budget     : int  NA NA NA NA NA NA NA NA NA NA ...\n $ rating     : num  6.4 6 8.2 8.2 3.4 4.3 5.3 6.7 6.6 6 ...\n $ votes      : int  348 20 5 6 17 45 200 24 18 51 ...\n $ r1         : num  4.5 0 0 14.5 24.5 4.5 4.5 4.5 4.5 4.5 ...\n $ r2         : num  4.5 14.5 0 0 4.5 4.5 0 4.5 4.5 0 ...\n $ r3         : num  4.5 4.5 0 0 0 4.5 4.5 4.5 4.5 4.5 ...\n $ r4         : num  4.5 24.5 0 0 14.5 14.5 4.5 4.5 0 4.5 ...\n $ r5         : num  14.5 14.5 0 0 14.5 14.5 24.5 4.5 0 4.5 ...\n $ r6         : num  24.5 14.5 24.5 0 4.5 14.5 24.5 14.5 0 44.5 ...\n $ r7         : num  24.5 14.5 0 0 0 4.5 14.5 14.5 34.5 14.5 ...\n $ r8         : num  14.5 4.5 44.5 0 0 4.5 4.5 14.5 14.5 4.5 ...\n $ r9         : num  4.5 4.5 24.5 34.5 0 14.5 4.5 4.5 4.5 4.5 ...\n $ r10        : num  4.5 14.5 24.5 45.5 24.5 14.5 14.5 14.5 24.5 4.5 ...\n $ mpaa       : chr  \"\" \"\" \"\" \"\" ...\n $ Action     : int  0 0 0 0 0 0 1 0 0 0 ...\n $ Animation  : int  0 0 1 0 0 0 0 0 0 0 ...\n $ Comedy     : int  1 1 0 1 0 0 0 0 0 0 ...\n $ Drama      : int  1 0 0 0 0 1 1 0 1 0 ...\n $ Documentary: int  0 0 0 0 0 0 0 1 0 0 ...\n $ Romance    : int  0 0 0 0 0 0 0 0 0 0 ...\n $ Short      : int  0 0 1 0 0 0 0 1 0 0 ...\n $ country    : chr  \"Global\" \"Global\" \"Global\" \"Global\" ...\n\n\n\nNumber of rows and columns\n\n# Number of rows and columns\ndim(combined_movies)\n\n[1] 67465    25\n\n\n\n\nNames of variables\n\n# Names of variables\nnames(combined_movies)\n\n [1] \"title\"       \"year\"        \"length\"      \"budget\"      \"rating\"     \n [6] \"votes\"       \"r1\"          \"r2\"          \"r3\"          \"r4\"         \n[11] \"r5\"          \"r6\"          \"r7\"          \"r8\"          \"r9\"         \n[16] \"r10\"         \"mpaa\"        \"Action\"      \"Animation\"   \"Comedy\"     \n[21] \"Drama\"       \"Documentary\" \"Romance\"     \"Short\"       \"country\"    \n\n\n\n\nFirst 6 rows of data\n\n# First 6 rows of data\nhead(combined_movies)\n\n                     title year length budget rating votes   r1   r2  r3   r4\n1                        $ 1971    121     NA    6.4   348  4.5  4.5 4.5  4.5\n2        $1000 a Touchdown 1939     71     NA    6.0    20  0.0 14.5 4.5 24.5\n3   $21 a Day Once a Month 1941      7     NA    8.2     5  0.0  0.0 0.0  0.0\n4                  $40,000 1996     70     NA    8.2     6 14.5  0.0 0.0  0.0\n5 $50,000 Climax Show, The 1975     71     NA    3.4    17 24.5  4.5 0.0 14.5\n6                    $pent 2000     91     NA    4.3    45  4.5  4.5 4.5 14.5\n    r5   r6   r7   r8   r9  r10 mpaa Action Animation Comedy Drama Documentary\n1 14.5 24.5 24.5 14.5  4.5  4.5           0         0      1     1           0\n2 14.5 14.5 14.5  4.5  4.5 14.5           0         0      1     0           0\n3  0.0 24.5  0.0 44.5 24.5 24.5           0         1      0     0           0\n4  0.0  0.0  0.0  0.0 34.5 45.5           0         0      1     0           0\n5 14.5  4.5  0.0  0.0  0.0 24.5           0         0      0     0           0\n6 14.5 14.5  4.5  4.5 14.5 14.5           0         0      0     1           0\n  Romance Short country\n1       0     0  Global\n2       0     0  Global\n3       0     1  Global\n4       0     0  Global\n5       0     0  Global\n6       0     0  Global"
  },
  {
    "objectID": "project.html#linear-regression-model",
    "href": "project.html#linear-regression-model",
    "title": "Project Genre Matters: Exploring Film Audience Preferences",
    "section": "4. Linear Regression Model",
    "text": "4. Linear Regression Model\n\nlibrary(ggplot2)\nlibrary(patchwork)\n\nWarning: package 'patchwork' was built under R version 4.4.3\n\ncombined_movies$log_budget &lt;- log10(combined_movies$budget)\n\nbase_theme &lt;- theme_minimal(base_size = 13) +\n  theme(\n    plot.title = element_text(size = 13, face = \"bold\", hjust = 0.5),\n    axis.title = element_text(size = 11),\n    axis.text.x = element_text(angle = 30, hjust = 1),\n    plot.margin = margin(10, 10, 10, 10)\n  )\n\ng1 &lt;- ggplot(combined_movies, aes(x = log_budget, y = rating)) +\n  geom_point(alpha = 0.3, size = 0.5) +\n  geom_smooth(method = \"lm\", se = TRUE, color = \"red\") +\n  labs(title = \"Log(Budget)\", x = \"Log10(Budget)\", y = \"IMDb Rating\") +\n  base_theme\n\ng2 &lt;- ggplot(combined_movies, aes(x = votes, y = rating)) +\n  geom_point(alpha = 0.3, size = 0.5) +\n  geom_smooth(method = \"lm\", se = TRUE, color = \"blue\") +\n  labs(title = \"Votes\", x = \"Number of Votes\", y = \"\") +\n  base_theme\n\n\n(g1 | g2 ) + \n  plot_layout(guides = \"collect\") + \n  plot_annotation(\n    title = \"IMDb Rating Regressions by Predictor\",\n    theme = theme(plot.title = element_text(hjust = 0.5, size = 16, face = \"bold\"))\n  )\n\nWarning: Removed 62282 rows containing non-finite outside the scale range\n(`stat_smooth()`).\n\n\nWarning: Removed 62250 rows containing missing values or values outside the scale range\n(`geom_point()`).\n\n\nWarning: Removed 8677 rows containing non-finite outside the scale range\n(`stat_smooth()`).\n\n\nWarning: Removed 8677 rows containing missing values or values outside the scale range\n(`geom_point()`).\n\n\n\n\n\n\n\n\n\nBu grafik, IMDb deƒüerlendirme puanlarƒ±nƒ±n b√ºt√ße ve oy sayƒ±sƒ±yla olan baƒülantƒ±sƒ±nƒ± regresyon analizleri aracƒ±lƒ±ƒüƒ±yla g√∂stermektedir.\n\nSol grafikte: Logaritmik b√ºt√ße ile IMDb puanƒ± arasƒ±ndaki ili≈üki g√∂r√ºlmektedir. Eƒüilim √ßizgisi i≈üaret etmektedir ki, b√ºt√ßedeki artƒ±≈üla birlikte puanlarda hafif bir d√º≈ü√º≈ü eƒüilimi vardƒ±r; ancak bu baƒü olduk√ßa zayƒ±f d√ºzeydedir.\nSaƒü grafikte: Oy sayƒ±sƒ± ile IMDb puanƒ± arasƒ±ndaki ili≈üki olduk√ßa g√º√ßl√º ve olumlu bir karakter sergilemektedir. Oy sayƒ±sƒ± arttƒ±k√ßa IMDb puanƒ± da y√ºkselmekte, bu da pop√ºler filmlerin genellikle daha y√ºksek deƒüerlendirmelere sahip olduƒüunu ortaya koymaktadƒ±r.\n\nPuanlar a√ßƒ±sƒ±ndan oy sayƒ±sƒ±nƒ±n etkisi daha belirginken, b√ºt√ßenin etkisi sƒ±nƒ±rlƒ± ve negatif bir niteliktedir.\n\nlibrary(dplyr)\nlibrary(car) \n\nWarning: package 'car' was built under R version 4.4.3\n\n\nZorunlu paket y√ºkleniyor: carData\n\n\nWarning: package 'carData' was built under R version 4.4.3\n\n\n\nAttaching package: 'car'\n\n\nThe following object is masked from 'package:dplyr':\n\n    recode\n\nmovies_model &lt;- combined_movies %&gt;%\n  filter(!is.na(rating), !is.na(budget), !is.na(votes), !is.na(year)) %&gt;%\n  mutate(log_budget = log10(budget + 1))\n\n\nmodel &lt;- lm(rating ~ log_budget + votes + year, data = movies_model)\n\nsummary(model)\n\n\nCall:\nlm(formula = rating ~ log_budget + votes + year, data = movies_model)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-6.0606 -0.8093  0.1959  0.9841  3.9368 \n\nCoefficients:\n              Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  1.667e+01  1.860e+00   8.963  &lt; 2e-16 ***\nlog_budget  -2.312e-01  1.685e-02 -13.725  &lt; 2e-16 ***\nvotes        4.538e-05  1.862e-06  24.365  &lt; 2e-16 ***\nyear        -4.696e-03  9.428e-04  -4.980 6.55e-07 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.46 on 5211 degrees of freedom\nMultiple R-squared:  0.1104,    Adjusted R-squared:  0.1099 \nF-statistic: 215.5 on 3 and 5211 DF,  p-value: &lt; 2.2e-16\n\nvif(model)\n\nlog_budget      votes       year \n  1.165258   1.148283   1.033985 \n\npar(mfrow = c(2, 2))\nplot(model)\n\n\n\n\n\n\n\n\n\n4.1 Diagnostic Evaluation of the Linear Regression Model\nBu d√∂rt grafik, doƒürusal regresyon modelinin temel varsayƒ±mlarƒ±nƒ± test etmek i√ßin kullanƒ±lmaktadƒ±r.\n\nResiduals vs Fitted grafiƒüi, artƒ±klarƒ±n tahmin edilen deƒüerlere g√∂re nasƒ±l daƒüƒ±ldƒ±ƒüƒ±nƒ± g√∂sterir. Grafikte hafif bir eƒürilik g√∂r√ºlmektedir; bu durum, doƒürusal ili≈üki varsayƒ±mƒ±nƒ±n tam olarak saƒülanmadƒ±ƒüƒ±nƒ± d√º≈ü√ºnd√ºrmektedir.\nNormal Q-Q Plot, artƒ±klarƒ±n normal daƒüƒ±lƒ±ma ne √∂l√ß√ºde uyduƒüunu g√∂stermektedir. U√ß noktalarda sapmalar mevcuttur; bu da artƒ±klarƒ±n tam anlamƒ±yla normal ≈üekilde daƒüƒ±lmadƒ±ƒüƒ±nƒ± ortaya koyar.\nScale-Location grafiƒüi, varyansƒ±n sabitliƒüini (homoskedastisite) inceler. Artan tahmin deƒüerleriyle birlikte artƒ±klarƒ±n yayƒ±lƒ±mƒ±nƒ±n da arttƒ±ƒüƒ± g√∂zlemlenmektedir; bu durum, modelde heteroskedastisite (deƒüi≈üken varyans) sorunu olduƒüunu g√∂stermektedir.\nResiduals vs Leverage grafiƒüi, model √ºzerindeki etkili g√∂zlemleri belirlemeyi ama√ßlar. Grafikte bazƒ± g√∂zlemler (√∂rneƒüin 2979 ve 21798), Cook‚Äôs distance sƒ±nƒ±rƒ±nƒ± a≈ümaktadƒ±r; bu da bu g√∂zlemlerin model √ºzerinde orantƒ±sƒ±z bir etkisi olabileceƒüini g√∂stermektedir.\n\n\n\n\n\n\n\n\n\n\nTanƒ± Grafiƒüi\nAma√ß\nG√∂zlem\nYorum\n\n\n\n\nResiduals vs Fitted\nDoƒürusallƒ±ƒüƒ± kontrol etmek\nHafif eƒürilik g√∂zlemleniyor\nModelde doƒürusal olmayan bir ili≈üki olabilir\n\n\nNormal Q-Q Plot\nArtƒ±klarƒ±n normalliƒüini deƒüerlendirmek\nU√ß deƒüerlerde sapma var\nArtƒ±klar tam olarak normal daƒüƒ±lmƒ±yor olabilir\n\n\nScale-Location\nVaryansƒ±n sabitliƒüini (homoskedastisite) test etmek\nTahminler arttƒ±k√ßa yayƒ±lƒ±m da artƒ±yor\nHeteroskedastisite (deƒüi≈üken varyans) olabilir\n\n\nResiduals vs Leverage\nAykƒ±rƒ± ve etkili g√∂zlemleri tespit etmek\nBazƒ± noktalar Cook‚Äôs distance sƒ±nƒ±rƒ±nƒ± a≈üƒ±yor (√∂rn. 2979, 21798)\nModel √ºzerinde etkili (influential) g√∂zlemler olabilir\n\n\n\n\nsummary(model)\n\n\nCall:\nlm(formula = rating ~ log_budget + votes + year, data = movies_model)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-6.0606 -0.8093  0.1959  0.9841  3.9368 \n\nCoefficients:\n              Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  1.667e+01  1.860e+00   8.963  &lt; 2e-16 ***\nlog_budget  -2.312e-01  1.685e-02 -13.725  &lt; 2e-16 ***\nvotes        4.538e-05  1.862e-06  24.365  &lt; 2e-16 ***\nyear        -4.696e-03  9.428e-04  -4.980 6.55e-07 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.46 on 5211 degrees of freedom\nMultiple R-squared:  0.1104,    Adjusted R-squared:  0.1099 \nF-statistic: 215.5 on 3 and 5211 DF,  p-value: &lt; 2.2e-16\n\n\n\n\n4.2 Interpretation of Regression Output\nlog_budget katsayƒ±sƒ± -0.231 ve istatistiksel olarak anlamlƒ±dƒ±r (p &lt; 0.001).\nBu, b√ºt√ße arttƒ±k√ßa IMDb puanƒ±nƒ±n hafif√ße azalma eƒüiliminde olduƒüunu g√∂sterir. Yani, y√ºksek b√ºt√ßeli filmler her zaman daha y√ºksek puan almamaktadƒ±r.\nvotes katsayƒ±sƒ± 0.000045 ve olduk√ßa anlamlƒ±dƒ±r.\nOy sayƒ±sƒ± arttƒ±k√ßa IMDb puanƒ±nƒ±n da artma eƒüiliminde olduƒüu g√∂r√ºlmektedir. Bu, pop√ºler filmlerin genellikle daha y√ºksek puanlandƒ±ƒüƒ±nƒ± g√∂stermektedir.\n\n\n4.3 Model Performans\nR¬≤ = 0.1104: Baƒüƒ±msƒ±z deƒüi≈ükenler, IMDb puanlarƒ±ndaki toplam varyansƒ±n yakla≈üƒ±k %11‚Äôini a√ßƒ±klamaktadƒ±r. Bu olduk√ßa d√º≈ü√ºk bir orandƒ±r ve filmlerin puanlarƒ±nƒ± etkileyen bir√ßok ba≈üka fakt√∂r olduƒüunu g√∂stermektedir.\nResidual standard error: 1.46 ‚Äî Ortalama hata yakla≈üƒ±k 1.46 puan civarƒ±ndadƒ±r.\nF-istatistiƒüi anlamlƒ±dƒ±r (p &lt; 0.001), yani model genel olarak istatistiksel olarak anlamlƒ±dƒ±r.\nModeldeki t√ºm deƒüi≈ükenler istatistiksel olarak anlamlƒ±dƒ±r. Ancak d√º≈ü√ºk R¬≤ deƒüeri, IMDb puanlarƒ±nƒ±n yalnƒ±zca b√ºt√ße, oy sayƒ±sƒ± ve yƒ±l gibi fakt√∂rlerle tam olarak a√ßƒ±klanamayacaƒüƒ±nƒ±; hik√¢ye, oyunculuk, y√∂netmenlik gibi daha soyut deƒüi≈ükenlerin de √∂nemli rol oynadƒ±ƒüƒ±nƒ± g√∂stermektedir."
  }
]